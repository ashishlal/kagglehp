{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/mathormad/inceptionv3-baseline-lb-0-379/code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.io\n",
    "from skimage.transform import resize\n",
    "from imgaug import augmenters as iaa\n",
    "from tqdm import tqdm\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from sklearn.utils import class_weight, shuffle\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "SIZE = 299"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/rejpalcz/best-loss-function-for-f1-score-metric/notebook\n",
    "import tensorflow as tf\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    y_pred = K.round(y_pred)\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n",
    "\n",
    "def f1_loss(y_true, y_pred):\n",
    "    \n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(K.binary_crossentropy(y_true, y_pred), axis=-1) + (1 - K.mean(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset info\n",
    "path_to_train = '../data/train/'\n",
    "data = pd.read_csv('../data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00070df0-bbc3-11e8-b2bc-ac1f6b6435d0</td>\n",
       "      <td>16 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000a6c98-bb9b-11e8-b2b9-ac1f6b6435d0</td>\n",
       "      <td>7 1 2 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000a9596-bbc4-11e8-b2bc-ac1f6b6435d0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000c99ba-bba4-11e8-b2b9-ac1f6b6435d0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001838f8-bbca-11e8-b2bc-ac1f6b6435d0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Id   Target\n",
       "0  00070df0-bbc3-11e8-b2bc-ac1f6b6435d0     16 0\n",
       "1  000a6c98-bb9b-11e8-b2b9-ac1f6b6435d0  7 1 2 0\n",
       "2  000a9596-bbc4-11e8-b2bc-ac1f6b6435d0        5\n",
       "3  000c99ba-bba4-11e8-b2b9-ac1f6b6435d0        1\n",
       "4  001838f8-bbca-11e8-b2bc-ac1f6b6435d0       18"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_info = []\n",
    "for name, labels in zip(data['Id'], data['Target'].str.split(' ')):\n",
    "    train_dataset_info.append({\n",
    "        'path':os.path.join(path_to_train, name),\n",
    "        'labels':np.array([int(label) for label in labels])})\n",
    "train_dataset_info = np.array(train_dataset_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([{'path': '../data/train/00070df0-bbc3-11e8-b2bc-ac1f6b6435d0', 'labels': array([16,  0])},\n",
       "       {'path': '../data/train/000a6c98-bb9b-11e8-b2b9-ac1f6b6435d0', 'labels': array([7, 1, 2, 0])},\n",
       "       {'path': '../data/train/000a9596-bbc4-11e8-b2bc-ac1f6b6435d0', 'labels': array([5])},\n",
       "       ...,\n",
       "       {'path': '../data/train/fff189d8-bbab-11e8-b2ba-ac1f6b6435d0', 'labels': array([7])},\n",
       "       {'path': '../data/train/fffdf7e0-bbc4-11e8-b2bc-ac1f6b6435d0', 'labels': array([25,  2, 21])},\n",
       "       {'path': '../data/train/fffe0ffe-bbc0-11e8-b2bb-ac1f6b6435d0', 'labels': array([2, 0])}],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class data_generator:\n",
    "    \n",
    "    def create_train(dataset_info, batch_size, shape, augument=True):\n",
    "        assert shape[2] == 3\n",
    "        while True:\n",
    "            dataset_info = shuffle(dataset_info)\n",
    "            for start in range(0, len(dataset_info), batch_size):\n",
    "                end = min(start + batch_size, len(dataset_info))\n",
    "                batch_images = []\n",
    "                X_train_batch = dataset_info[start:end]\n",
    "                batch_labels = np.zeros((len(X_train_batch), 28))\n",
    "                for i in range(len(X_train_batch)):\n",
    "                    image = data_generator.load_image(\n",
    "                        X_train_batch[i]['path'], shape)   \n",
    "                    if augument:\n",
    "                        image = data_generator.augment(image)\n",
    "                    batch_images.append(image/255.)\n",
    "                    batch_labels[i][X_train_batch[i]['labels']] = 1\n",
    "                yield np.array(batch_images, np.float32), batch_labels\n",
    "\n",
    "    def load_image(path, shape):\n",
    "        image_red_ch = Image.open(path+'_red.png')\n",
    "        image_yellow_ch = Image.open(path+'_yellow.png')\n",
    "        image_green_ch = Image.open(path+'_green.png')\n",
    "        image_blue_ch = Image.open(path+'_blue.png')\n",
    "        image = np.stack((\n",
    "            np.array(image_red_ch),\n",
    "            np.array(image_green_ch), \n",
    "            np.array(image_blue_ch)), -1)\n",
    "        w, h = 512, 512\n",
    "        zero_data = np.zeros((h, w), dtype=np.uint8)\n",
    "#         image2 = np.stack((\n",
    "#             np.array(image_yellow_ch),\n",
    "#             zero_data, zero_data), -1)\n",
    "#         print(image1.shape, image2.shape)\n",
    "#         image = np.vstack((image1, image2))\n",
    "        image = cv2.resize(image, (shape[0], shape[1]))\n",
    "        return image\n",
    "\n",
    "    def augment(image):\n",
    "        augment_img = iaa.Sequential([\n",
    "            iaa.OneOf([\n",
    "                iaa.Affine(rotate=0),\n",
    "                iaa.Affine(rotate=90),\n",
    "                iaa.Affine(rotate=180),\n",
    "                iaa.Affine(rotate=270),\n",
    "                iaa.Fliplr(0.5),\n",
    "                iaa.Flipud(0.5),\n",
    "            ])], random_order=True)\n",
    "\n",
    "        image_aug = augment_img.augment_image(image)\n",
    "        return image_aug\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, GlobalMaxPooling2D, BatchNormalization, Input, Conv2D\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import metrics\n",
    "from keras.optimizers import Adam \n",
    "from keras import backend as K\n",
    "import keras\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape, n_out):\n",
    "    input_tensor = Input(shape=input_shape)\n",
    "    base_model = InceptionV3(include_top=False,\n",
    "                   weights='imagenet',\n",
    "                   input_shape=input_shape)\n",
    "    bn = BatchNormalization()(input_tensor)\n",
    "    x = base_model(bn)\n",
    "    x = Conv2D(32, kernel_size=(1,1), activation='relu')(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(n_out, activation='sigmoid')(x)\n",
    "    model = Model(input_tensor, output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.ops import array_ops\n",
    "\n",
    "# https://github.com/ailias/Focal-Loss-implement-on-Tensorflow/blob/master/focal_loss.py\n",
    "def focal_loss_org(prediction_tensor, target_tensor, weights=None, alpha=0.25, gamma=2):\n",
    "    r\"\"\"Compute focal loss for predictions.\n",
    "        Multi-labels Focal loss formula:\n",
    "            FL = -alpha * (z-p)^gamma * log(p) -(1-alpha) * p^gamma * log(1-p)\n",
    "                 ,which alpha = 0.25, gamma = 2, p = sigmoid(x), z = target_tensor.\n",
    "    Args:\n",
    "     prediction_tensor: A float tensor of shape [batch_size, num_anchors,\n",
    "        num_classes] representing the predicted logits for each class\n",
    "     target_tensor: A float tensor of shape [batch_size, num_anchors,\n",
    "        num_classes] representing one-hot encoded classification targets\n",
    "     weights: A float tensor of shape [batch_size, num_anchors]\n",
    "     alpha: A scalar tensor for focal loss alpha hyper-parameter\n",
    "     gamma: A scalar tensor for focal loss gamma hyper-parameter\n",
    "    Returns:\n",
    "        loss: A (scalar) tensor representing the value of the loss function\n",
    "    \"\"\"\n",
    "    sigmoid_p = tf.nn.sigmoid(prediction_tensor)\n",
    "    zeros = array_ops.zeros_like(sigmoid_p, dtype=sigmoid_p.dtype)\n",
    "    \n",
    "    # For poitive prediction, only need consider front part loss, back part is 0;\n",
    "    # target_tensor > zeros <=> z=1, so poitive coefficient = z - p.\n",
    "    pos_p_sub = array_ops.where(target_tensor > zeros, target_tensor - sigmoid_p, zeros)\n",
    "    \n",
    "    # For negative prediction, only need consider back part loss, front part is 0;\n",
    "    # target_tensor > zeros <=> z=1, so negative coefficient = 0.\n",
    "    neg_p_sub = array_ops.where(target_tensor > zeros, zeros, sigmoid_p)\n",
    "    per_entry_cross_ent = - alpha * (pos_p_sub ** gamma) * tf.log(tf.clip_by_value(sigmoid_p, 1e-8, 1.0)) \\\n",
    "                          - (1 - alpha) * (neg_p_sub ** gamma) * tf.log(tf.clip_by_value(1.0 - sigmoid_p, 1e-8, 1.0))\n",
    "    return tf.reduce_sum(per_entry_cross_ent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def focal_loss(weights=None, alpha=0.25, gamma=2):\n",
    "    def focal_loss_my(target_tensor, prediction_tensor, ):\n",
    "        r\"\"\"Compute focal loss for predictions.\n",
    "            Multi-labels Focal loss formula:\n",
    "                FL = -alpha * (z-p)^gamma * log(p) -(1-alpha) * p^gamma * log(1-p)\n",
    "                     ,which alpha = 0.25, gamma = 2, p = sigmoid(x), z = target_tensor.\n",
    "        Args:\n",
    "         prediction_tensor: A float tensor of shape [batch_size, num_anchors,\n",
    "            num_classes] representing the predicted logits for each class\n",
    "         target_tensor: A float tensor of shape [batch_size, num_anchors,\n",
    "            num_classes] representing one-hot encoded classification targets\n",
    "         weights: A float tensor of shape [batch_size, num_anchors]\n",
    "         alpha: A scalar tensor for focal loss alpha hyper-parameter\n",
    "         gamma: A scalar tensor for focal loss gamma hyper-parameter\n",
    "        Returns:\n",
    "            loss: A (scalar) tensor representing the value of the loss function\n",
    "        \"\"\"\n",
    "        sigmoid_p = tf.nn.sigmoid(prediction_tensor)\n",
    "        zeros = array_ops.zeros_like(sigmoid_p, dtype=sigmoid_p.dtype)\n",
    "\n",
    "        # For poitive prediction, only need consider front part loss, back part is 0;\n",
    "        # target_tensor > zeros <=> z=1, so poitive coefficient = z - p.\n",
    "        pos_p_sub = array_ops.where(target_tensor > zeros, target_tensor - sigmoid_p, zeros)\n",
    "\n",
    "        # For negative prediction, only need consider back part loss, front part is 0;\n",
    "        # target_tensor > zeros <=> z=1, so negative coefficient = 0.\n",
    "        neg_p_sub = array_ops.where(target_tensor > zeros, zeros, sigmoid_p)\n",
    "        per_entry_cross_ent = - alpha * (pos_p_sub ** gamma) * tf.log(tf.clip_by_value(sigmoid_p, 1e-8, 1.0)) \\\n",
    "                              - (1 - alpha) * (neg_p_sub ** gamma) * tf.log(tf.clip_by_value(1.0 - sigmoid_p, 1e-8, 1.0))\n",
    "        return tf.reduce_sum(per_entry_cross_ent)\n",
    "#         return K.mean(K.binary_crossentropy(target_tensor, prediction_tensor), axis=-1) + tf.reduce_sum(per_entry_cross_ent)\n",
    "    return focal_loss_my"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def focal_loss_fixed(y_true, y_pred):\n",
    "    gamma = 2.\n",
    "    alpha = 0.25\n",
    "    print(y_pred)\n",
    "    print(y_true)\n",
    "    pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
    "    pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
    "\n",
    "#     pt_1 = K.clip(pt_1, 1e-3, .999)\n",
    "#     pt_0 = K.clip(pt_0, 1e-3, .999)\n",
    "\n",
    "    return -K.sum(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1))-K.sum((1-alpha) * K.pow( pt_0, gamma) * K.log(1. - pt_0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def focal_loss(gamma=2., alpha=.25):\n",
    "#     def focal_loss_fixed(y_true, y_pred):\n",
    "#         pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
    "#         pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
    "\n",
    "#         pt_1 = K.clip(pt_1, 1e-3, .999)\n",
    "#         pt_0 = K.clip(pt_0, 1e-3, .999)\n",
    "\n",
    "#         return -K.sum(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1))-K.sum((1-alpha) * K.pow( pt_0, gamma) * K.log(1. - pt_0))\n",
    "#     return focal_loss_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create callbacks list\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31072,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_info.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1554/1554 [==============================] - 365s 235ms/step - loss: 1.1206 - f1: 0.0373 - val_loss: 1.1880 - val_f1: 0.0393\n",
      "Epoch 2/2\n",
      "1554/1554 [==============================] - 352s 226ms/step - loss: 1.1055 - f1: 0.0490 - val_loss: 1.2991 - val_f1: 0.0289\n",
      "Epoch 1/10\n",
      "1554/1554 [==============================] - 430s 277ms/step - loss: 1.0471 - f1: 0.1076 - val_loss: 0.9681 - val_f1: 0.1936\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.96807, saving model to ../cache/InceptionV3.h5\n",
      "Epoch 2/10\n",
      "1554/1554 [==============================] - 412s 265ms/step - loss: 0.9769 - f1: 0.1726 - val_loss: 0.9112 - val_f1: 0.2385\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.96807 to 0.91122, saving model to ../cache/InceptionV3.h5\n",
      "Epoch 3/10\n",
      "1554/1554 [==============================] - 412s 265ms/step - loss: 0.9343 - f1: 0.2079 - val_loss: 0.8740 - val_f1: 0.2763\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.91122 to 0.87399, saving model to ../cache/InceptionV3.h5\n",
      "Epoch 4/10\n",
      "1554/1554 [==============================] - 411s 265ms/step - loss: 0.9085 - f1: 0.2283 - val_loss: 0.8660 - val_f1: 0.2772\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.87399 to 0.86604, saving model to ../cache/InceptionV3.h5\n",
      "Epoch 5/10\n",
      "1554/1554 [==============================] - 409s 263ms/step - loss: 0.8936 - f1: 0.2380 - val_loss: 0.8597 - val_f1: 0.2867\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.86604 to 0.85974, saving model to ../cache/InceptionV3.h5\n",
      "Epoch 6/10\n",
      "1554/1554 [==============================] - 445s 287ms/step - loss: 0.8789 - f1: 0.2483 - val_loss: 0.8228 - val_f1: 0.3146\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.85974 to 0.82278, saving model to ../cache/InceptionV3.h5\n",
      "Epoch 7/10\n",
      "1554/1554 [==============================] - 450s 290ms/step - loss: 0.8679 - f1: 0.2550 - val_loss: 0.8160 - val_f1: 0.3194\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.82278 to 0.81602, saving model to ../cache/InceptionV3.h5\n",
      "Epoch 8/10\n",
      "1554/1554 [==============================] - 451s 291ms/step - loss: 0.8569 - f1: 0.2633 - val_loss: 0.8173 - val_f1: 0.3258\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.81602\n",
      "Epoch 9/10\n",
      "1554/1554 [==============================] - 449s 289ms/step - loss: 0.8497 - f1: 0.2670 - val_loss: 0.8071 - val_f1: 0.3241\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.81602 to 0.80711, saving model to ../cache/InceptionV3.h5\n",
      "Epoch 10/10\n",
      "1554/1554 [==============================] - 449s 289ms/step - loss: 0.8401 - f1: 0.2747 - val_loss: 0.8226 - val_f1: 0.3202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/6215 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00010: val_loss did not improve from 0.80711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6215/6215 [03:44<00:00, 27.64it/s]\n",
      "11702it [07:09, 27.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1554/1554 [==============================] - 362s 233ms/step - loss: 1.1201 - f1: 0.0390 - val_loss: 1.1805 - val_f1: 0.0297\n",
      "Epoch 2/2\n",
      "1554/1554 [==============================] - 348s 224ms/step - loss: 1.1055 - f1: 0.0497 - val_loss: 1.1601 - val_f1: 0.0206\n",
      "Epoch 1/10\n",
      "1554/1554 [==============================] - 422s 271ms/step - loss: 1.0513 - f1: 0.1013 - val_loss: 0.9712 - val_f1: 0.1880\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.97124, saving model to ../cache/InceptionV3.h5\n",
      "Epoch 2/10\n",
      "1554/1554 [==============================] - 409s 263ms/step - loss: 0.9847 - f1: 0.1654 - val_loss: 0.9390 - val_f1: 0.2307\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.97124 to 0.93899, saving model to ../cache/InceptionV3.h5\n",
      "Epoch 3/10\n",
      "1554/1554 [==============================] - 406s 261ms/step - loss: 0.9358 - f1: 0.2068 - val_loss: 0.8671 - val_f1: 0.2848\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.93899 to 0.86708, saving model to ../cache/InceptionV3.h5\n",
      "Epoch 4/10\n",
      "1554/1554 [==============================] - 428s 276ms/step - loss: 0.9099 - f1: 0.2259 - val_loss: 0.8467 - val_f1: 0.2993\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.86708 to 0.84671, saving model to ../cache/InceptionV3.h5\n",
      "Epoch 5/10\n",
      "1554/1554 [==============================] - 412s 265ms/step - loss: 0.8899 - f1: 0.2412 - val_loss: 0.8337 - val_f1: 0.3118\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.84671 to 0.83366, saving model to ../cache/InceptionV3.h5\n",
      "Epoch 6/10\n",
      "1554/1554 [==============================] - 411s 265ms/step - loss: 0.8766 - f1: 0.2491 - val_loss: 0.8092 - val_f1: 0.3266\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.83366 to 0.80921, saving model to ../cache/InceptionV3.h5\n",
      "Epoch 7/10\n",
      "1554/1554 [==============================] - 409s 264ms/step - loss: 0.8648 - f1: 0.2564 - val_loss: 0.8364 - val_f1: 0.3063\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.80921\n",
      "Epoch 8/10\n",
      "1554/1554 [==============================] - 411s 265ms/step - loss: 0.8550 - f1: 0.2630 - val_loss: 0.7913 - val_f1: 0.3340\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.80921 to 0.79135, saving model to ../cache/InceptionV3.h5\n",
      "Epoch 9/10\n",
      "1554/1554 [==============================] - 402s 259ms/step - loss: 0.8472 - f1: 0.2687 - val_loss: 0.7978 - val_f1: 0.3375\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.79135\n",
      "Epoch 10/10\n",
      "1554/1554 [==============================] - 446s 287ms/step - loss: 0.8380 - f1: 0.2743 - val_loss: 0.7868 - val_f1: 0.3462\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.79135 to 0.78676, saving model to ../cache/InceptionV3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6215/6215 [03:57<00:00, 26.12it/s]\n",
      "11702it [07:16, 26.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1554/1554 [==============================] - 447s 287ms/step - loss: 1.1206 - f1: 0.0391 - val_loss: 1.2702 - val_f1: 0.0379\n",
      "Epoch 2/2\n",
      "1554/1554 [==============================] - 354s 228ms/step - loss: 1.1049 - f1: 0.0519 - val_loss: 1.1671 - val_f1: 0.0253\n",
      "Epoch 1/10\n",
      "1554/1554 [==============================] - 437s 281ms/step - loss: 1.0546 - f1: 0.1016 - val_loss: 1.0202 - val_f1: 0.1585\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02019, saving model to ../cache/InceptionV3.h5\n",
      "Epoch 2/10\n",
      "1554/1554 [==============================] - 410s 264ms/step - loss: 0.9809 - f1: 0.1684 - val_loss: 0.9338 - val_f1: 0.2217\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.02019 to 0.93380, saving model to ../cache/InceptionV3.h5\n",
      "Epoch 3/10\n",
      "1554/1554 [==============================] - 411s 265ms/step - loss: 0.9361 - f1: 0.2075 - val_loss: 0.8720 - val_f1: 0.2763\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.93380 to 0.87204, saving model to ../cache/InceptionV3.h5\n",
      "Epoch 4/10\n",
      "1554/1554 [==============================] - 413s 265ms/step - loss: 0.9078 - f1: 0.2282 - val_loss: 0.8840 - val_f1: 0.2834\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.87204\n",
      "Epoch 5/10\n",
      "1554/1554 [==============================] - 411s 264ms/step - loss: 0.8890 - f1: 0.2404 - val_loss: 0.8825 - val_f1: 0.2710\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.87204\n",
      "Epoch 6/10\n",
      "1554/1554 [==============================] - 407s 262ms/step - loss: 0.8757 - f1: 0.2503 - val_loss: 0.8101 - val_f1: 0.3260\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.87204 to 0.81014, saving model to ../cache/InceptionV3.h5\n",
      "Epoch 7/10\n",
      "1554/1554 [==============================] - 402s 259ms/step - loss: 0.8658 - f1: 0.2565 - val_loss: 0.8155 - val_f1: 0.3166\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.81014\n",
      "Epoch 8/10\n",
      "1554/1554 [==============================] - 401s 258ms/step - loss: 0.8546 - f1: 0.2639 - val_loss: 0.8096 - val_f1: 0.3272\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.81014 to 0.80963, saving model to ../cache/InceptionV3.h5\n",
      "Epoch 9/10\n",
      "1554/1554 [==============================] - 401s 258ms/step - loss: 0.8454 - f1: 0.2706 - val_loss: 0.7819 - val_f1: 0.3465\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.80963 to 0.78191, saving model to ../cache/InceptionV3.h5\n",
      "Epoch 10/10\n",
      "1554/1554 [==============================] - 401s 258ms/step - loss: 0.8375 - f1: 0.2759 - val_loss: 0.8022 - val_f1: 0.3246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/6214 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00010: val_loss did not improve from 0.78191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6214/6214 [04:11<00:00, 24.67it/s]\n",
      "11702it [07:41, 25.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1554/1554 [==============================] - 367s 236ms/step - loss: 1.1201 - f1: 0.0392 - val_loss: 1.1317 - val_f1: 0.0256\n",
      "Epoch 2/2\n",
      "1554/1554 [==============================] - 350s 225ms/step - loss: 1.1064 - f1: 0.0495 - val_loss: 1.2329 - val_f1: 0.0343\n",
      "Epoch 1/10\n",
      "1554/1554 [==============================] - 429s 276ms/step - loss: 1.0577 - f1: 0.0957 - val_loss: 0.9800 - val_f1: 0.1799\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.98004, saving model to ../cache/InceptionV3.h5\n",
      "Epoch 2/10\n",
      "1554/1554 [==============================] - 403s 259ms/step - loss: 0.9799 - f1: 0.1698 - val_loss: 0.9092 - val_f1: 0.2417\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.98004 to 0.90920, saving model to ../cache/InceptionV3.h5\n",
      "Epoch 3/10\n",
      "1554/1554 [==============================] - 403s 260ms/step - loss: 0.9330 - f1: 0.2086 - val_loss: 0.8686 - val_f1: 0.2786\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.90920 to 0.86858, saving model to ../cache/InceptionV3.h5\n",
      "Epoch 4/10\n",
      "1554/1554 [==============================] - 402s 258ms/step - loss: 0.9033 - f1: 0.2314 - val_loss: 0.8590 - val_f1: 0.2906\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.86858 to 0.85897, saving model to ../cache/InceptionV3.h5\n",
      "Epoch 5/10\n",
      "1554/1554 [==============================] - 403s 259ms/step - loss: 0.8861 - f1: 0.2422 - val_loss: 0.8265 - val_f1: 0.3089\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.85897 to 0.82646, saving model to ../cache/InceptionV3.h5\n",
      "Epoch 6/10\n",
      "1554/1554 [==============================] - 401s 258ms/step - loss: 0.8720 - f1: 0.2535 - val_loss: 0.8301 - val_f1: 0.3093\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.82646\n",
      "Epoch 7/10\n",
      "1554/1554 [==============================] - 402s 259ms/step - loss: 0.8595 - f1: 0.2608 - val_loss: 0.8223 - val_f1: 0.3214\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.82646 to 0.82232, saving model to ../cache/InceptionV3.h5\n",
      "Epoch 8/10\n",
      "1554/1554 [==============================] - 402s 259ms/step - loss: 0.8510 - f1: 0.2654 - val_loss: 0.7956 - val_f1: 0.3402\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.82232 to 0.79557, saving model to ../cache/InceptionV3.h5\n",
      "Epoch 9/10\n",
      "1554/1554 [==============================] - 403s 260ms/step - loss: 0.8416 - f1: 0.2723 - val_loss: 0.7997 - val_f1: 0.3414\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.79557\n",
      "Epoch 10/10\n",
      "1554/1554 [==============================] - 403s 259ms/step - loss: 0.8319 - f1: 0.2791 - val_loss: 0.8111 - val_f1: 0.3252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/6214 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00010: val_loss did not improve from 0.79557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6214/6214 [04:21<00:00, 23.73it/s]\n",
      "11702it [07:56, 24.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1554/1554 [==============================] - 364s 234ms/step - loss: 1.1213 - f1: 0.0363 - val_loss: 1.1416 - val_f1: 0.0298\n",
      "Epoch 2/2\n",
      "1554/1554 [==============================] - 343s 221ms/step - loss: 1.1069 - f1: 0.0470 - val_loss: 1.2961 - val_f1: 0.0269\n",
      "Epoch 1/10\n",
      "1554/1554 [==============================] - 428s 275ms/step - loss: 1.0567 - f1: 0.0970 - val_loss: 0.9788 - val_f1: 0.1771\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.97879, saving model to ../cache/InceptionV3.h5\n",
      "Epoch 2/10\n",
      "1554/1554 [==============================] - 399s 257ms/step - loss: 0.9915 - f1: 0.1599 - val_loss: 0.9339 - val_f1: 0.2184\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.97879 to 0.93393, saving model to ../cache/InceptionV3.h5\n",
      "Epoch 3/10\n",
      "1554/1554 [==============================] - 399s 257ms/step - loss: 0.9439 - f1: 0.2022 - val_loss: 0.9107 - val_f1: 0.2510\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.93393 to 0.91074, saving model to ../cache/InceptionV3.h5\n",
      "Epoch 4/10\n",
      "1554/1554 [==============================] - 399s 257ms/step - loss: 0.9142 - f1: 0.2242 - val_loss: 0.8483 - val_f1: 0.2932\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.91074 to 0.84833, saving model to ../cache/InceptionV3.h5\n",
      "Epoch 5/10\n",
      "1554/1554 [==============================] - 399s 257ms/step - loss: 0.8944 - f1: 0.2367 - val_loss: 0.8285 - val_f1: 0.3101\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.84833 to 0.82847, saving model to ../cache/InceptionV3.h5\n",
      "Epoch 6/10\n",
      "1554/1554 [==============================] - 399s 257ms/step - loss: 0.8800 - f1: 0.2462 - val_loss: 0.8895 - val_f1: 0.2703\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.82847\n",
      "Epoch 7/10\n",
      "1554/1554 [==============================] - 400s 257ms/step - loss: 0.8720 - f1: 0.2521 - val_loss: 0.8481 - val_f1: 0.3059\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.82847\n",
      "Epoch 8/10\n",
      "1554/1554 [==============================] - 399s 257ms/step - loss: 0.8603 - f1: 0.2600 - val_loss: 0.8220 - val_f1: 0.3191\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.82847 to 0.82200, saving model to ../cache/InceptionV3.h5\n",
      "Epoch 9/10\n",
      "1554/1554 [==============================] - 400s 257ms/step - loss: 0.8548 - f1: 0.2629 - val_loss: 0.7947 - val_f1: 0.3414\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.82200 to 0.79474, saving model to ../cache/InceptionV3.h5\n",
      "Epoch 10/10\n",
      "1554/1554 [==============================] - 400s 257ms/step - loss: 0.8470 - f1: 0.2685 - val_loss: 0.7860 - val_f1: 0.3453\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.79474 to 0.78603, saving model to ../cache/InceptionV3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6214/6214 [04:31<00:00, 22.88it/s]\n",
      "11702it [08:09, 23.90it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# split data into train, valid\n",
    "indexes = np.arange(train_dataset_info.shape[0])\n",
    "# np.random.shuffle(indexes)\n",
    "# train_indexes, valid_indexes = train_test_split(indexes, test_size=0.15, random_state=8)\n",
    "n_splits = 5\n",
    "kf = KFold(n_splits=n_splits, random_state=42, shuffle=True)\n",
    "submit = pd.read_csv('../data/sample_submission.csv')\n",
    "\n",
    "# train_generator = data_generator.create_train(\n",
    "#     train_dataset_info[train_indexes], batch_size, (SIZE,SIZE,3), augument=True)\n",
    "# validation_generator = data_generator.create_train(\n",
    "#     train_dataset_info[valid_indexes], 32, (SIZE,SIZE,3), augument=False)\n",
    "\n",
    "oof_class_preds = np.zeros((train_dataset_info.shape[0], 28))\n",
    "sub_class_preds = np.zeros((submit.shape[0], 28))\n",
    "\n",
    "fold_ = 0\n",
    "epochs = 10; batch_size = 16\n",
    "for train_indexes, valid_indexes in kf.split(indexes):\n",
    "    \n",
    "    checkpoint = ModelCheckpoint('../cache/InceptionV3.h5', monitor='val_loss', verbose=1, \n",
    "                                 save_best_only=True, mode='min', save_weights_only = True)\n",
    "    reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, \n",
    "                                       verbose=1, mode='auto', epsilon=0.0001)\n",
    "    early = EarlyStopping(monitor=\"val_loss\", \n",
    "                          mode=\"min\", \n",
    "                          patience=6)\n",
    "    callbacks_list = [checkpoint, early, reduceLROnPlat]\n",
    "\n",
    "\n",
    "    _preds = []\n",
    "    # create train and valid datagens\n",
    "    train_generator = data_generator.create_train(\n",
    "        train_dataset_info[train_indexes], batch_size, (SIZE,SIZE,3), augument=True)\n",
    "    validation_generator = data_generator.create_train(\n",
    "        train_dataset_info[valid_indexes], 32, (SIZE,SIZE,3), augument=False)\n",
    "\n",
    "    # warm up model\n",
    "    model = create_model(\n",
    "        input_shape=(SIZE,SIZE,3), \n",
    "        n_out=28)\n",
    "\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False\n",
    "    model.layers[-1].trainable = True\n",
    "    model.layers[-2].trainable = True\n",
    "    model.layers[-3].trainable = True\n",
    "    model.layers[-4].trainable = True\n",
    "    model.layers[-5].trainable = True\n",
    "    model.layers[-6].trainable = True\n",
    "    \n",
    "    model.compile(\n",
    "        loss=f1_loss, \n",
    "        optimizer=Adam(1e-03),\n",
    "        metrics=[f1])\n",
    "#     model.summary()\n",
    "\n",
    "    model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=np.ceil(float(len(train_indexes)) / float(batch_size)),\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=np.ceil(float(len(valid_indexes)) / float(batch_size)),\n",
    "        epochs=2, \n",
    "        verbose=1)\n",
    "    \n",
    "    # train all layers\n",
    "    epochs=10\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = True\n",
    "    model.compile(loss=f1_loss,\n",
    "                optimizer=Adam(lr=1e-4),\n",
    "                metrics=[f1])\n",
    "    model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=np.ceil(float(len(train_indexes)) / float(batch_size)),\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=np.ceil(float(len(valid_indexes)) / float(batch_size)),\n",
    "        epochs=epochs, \n",
    "        verbose=1,\n",
    "        callbacks=callbacks_list)\n",
    "    \n",
    "    for idx in tqdm(valid_indexes):\n",
    "        item = train_dataset_info[idx]\n",
    "        path = item['path']\n",
    "        labels = item['labels']\n",
    "        image = data_generator.load_image(path, (SIZE,SIZE,3))/255.\n",
    "        score_predict = model.predict(image[np.newaxis])[0]\n",
    "        oof_class_preds[idx] = score_predict\n",
    "    \n",
    "    for idx, name in tqdm(enumerate(submit['Id'])):\n",
    "        path = os.path.join('../data/test/', name)\n",
    "        image = data_generator.load_image(path, (SIZE,SIZE,3))/255.\n",
    "        score_predict = model.predict(image[np.newaxis])[0]\n",
    "        sub_class_preds[idx] += score_predict\n",
    "    fold_ += 1\n",
    "sub_class_preds /= n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oof_class_preds = np.zeros((train_dataset_info.shape[0], 28))\n",
    "# sub_class_preds = np.zeros((submit.shape[0], 28))\n",
    "# score_predict = model.predict(image[np.newaxis])[0]\n",
    "# oof_class_preds[idx] = score_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for train_index, test_index in kf.split(indexes):\n",
    "# ...    print(\"TRAIN:\", train_index, \"TEST:\", test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11702, 28)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_class_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11702/11702 [00:00<00:00, 87471.97it/s]\n"
     ]
    }
   ],
   "source": [
    "predicted = []\n",
    "for line in tqdm(sub_class_preds):\n",
    "    label_predict = np.arange(28)[line>=0.2]\n",
    "    str_predict_label = ' '.join(str(l) for l in label_predict)\n",
    "    predicted.append(str_predict_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11702"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2',\n",
       " '5 6 25',\n",
       " '0 5 21 25',\n",
       " '0 25',\n",
       " '7 25',\n",
       " '4 25',\n",
       " '0 4 25',\n",
       " '0 25',\n",
       " '0',\n",
       " '25',\n",
       " '0 18 25',\n",
       " '3 5',\n",
       " '0 2 25',\n",
       " '7',\n",
       " '23',\n",
       " '0 2 18 25',\n",
       " '2 14',\n",
       " '0 5',\n",
       " '12 14 21',\n",
       " '0 5',\n",
       " '1 6 25',\n",
       " '3 5 24',\n",
       " '0 25',\n",
       " '0 7',\n",
       " '0 4',\n",
       " '0 12 21 25',\n",
       " '0 21',\n",
       " '0 5',\n",
       " '0 25',\n",
       " '0 5',\n",
       " '13 21',\n",
       " '0 19 25',\n",
       " '7 14 16 17 18 21 25',\n",
       " '0 5 25',\n",
       " '0 7 25',\n",
       " '13',\n",
       " '0 21 25',\n",
       " '0 3',\n",
       " '0 21 25',\n",
       " '1',\n",
       " '0 25',\n",
       " '6 25',\n",
       " '0 21 25',\n",
       " '18 19 25',\n",
       " '0 25',\n",
       " '6 7 21 25',\n",
       " '0 2',\n",
       " '0',\n",
       " '6 7 21 25',\n",
       " '0',\n",
       " '0 16 17 25',\n",
       " '0 5',\n",
       " '7 22',\n",
       " '0 25',\n",
       " '3',\n",
       " '0 25',\n",
       " '0 25',\n",
       " '11 12 21 22',\n",
       " '0 25',\n",
       " '0 21 25',\n",
       " '2 22',\n",
       " '0 5 16 21',\n",
       " '0 14 21 25',\n",
       " '7 21 25',\n",
       " '23',\n",
       " '0 18 19 21 25',\n",
       " '2 3 6 21 25',\n",
       " '0 21 25',\n",
       " '0 1 16 25',\n",
       " '0 21 25',\n",
       " '2 3',\n",
       " '0',\n",
       " '14 21',\n",
       " '4',\n",
       " '0 21',\n",
       " '0',\n",
       " '0 4',\n",
       " '0 1 21',\n",
       " '0 25',\n",
       " '0 25',\n",
       " '0 25',\n",
       " '0 25',\n",
       " '0 21 25',\n",
       " '0 21 25',\n",
       " '7 17 18 19',\n",
       " '0 24',\n",
       " '8 20 22 23',\n",
       " '0 21',\n",
       " '14 25',\n",
       " '11 12 14',\n",
       " '0 25',\n",
       " '11 12 21',\n",
       " '23',\n",
       " '13 21',\n",
       " '0 21 25',\n",
       " '0 21 25',\n",
       " '7 17 18 25',\n",
       " '0 7 18 19 25',\n",
       " '24',\n",
       " '0 6 25',\n",
       " '0 25',\n",
       " '23',\n",
       " '21 25',\n",
       " '0 2 23',\n",
       " '7 11',\n",
       " '0 21 25',\n",
       " '0 14 16',\n",
       " '0 11 16 22 24',\n",
       " '7 20',\n",
       " '0 25',\n",
       " '0 2',\n",
       " '1',\n",
       " '14 16 17 18 25',\n",
       " '0 21 22 25',\n",
       " '21 25',\n",
       " '21 23',\n",
       " '0 2 25',\n",
       " '4 25',\n",
       " '6 14 17 25',\n",
       " '5 26',\n",
       " '0 18 19 25',\n",
       " '0 21 25',\n",
       " '2 21 25',\n",
       " '0 7 20 23',\n",
       " '0 2 4',\n",
       " '0',\n",
       " '0 21 25',\n",
       " '25',\n",
       " '0 4',\n",
       " '18 19',\n",
       " '25',\n",
       " '0 21 25',\n",
       " '0',\n",
       " '0',\n",
       " '0 11',\n",
       " '3 5',\n",
       " '0 14 16 25',\n",
       " '0',\n",
       " '0 21',\n",
       " '6 21 25',\n",
       " '0 19',\n",
       " '6 21 25',\n",
       " '0 1 5',\n",
       " '0 5',\n",
       " '0 2 25',\n",
       " '22 26',\n",
       " '0 21 25',\n",
       " '0 6 7 21 25',\n",
       " '0',\n",
       " '6 25',\n",
       " '0 5 23',\n",
       " '7 16 17 18',\n",
       " '0 7',\n",
       " '0 25',\n",
       " '6 7 25',\n",
       " '6 23',\n",
       " '0 7',\n",
       " '0 25',\n",
       " '0 1 21 25',\n",
       " '25',\n",
       " '0 18 19 25',\n",
       " '0 21 25',\n",
       " '0 7 18 24 25',\n",
       " '4 25',\n",
       " '5',\n",
       " '0 23 25',\n",
       " '0 25',\n",
       " '19',\n",
       " '0 21 25',\n",
       " '7 21 25',\n",
       " '5 25',\n",
       " '0 6 21 25',\n",
       " '0 21 25',\n",
       " '21 23',\n",
       " '0 2',\n",
       " '0 25',\n",
       " '21',\n",
       " '0 7 24 25',\n",
       " '0 12 21',\n",
       " '0 2 25',\n",
       " '0 5',\n",
       " '23',\n",
       " '0 16 19',\n",
       " '0 19 24',\n",
       " '14',\n",
       " '0 21 25',\n",
       " '0 21 25',\n",
       " '0 5 25',\n",
       " '1 6 23',\n",
       " '0 14 21 25',\n",
       " '14 17 21 25',\n",
       " '0 25',\n",
       " '5 21',\n",
       " '21 25',\n",
       " '0 5 21 25',\n",
       " '0 13 21 22',\n",
       " '0 25',\n",
       " '16 18 19 21',\n",
       " '23 25',\n",
       " '0 25',\n",
       " '2 21',\n",
       " '0 2 3 25',\n",
       " '0 2 25',\n",
       " '0 25',\n",
       " '0 3 25',\n",
       " '21',\n",
       " '0 21 25',\n",
       " '0 5',\n",
       " '0',\n",
       " '0 21',\n",
       " '0 12 14 16 21',\n",
       " '0 5 22',\n",
       " '7',\n",
       " '0 5',\n",
       " '18 19',\n",
       " '0 21',\n",
       " '24',\n",
       " '7 21',\n",
       " '21 22',\n",
       " '2 3',\n",
       " '0 22',\n",
       " '14 21 25',\n",
       " '21',\n",
       " '2 12 21',\n",
       " '8 20 23',\n",
       " '0 23',\n",
       " '21',\n",
       " '21 25',\n",
       " '0 18 19',\n",
       " '0 5 24',\n",
       " '11 21 25',\n",
       " '0 11',\n",
       " '0 2',\n",
       " '0 23',\n",
       " '0 23 25',\n",
       " '11',\n",
       " '13 22 26',\n",
       " '0 12',\n",
       " '0 25',\n",
       " '0 2 17 18 21 25',\n",
       " '12 21',\n",
       " '2 7',\n",
       " '21 25',\n",
       " '0 21 25',\n",
       " '2 11 14 21 25',\n",
       " '12 23',\n",
       " '25',\n",
       " '4 5',\n",
       " '13 21 22',\n",
       " '0 1',\n",
       " '0 25',\n",
       " '0 25',\n",
       " '2 21 25',\n",
       " '0 2',\n",
       " '0 25',\n",
       " '11',\n",
       " '23',\n",
       " '3 5',\n",
       " '19 25',\n",
       " '12 21',\n",
       " '17 18 21 25',\n",
       " '0 19 26',\n",
       " '0 5',\n",
       " '0 2 5',\n",
       " '12 13 21 22',\n",
       " '0',\n",
       " '12 21 22',\n",
       " '0 2',\n",
       " '0 7 23 25',\n",
       " '0 25',\n",
       " '0 19',\n",
       " '0 25',\n",
       " '0 12',\n",
       " '0 2 25',\n",
       " '2',\n",
       " '0 18 19 25',\n",
       " '0 2',\n",
       " '11',\n",
       " '0 25',\n",
       " '0',\n",
       " '0 25',\n",
       " '0 2 21',\n",
       " '3 25',\n",
       " '8 9 10 13 20 26',\n",
       " '0 19',\n",
       " '0 12 21',\n",
       " '0',\n",
       " '7 24',\n",
       " '0 1 2',\n",
       " '7 11 24',\n",
       " '0 5 7 22',\n",
       " '0 14 16 23',\n",
       " '0 21 25',\n",
       " '7',\n",
       " '0 19',\n",
       " '0 21 25',\n",
       " '0 25',\n",
       " '0 2 25',\n",
       " '0 5 19',\n",
       " '0 2',\n",
       " '0 19 26',\n",
       " '0 3 5',\n",
       " '11 25',\n",
       " '12 14',\n",
       " '25',\n",
       " '0 21',\n",
       " '1',\n",
       " '11 14 16 17 25',\n",
       " '0 21',\n",
       " '0 25',\n",
       " '6 11 25',\n",
       " '7 11 21',\n",
       " '0 7 25',\n",
       " '0',\n",
       " '0 25',\n",
       " '21 25',\n",
       " '14 16 17 18 21 25',\n",
       " '0 3 25',\n",
       " '0 25',\n",
       " '0 16 17 25',\n",
       " '19 26',\n",
       " '6 25',\n",
       " '0 21 25',\n",
       " '0 2',\n",
       " '0',\n",
       " '0 2 7 18 24',\n",
       " '21 22',\n",
       " '0 2',\n",
       " '0 2 3',\n",
       " '0 14 16',\n",
       " '5',\n",
       " '3 5 19 25',\n",
       " '25',\n",
       " '0 1 21',\n",
       " '0 12 21 25',\n",
       " '7',\n",
       " '24',\n",
       " '17 21 25',\n",
       " '0 25',\n",
       " '1 6 25',\n",
       " '0 21 25',\n",
       " '0 7 18 24',\n",
       " '0 2 4',\n",
       " '14 16 17',\n",
       " '4 12 21 25',\n",
       " '0 2 3 25',\n",
       " '18 19 24',\n",
       " '2 3 7',\n",
       " '0 2 21 25',\n",
       " '0 25',\n",
       " '0 7',\n",
       " '9 19 20 26',\n",
       " '0 25',\n",
       " '0 5 19 21',\n",
       " '0 25',\n",
       " '3',\n",
       " '0 7 24',\n",
       " '0 4 5 21',\n",
       " '21 25',\n",
       " '0 2 4 23',\n",
       " '11 24 25',\n",
       " '2 6 25',\n",
       " '0 25',\n",
       " '0 25',\n",
       " '7',\n",
       " '11 21',\n",
       " '11',\n",
       " '0',\n",
       " '0 18 19 21 25',\n",
       " '0 1 5',\n",
       " '17 18 21 25',\n",
       " '0 1 25',\n",
       " '0 21 25',\n",
       " '21 25',\n",
       " '0 23 25',\n",
       " '0 12 21 25',\n",
       " '0',\n",
       " '0 3 25',\n",
       " '12 21',\n",
       " '4 13 21 25',\n",
       " '0 13 21',\n",
       " '2 7',\n",
       " '0',\n",
       " '0 2 21 25',\n",
       " '0 4 5',\n",
       " '14 16 17 21 25',\n",
       " '0',\n",
       " '2 3',\n",
       " '18 19',\n",
       " '0 21 25',\n",
       " '7 14 16 17 18 25',\n",
       " '0 25',\n",
       " '0 14 16',\n",
       " '0 21 25',\n",
       " '0 5 19',\n",
       " '0 19',\n",
       " '0 21',\n",
       " '0 11 21 25',\n",
       " '14 21 25',\n",
       " '0 12',\n",
       " '12 13 21 25',\n",
       " '0',\n",
       " '21 25',\n",
       " '0 12 14 21',\n",
       " '0 21 22 25',\n",
       " '0 2 23 25',\n",
       " '0 13 23',\n",
       " '26',\n",
       " '0 21 25',\n",
       " '1 11 21',\n",
       " '6 25',\n",
       " '0 21',\n",
       " '23',\n",
       " '7',\n",
       " '0 25',\n",
       " '0',\n",
       " '0 13 21 25',\n",
       " '0 25',\n",
       " '0 21 25',\n",
       " '0 7 24',\n",
       " '0 7 25',\n",
       " '0 2 5',\n",
       " '21 23 25',\n",
       " '0 2 3 4 25',\n",
       " '0 21 25',\n",
       " '0 7 25',\n",
       " '0 18 25',\n",
       " '0 18 19',\n",
       " '0 3 5 24',\n",
       " '4 21 25',\n",
       " '0 12 21 25',\n",
       " '0 25',\n",
       " '23',\n",
       " '0 14 16',\n",
       " '0 18 25',\n",
       " '0 7 18 21 25',\n",
       " '0 4',\n",
       " '0 21 25',\n",
       " '2',\n",
       " '7',\n",
       " '0 1 14 16',\n",
       " '21 25',\n",
       " '0 11 25',\n",
       " '0 2 21',\n",
       " '0 25',\n",
       " '0 13 21 22 25',\n",
       " '0 19',\n",
       " '18 21 25',\n",
       " '14 16 17 18 25',\n",
       " '0 17 18 21 25',\n",
       " '12 21',\n",
       " '0 2 3',\n",
       " '0 4 21 25',\n",
       " '0 5',\n",
       " '0',\n",
       " '0',\n",
       " '0 3 5 25',\n",
       " '21 25',\n",
       " '6 11 23 25',\n",
       " '0 4',\n",
       " '0 25',\n",
       " '0 21 25',\n",
       " '0 2 3',\n",
       " '0 2 25',\n",
       " '7 20',\n",
       " '13 21',\n",
       " '23 25',\n",
       " '0 2 23',\n",
       " '0 2 11',\n",
       " '7 11',\n",
       " '2 3',\n",
       " '2 23 25',\n",
       " '0 2',\n",
       " '0 21 25',\n",
       " '14 17 21 25',\n",
       " '3 4 5',\n",
       " '0 25',\n",
       " '0 21 25',\n",
       " '6 25',\n",
       " '4',\n",
       " '14',\n",
       " '0 21 25',\n",
       " '4',\n",
       " '0 7',\n",
       " '0 21 22',\n",
       " '0 21 25',\n",
       " '25',\n",
       " '0 13 21',\n",
       " '4',\n",
       " '0 1',\n",
       " '0 25',\n",
       " '21 25',\n",
       " '0 25',\n",
       " '2 3 6 21 25',\n",
       " '0 25',\n",
       " '7 23',\n",
       " '12 21',\n",
       " '0 7',\n",
       " '0 23',\n",
       " '0 18 19 25',\n",
       " '21 25',\n",
       " '2',\n",
       " '0',\n",
       " '21 25',\n",
       " '21',\n",
       " '0',\n",
       " '0 21 25',\n",
       " '2 7 25',\n",
       " '0 7 25',\n",
       " '0 7',\n",
       " '0 21 25',\n",
       " '0 7 21 25',\n",
       " '12 13',\n",
       " '0 21 25',\n",
       " '0 13 21 22 25',\n",
       " '21 25',\n",
       " '7',\n",
       " '0 21 25',\n",
       " '21 25',\n",
       " '3',\n",
       " '26',\n",
       " '0 25',\n",
       " '0 1 2 25',\n",
       " '0 6 25',\n",
       " '0',\n",
       " '19 21 25',\n",
       " '0 4 5',\n",
       " '0 7',\n",
       " '0 25',\n",
       " '21',\n",
       " '18 19',\n",
       " '0 21 25',\n",
       " '0 17 25',\n",
       " '0 14 17 18 21 25',\n",
       " '4 25',\n",
       " '0 14 16 17',\n",
       " '2 3 25',\n",
       " '19',\n",
       " '0 25',\n",
       " '18 19',\n",
       " '12',\n",
       " '0 21',\n",
       " '0 5',\n",
       " '0',\n",
       " '0 25',\n",
       " '7 11',\n",
       " '4',\n",
       " '0 25',\n",
       " '2 21 25',\n",
       " '0 2',\n",
       " '6 23',\n",
       " '14',\n",
       " '0 2 25',\n",
       " '0 11 12 25',\n",
       " '2 7 21 25',\n",
       " '21',\n",
       " '12 21',\n",
       " '0 25',\n",
       " '0 17 18 21 25',\n",
       " '0 21 25',\n",
       " '0 7',\n",
       " '0 21',\n",
       " '21 23',\n",
       " '0 2 7',\n",
       " '0 18 25',\n",
       " '0 21 25',\n",
       " '0 2 21 25',\n",
       " '0 25',\n",
       " '6 25',\n",
       " '0 23 25',\n",
       " '7 25',\n",
       " '0 25',\n",
       " '6 14 25',\n",
       " '0 5',\n",
       " '7 21 24 25',\n",
       " '24',\n",
       " '0 16 17 25',\n",
       " '7',\n",
       " '0',\n",
       " '21 25',\n",
       " '0 25',\n",
       " '21 25',\n",
       " '6 11 21 25',\n",
       " '5 18 19 21 25',\n",
       " '21',\n",
       " '0 25',\n",
       " '21',\n",
       " '4',\n",
       " '23',\n",
       " '12 21 22',\n",
       " '0 7 19',\n",
       " '0 5 23',\n",
       " '0 13 22',\n",
       " '6 25',\n",
       " '21 22 25',\n",
       " '0 25',\n",
       " '0 13 19',\n",
       " '2 3',\n",
       " '2 14 16',\n",
       " '11',\n",
       " '0 21 25',\n",
       " '0 1 2',\n",
       " '23',\n",
       " '0 25',\n",
       " '0 21 25',\n",
       " '0 5 21 25',\n",
       " '0',\n",
       " '18 19',\n",
       " '0 4 7',\n",
       " '0 12 13 21',\n",
       " '0 25',\n",
       " '7 21 25',\n",
       " '0 7',\n",
       " '12 21',\n",
       " '5 19',\n",
       " '5 21',\n",
       " '23',\n",
       " '1 21',\n",
       " '0 25',\n",
       " '5 7',\n",
       " '21 23 25',\n",
       " '3 5',\n",
       " '0 12',\n",
       " '11 14 16',\n",
       " '23 25',\n",
       " '0 21',\n",
       " '5 21 22',\n",
       " '21 22',\n",
       " '0 25',\n",
       " '25',\n",
       " '0 12 21',\n",
       " '0 25',\n",
       " '0 7 21',\n",
       " '0 21 25',\n",
       " '3 5 25',\n",
       " '14 16 17',\n",
       " '0 7 18',\n",
       " '0 18 19',\n",
       " '5',\n",
       " '0',\n",
       " '0 5 12 21',\n",
       " '13',\n",
       " '0',\n",
       " '23 25',\n",
       " '0 7',\n",
       " '6 11 12 21 25',\n",
       " '0 1 25',\n",
       " '21 25',\n",
       " '0 5 25',\n",
       " '25 26',\n",
       " '21 25',\n",
       " '0 21 25',\n",
       " '0 21',\n",
       " '0 2 3 7',\n",
       " '0 2',\n",
       " '5 12 21',\n",
       " '0 25',\n",
       " '0 1 5',\n",
       " '0 1 18 19 21 25',\n",
       " '0 25',\n",
       " '0 18 19',\n",
       " '0',\n",
       " '0 19 22',\n",
       " '0 21 22 25',\n",
       " '0 21 25',\n",
       " '4',\n",
       " '7',\n",
       " '0 5 25',\n",
       " '0 5 6 25',\n",
       " '21 22',\n",
       " '14 16 17 25',\n",
       " '0 21 22',\n",
       " '0 2 21 25',\n",
       " '7',\n",
       " '5 25',\n",
       " '18 19 24',\n",
       " '0 1 21 25',\n",
       " '0 21',\n",
       " '19 26',\n",
       " '7 18 19 25',\n",
       " '23 25',\n",
       " '1 2 25',\n",
       " '0 14 16',\n",
       " '13 22',\n",
       " '0 21 25',\n",
       " '0 21 25',\n",
       " '0 22',\n",
       " '0 4',\n",
       " '0 25',\n",
       " '0 16 21 25',\n",
       " '0 25',\n",
       " '23',\n",
       " '0 21 22',\n",
       " '4',\n",
       " '12 13 21',\n",
       " '0 21 25',\n",
       " '21 25',\n",
       " '0 12 21 25',\n",
       " '0 1 21 25',\n",
       " '0 5 14 21 25',\n",
       " '5',\n",
       " '0',\n",
       " '21 23',\n",
       " '14 16 17',\n",
       " '0 2 3 25',\n",
       " '5 25',\n",
       " '11',\n",
       " '0 7',\n",
       " '0 21 22',\n",
       " '3 24',\n",
       " '0 21 25',\n",
       " '0 25',\n",
       " '21 25',\n",
       " '1 21 25',\n",
       " '7 17 25',\n",
       " '0 21 25',\n",
       " '11 12 21 22',\n",
       " '0 2',\n",
       " '0 3 5',\n",
       " '0 21 25',\n",
       " '0 2 7 18 25',\n",
       " '21',\n",
       " '21 25',\n",
       " '0 25',\n",
       " '19',\n",
       " '0',\n",
       " '0 2 21 25',\n",
       " '0 23',\n",
       " '0 1 2 5',\n",
       " '0 19',\n",
       " '0 21 25',\n",
       " '0 13 21 22 25',\n",
       " '0 5',\n",
       " '0 21 25',\n",
       " '0 2 7',\n",
       " '0 1 2',\n",
       " '0 7',\n",
       " '0 21 25',\n",
       " '0 7 18 21 25',\n",
       " '23',\n",
       " '7 12 13 21',\n",
       " '0 3 21 25',\n",
       " '0 25',\n",
       " '7 21 23 25',\n",
       " '21',\n",
       " '7 21 22 24 25',\n",
       " '0 13',\n",
       " '0 21 25',\n",
       " '0 25',\n",
       " '0 21 25',\n",
       " '0',\n",
       " '23',\n",
       " '0 2 21 25',\n",
       " '0 2',\n",
       " '0 21 25',\n",
       " '0 5',\n",
       " '21 25',\n",
       " '0',\n",
       " '0 21 25',\n",
       " '23',\n",
       " '13 21 25',\n",
       " '0 21 25',\n",
       " '0 2 21 25',\n",
       " '14 16',\n",
       " '7',\n",
       " '12 14 21 25',\n",
       " '0 7 21 25',\n",
       " '18 19 21 25',\n",
       " '7 23',\n",
       " '7 11',\n",
       " '0 7',\n",
       " '7 18 24',\n",
       " '23',\n",
       " '0 21 25',\n",
       " '0 25',\n",
       " '0 25',\n",
       " '14 16 17 25',\n",
       " '23 25',\n",
       " '0 2',\n",
       " '21 25',\n",
       " '0 25',\n",
       " '11 21 23',\n",
       " '14 16 17 21 25',\n",
       " '0 12 21 22',\n",
       " '14 16 17 21 25',\n",
       " '6 14 25',\n",
       " '0 7 18 19 25',\n",
       " '23',\n",
       " '5',\n",
       " '2 7',\n",
       " '7 21 23',\n",
       " '0',\n",
       " '0',\n",
       " '0 7 25',\n",
       " '0 25',\n",
       " '21 25',\n",
       " '0 7 25',\n",
       " '0 12 25',\n",
       " '21 22 25',\n",
       " '0 2 25',\n",
       " '0 18 19 25',\n",
       " '12',\n",
       " '0',\n",
       " '0 25',\n",
       " '0 21',\n",
       " '0 21',\n",
       " '23',\n",
       " '17 18 19 25',\n",
       " '0 25',\n",
       " '0 19',\n",
       " '0 23',\n",
       " '11',\n",
       " '2',\n",
       " '0 7 25',\n",
       " '0 7',\n",
       " '5',\n",
       " '0',\n",
       " '14 16 17 18 21 25',\n",
       " '0 21 25',\n",
       " '0 21 25',\n",
       " '21 25',\n",
       " '0 13 14 16 25',\n",
       " '0 25',\n",
       " '0 25',\n",
       " '0 21 25',\n",
       " '0 21 25',\n",
       " '7 25',\n",
       " '6 25',\n",
       " '6 21 25',\n",
       " '0 21',\n",
       " '21 25',\n",
       " '0 21 25',\n",
       " '0 25',\n",
       " '0 21',\n",
       " '0',\n",
       " '0 25',\n",
       " '3',\n",
       " '0',\n",
       " '0 1 5',\n",
       " '0 2 21',\n",
       " '0 25',\n",
       " '0 5',\n",
       " '0 19',\n",
       " '0 1 5',\n",
       " '7 9 10',\n",
       " '0 26',\n",
       " '0 21 25',\n",
       " '0 21 25',\n",
       " '13 19 21 25',\n",
       " '0 12 21',\n",
       " '0 25',\n",
       " '0 21 25',\n",
       " '14 16 17',\n",
       " '21 25',\n",
       " '0 21 25',\n",
       " '0',\n",
       " '21 25',\n",
       " '0 2',\n",
       " '21',\n",
       " '0 18 19',\n",
       " '21',\n",
       " '0 21 25',\n",
       " '0 2',\n",
       " '0 1',\n",
       " '25',\n",
       " '0 25',\n",
       " '0 5 12 21',\n",
       " '0 25',\n",
       " '0 11 16 24',\n",
       " '0 5 21',\n",
       " '7 11 24',\n",
       " '3 5 25',\n",
       " '0 2',\n",
       " '0 5',\n",
       " '6 11 25',\n",
       " '0',\n",
       " '0 22',\n",
       " '0 21',\n",
       " '12 23',\n",
       " '6 25',\n",
       " '0 23 25',\n",
       " '0 2 25',\n",
       " '21 22',\n",
       " '0 25',\n",
       " '0 25',\n",
       " '12 21',\n",
       " '0 23',\n",
       " '0 23 25',\n",
       " '0 25',\n",
       " '0 21 25',\n",
       " '0 2 18 21 25',\n",
       " '5',\n",
       " '23',\n",
       " '12 21 25',\n",
       " '2 7 25',\n",
       " '0 1 7',\n",
       " '1 6 25',\n",
       " '13 22 26',\n",
       " '0 21 25',\n",
       " '0 25',\n",
       " '0 7',\n",
       " '21 25',\n",
       " '0 13 21 22',\n",
       " '23',\n",
       " '25',\n",
       " '0 14 16 17 21 25',\n",
       " '4',\n",
       " '0 25',\n",
       " '0 5',\n",
       " '18 19 21 25',\n",
       " '0 3',\n",
       " '7 19 25',\n",
       " '0 25',\n",
       " '0',\n",
       " '19 26',\n",
       " '0 7',\n",
       " '14',\n",
       " '21 25',\n",
       " '7 24',\n",
       " '0 2 25',\n",
       " '7',\n",
       " '6 23 25',\n",
       " '0',\n",
       " '7 23 25',\n",
       " '0 25',\n",
       " '0 3 5',\n",
       " '0 21 25',\n",
       " '0 21 25',\n",
       " '0 2 7 25',\n",
       " '0 25',\n",
       " '0 6 21 25',\n",
       " '11 18 19 24 25',\n",
       " '0 4',\n",
       " '0 4',\n",
       " '17 18 21 25',\n",
       " '14 16',\n",
       " '0 21 25',\n",
       " '0 21 22 25',\n",
       " '19',\n",
       " '0 21',\n",
       " '0 7 21 25',\n",
       " '0 21 25',\n",
       " '21',\n",
       " '0 21 25',\n",
       " '1 21 25',\n",
       " '14 17 25',\n",
       " '0 2',\n",
       " '7',\n",
       " '0 25',\n",
       " '0 21 25',\n",
       " '4',\n",
       " '0 25',\n",
       " '0 11 14 16 17 25',\n",
       " '0 2 3 7',\n",
       " '0 17 18 21 25',\n",
       " '4 21 25',\n",
       " '21 25',\n",
       " '0 25',\n",
       " '0 19',\n",
       " '0 5',\n",
       " '0 18 19',\n",
       " '0 11 25',\n",
       " '25',\n",
       " '0 7',\n",
       " '12',\n",
       " '7',\n",
       " '0 7 23',\n",
       " '0 7 25',\n",
       " '0 5 7',\n",
       " '7',\n",
       " '21 25',\n",
       " '0 11 12 21 25',\n",
       " '0 4 25',\n",
       " '0',\n",
       " '0 21 22',\n",
       " '0',\n",
       " '0',\n",
       " '0 16 17 18 25',\n",
       " '0 25',\n",
       " '0 21 25',\n",
       " '2 11 21',\n",
       " '0 1 7 14 16 21',\n",
       " '0 25',\n",
       " '3',\n",
       " '6 21 25',\n",
       " '0 2 3 5 23',\n",
       " '3',\n",
       " '7 18 19 21 25',\n",
       " '23',\n",
       " '5',\n",
       " '0 25',\n",
       " '0 2',\n",
       " '0 1 19',\n",
       " '0 2',\n",
       " '0 2',\n",
       " '5',\n",
       " '0 1 25',\n",
       " '0 21 25',\n",
       " '0 25',\n",
       " '0 25',\n",
       " ...]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit['Predicted'] = predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submit\n",
    "# submit = pd.read_csv('../data/sample_submission.csv')\n",
    "# predicted = []\n",
    "# draw_predict = []\n",
    "# # model.load_weights('../cache/InceptionV3.h5')\n",
    "# for name in tqdm(submit['Id']):\n",
    "#     path = os.path.join('../data/test/', name)\n",
    "#     image = data_generator.load_image(path, (SIZE,SIZE,3))/255.\n",
    "#     score_predict = model.predict(image[np.newaxis])[0]\n",
    "#     draw_predict.append(score_predict)\n",
    "#     label_predict = np.arange(28)[score_predict>=0.2]\n",
    "#     str_predict_label = ' '.join(str(l) for l in label_predict)\n",
    "#     predicted.append(str_predict_label)\n",
    "\n",
    "# submit['Predicted'] = predicted\n",
    "# np.save('../cache/draw_predict_InceptionV3-8.npy', score_predict)\n",
    "# submit.to_csv('../submissions/submit_InceptionV3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv('../submissions/sub11.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/1855095/how-to-create-a-zip-archive-of-a-directory\n",
    "def backup_project_as_zip(project_dir, zip_file):\n",
    "    assert(os.path.isdir(project_dir))\n",
    "    assert(os.path.isdir(os.path.dirname(zip_file)))\n",
    "    shutil.make_archive(zip_file.replace('.zip',''), 'zip', project_dir)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-10-23 06:36:55.828507\n"
     ]
    }
   ],
   "source": [
    "import datetime, shutil\n",
    "now = datetime.datetime.now()\n",
    "print(now)\n",
    "PROJECT_PATH = '/home/watts/lal/Kaggle/kagglehp/scripts_nbs'\n",
    "backup_project_as_zip(PROJECT_PATH, '../cache/code.scripts_nbs.%s.zip'%now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.4.7.1 / client 1.3.8)\n",
      "Successfully submitted to Human Protein Atlas Image ClassificationCPU times: user 254 ms, sys: 195 ms, total: 449 ms\n",
      "Wall time: 12.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!kaggle competitions submit -c human-protein-atlas-image-classification -f ../submissions/sub11.csv -m \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.4.7.1 / client 1.3.8)\r\n",
      "fileName   date                 description  status    publicScore  privateScore  \r\n",
      "---------  -------------------  -----------  --------  -----------  ------------  \r\n",
      "sub11.csv  2018-10-23 01:07:18               complete  0.431        None          \r\n",
      "sub10.csv  2018-10-22 17:16:40               complete  0.336        None          \r\n",
      "sub9.csv   2018-10-21 20:04:09               complete  0.098        None          \r\n",
      "sub9.csv   2018-10-21 19:44:17               complete  0.073        None          \r\n",
      "sub9.csv   2018-10-21 19:37:30               complete  0.043        None          \r\n",
      "sub9.csv   2018-10-21 19:27:51               complete  0.000        None          \r\n",
      "sub8.csv   2018-10-20 20:08:45               complete  0.422        None          \r\n",
      "sub7.csv   2018-10-20 17:06:09               complete  0.389        None          \r\n",
      "sub5.csv   2018-10-19 18:27:33               complete  0.387        None          \r\n",
      "sub4.csv   2018-10-19 14:45:15               complete  0.411        None          \r\n",
      "sub3.csv   2018-10-19 10:19:26               complete  0.377        None          \r\n",
      "sub2.csv   2018-10-19 08:07:30               complete  0.135        None          \r\n",
      "sub1.csv   2018-10-19 06:28:57               complete  0.374        None          \r\n"
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "sleep(10)\n",
    "!kaggle competitions submissions -c human-protein-atlas-image-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11702/11702 [00:00<00:00, 83018.58it/s]\n"
     ]
    }
   ],
   "source": [
    "predicted = []\n",
    "for line in tqdm(sub_class_preds):\n",
    "    label_predict = np.arange(28)[line>=0.25]\n",
    "    str_predict_label = ' '.join(str(l) for l in label_predict)\n",
    "    predicted.append(str_predict_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit['Predicted'] = predicted\n",
    "submit.to_csv('../submissions/sub12.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-10-23 10:48:02.699601\n"
     ]
    }
   ],
   "source": [
    "import datetime, shutil\n",
    "now = datetime.datetime.now()\n",
    "print(now)\n",
    "PROJECT_PATH = '/home/watts/lal/Kaggle/kagglehp/scripts_nbs'\n",
    "backup_project_as_zip(PROJECT_PATH, '../cache/code.scripts_nbs.%s.zip'%now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.4.7.1 / client 1.3.8)\n",
      "Successfully submitted to Human Protein Atlas Image ClassificationCPU times: user 490 ms, sys: 287 ms, total: 777 ms\n",
      "Wall time: 23.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!kaggle competitions submit -c human-protein-atlas-image-classification -f ../submissions/sub12.csv -m \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.4.7.1 / client 1.3.8)\n",
      "fileName   date                 description  status    publicScore  privateScore  \n",
      "---------  -------------------  -----------  --------  -----------  ------------  \n",
      "sub12.csv  2018-10-23 05:18:36               complete  0.436        None          \n",
      "sub11.csv  2018-10-23 01:07:18               complete  0.431        None          \n",
      "sub10.csv  2018-10-22 17:16:40               complete  0.336        None          \n",
      "sub9.csv   2018-10-21 20:04:09               complete  0.098        None          \n",
      "sub9.csv   2018-10-21 19:44:17               complete  0.073        None          \n",
      "sub9.csv   2018-10-21 19:37:30               complete  0.043        None          \n",
      "sub9.csv   2018-10-21 19:27:51               complete  0.000        None          \n",
      "sub8.csv   2018-10-20 20:08:45               complete  0.422        None          \n",
      "sub7.csv   2018-10-20 17:06:09               complete  0.389        None          \n",
      "sub5.csv   2018-10-19 18:27:33               complete  0.387        None          \n",
      "sub4.csv   2018-10-19 14:45:15               complete  0.411        None          \n",
      "sub3.csv   2018-10-19 10:19:26               complete  0.377        None          \n",
      "sub2.csv   2018-10-19 08:07:30               complete  0.135        None          \n",
      "sub1.csv   2018-10-19 06:28:57               complete  0.374        None          \n"
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "sleep(10)\n",
    "!kaggle competitions submissions -c human-protein-atlas-image-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {0.3:'b', 0.35:'c', 0.4:'d', 0.45:'e', 0.5:'f'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11702/11702 [00:00<00:00, 95851.74it/s]\n",
      "100%|██████████| 11702/11702 [00:00<00:00, 108039.61it/s]\n",
      " 93%|█████████▎| 10837/11702 [00:00<00:00, 108346.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../submissions/sub11-b.csv\n",
      "../submissions/sub11-c.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 11702/11702 [00:00<00:00, 107651.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../submissions/sub11-d.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for alpha in [0.3, 0.35, 0.4]:\n",
    "    predicted = []\n",
    "    for line in tqdm(sub_class_preds):\n",
    "        label_predict = np.arange(28)[line>=alpha]\n",
    "        str_predict_label = ' '.join(str(l) for l in label_predict)\n",
    "        predicted.append(str_predict_label)\n",
    "    submit['Predicted'] = predicted\n",
    "    name = '../submissions/sub11-' + d[alpha] + '.csv'\n",
    "    print(name)\n",
    "    submit.to_csv(name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.4.7.1 / client 1.3.8)\n",
      "Successfully submitted to Human Protein Atlas Image ClassificationCPU times: user 279 ms, sys: 188 ms, total: 467 ms\n",
      "Wall time: 12.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!kaggle competitions submit -c human-protein-atlas-image-classification -f ../submissions/sub11-b.csv -m \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.4.7.1 / client 1.3.8)\r\n",
      "fileName     date                 description  status    publicScore  privateScore  \r\n",
      "-----------  -------------------  -----------  --------  -----------  ------------  \r\n",
      "sub11-b.csv  2018-10-23 05:25:32               complete  0.437        None          \r\n",
      "sub12.csv    2018-10-23 05:18:36               complete  0.436        None          \r\n",
      "sub11.csv    2018-10-23 01:07:18               complete  0.431        None          \r\n",
      "sub10.csv    2018-10-22 17:16:40               complete  0.336        None          \r\n",
      "sub9.csv     2018-10-21 20:04:09               complete  0.098        None          \r\n",
      "sub9.csv     2018-10-21 19:44:17               complete  0.073        None          \r\n",
      "sub9.csv     2018-10-21 19:37:30               complete  0.043        None          \r\n",
      "sub9.csv     2018-10-21 19:27:51               complete  0.000        None          \r\n",
      "sub8.csv     2018-10-20 20:08:45               complete  0.422        None          \r\n",
      "sub7.csv     2018-10-20 17:06:09               complete  0.389        None          \r\n",
      "sub5.csv     2018-10-19 18:27:33               complete  0.387        None          \r\n",
      "sub4.csv     2018-10-19 14:45:15               complete  0.411        None          \r\n",
      "sub3.csv     2018-10-19 10:19:26               complete  0.377        None          \r\n",
      "sub2.csv     2018-10-19 08:07:30               complete  0.135        None          \r\n",
      "sub1.csv     2018-10-19 06:28:57               complete  0.374        None          \r\n"
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "sleep(10)\n",
    "!kaggle competitions submissions -c human-protein-atlas-image-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31072, 28)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof_class_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00070df0-bbc3-11e8-b2bc-ac1f6b6435d0</td>\n",
       "      <td>16 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000a6c98-bb9b-11e8-b2b9-ac1f6b6435d0</td>\n",
       "      <td>7 1 2 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000a9596-bbc4-11e8-b2bc-ac1f6b6435d0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000c99ba-bba4-11e8-b2b9-ac1f6b6435d0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001838f8-bbca-11e8-b2bc-ac1f6b6435d0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Id   Target\n",
       "0  00070df0-bbc3-11e8-b2bc-ac1f6b6435d0     16 0\n",
       "1  000a6c98-bb9b-11e8-b2b9-ac1f6b6435d0  7 1 2 0\n",
       "2  000a9596-bbc4-11e8-b2bc-ac1f6b6435d0        5\n",
       "3  000c99ba-bba4-11e8-b2b9-ac1f6b6435d0        1\n",
       "4  001838f8-bbca-11e8-b2bc-ac1f6b6435d0       18"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31072, 2)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31072, 28)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_classes = 28\n",
    "y_train = np.zeros(oof_class_preds.shape)\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31072/31072 [00:00<00:00, 761215.45it/s]\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "for labels in tqdm(data['Target'].str.split(' ')):\n",
    "#     print(labels)\n",
    "    for label in labels:\n",
    "        y_train[idx][int(label)] = 1\n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 1., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 1., 0., 0.],\n",
       "       [1., 0., 1., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 0.30516408800294936\n",
      "0.5 0.3051538272504285\n",
      "0.75 0.3051518822685677\n",
      "1.0 0.3051507429050234\n",
      "------------------\n",
      "0.1 0.3374655589990885\n",
      "0.5 0.33744313624695615\n",
      "0.75 0.3374391064751636\n",
      "1.0 0.3374365528223586\n",
      "------------------\n",
      "0.1 0.3478230052717737\n",
      "0.5 0.3478094213713602\n",
      "0.75 0.34780678970667567\n",
      "1.0 0.3478049883197386\n",
      "------------------\n",
      "0.1 0.2683626869914665\n",
      "0.5 0.268352899140183\n",
      "0.75 0.26835153112706067\n",
      "1.0 0.26835055216969317\n",
      "------------------\n",
      "0.1 0.35815723900035146\n",
      "0.5 0.35815048203003075\n",
      "0.75 0.35814891018769357\n",
      "1.0 0.358147739540993\n",
      "------------------\n",
      "0.1 0.22794961526676827\n",
      "0.5 0.2279078050326938\n",
      "0.75 0.22789955736433287\n",
      "1.0 0.22789429905693348\n",
      "------------------\n",
      "0.1 0.1489416133060476\n",
      "0.5 0.14893490102819695\n",
      "0.75 0.14893130098979046\n",
      "1.0 0.14892760759756607\n",
      "------------------\n",
      "0.1 0.3187985084046536\n",
      "0.5 0.3187129546214597\n",
      "0.75 0.31869812554763033\n",
      "1.0 0.31868961998265277\n",
      "------------------\n",
      "0.1 0.058919401412568344\n",
      "0.5 0.05882704633553349\n",
      "0.75 0.05875189987664576\n",
      "1.0 0.058667325243741186\n",
      "------------------\n",
      "0.1 0.07156615804290622\n",
      "0.5 0.07126853113559695\n",
      "0.75 0.07114270096439868\n",
      "1.0 0.07102207063561539\n",
      "------------------\n",
      "0.1 0.06559085371180973\n",
      "0.5 0.06525100734222178\n",
      "0.75 0.06504384705631672\n",
      "1.0 0.0648313943033505\n",
      "------------------\n",
      "0.1 0.29730807295334705\n",
      "0.5 0.297301140773105\n",
      "0.75 0.29729961303613406\n",
      "1.0 0.29729853739572365\n",
      "------------------\n",
      "0.1 0.19265048634247706\n",
      "0.5 0.1926452315425764\n",
      "0.75 0.19264412737004155\n",
      "1.0 0.19264334473553268\n",
      "------------------\n",
      "0.1 0.1748069164585282\n",
      "0.5 0.17478356028400102\n",
      "0.75 0.17476578474136595\n",
      "1.0 0.17474727494423503\n",
      "------------------\n",
      "0.1 0.43803229207332933\n",
      "0.5 0.4380307918749215\n",
      "0.75 0.43803014288665315\n",
      "1.0 0.4380293723259563\n",
      "------------------\n",
      "0.1 0.0016208068563269284\n",
      "0.5 0.0016163966773466987\n",
      "0.75 0.0016155744275534456\n",
      "1.0 0.00161507349089407\n",
      "------------------\n",
      "0.1 0.04558853246204809\n",
      "0.5 0.04554502188513587\n",
      "0.75 0.045536490517141696\n",
      "1.0 0.04553106759841841\n",
      "------------------\n",
      "0.1 0.05816076634096368\n",
      "0.5 0.058108272616448124\n",
      "0.75 0.05809704454806286\n",
      "1.0 0.05808928716012451\n",
      "------------------\n",
      "0.1 0.14208904234077158\n",
      "0.5 0.1420849131331977\n",
      "0.75 0.14208374111057687\n",
      "1.0 0.14208258100291293\n",
      "------------------\n",
      "0.1 0.19295768243802502\n",
      "0.5 0.19294281489982212\n",
      "0.75 0.1929390098982947\n",
      "1.0 0.19293606522939977\n",
      "------------------\n",
      "0.1 0.07111900207059951\n",
      "0.5 0.07102736351614891\n",
      "0.75 0.07095020179710965\n",
      "1.0 0.07086671256860966\n",
      "------------------\n",
      "0.1 0.23888927869855436\n",
      "0.5 0.23888189324608725\n",
      "0.75 0.23888070032259182\n",
      "1.0 0.23887992644699105\n",
      "------------------\n",
      "0.1 0.16972905799179328\n",
      "0.5 0.16954646611666568\n",
      "0.75 0.16951043174174074\n",
      "1.0 0.1694886806232755\n",
      "------------------\n",
      "0.1 0.34062597994691424\n",
      "0.5 0.3405976836523227\n",
      "0.75 0.34059218225129834\n",
      "1.0 0.3405887172820029\n",
      "------------------\n",
      "0.1 0.17499433471107195\n",
      "0.5 0.17496541950975486\n",
      "0.75 0.1749573271216207\n",
      "1.0 0.17495069349445258\n",
      "------------------\n",
      "0.1 0.20889288553887697\n",
      "0.5 0.20887857564836687\n",
      "0.75 0.20887385077125095\n",
      "1.0 0.20886983974791637\n",
      "------------------\n",
      "0.1 0.09619467836456175\n",
      "0.5 0.09611981933143054\n",
      "0.75 0.09609321585505415\n",
      "1.0 0.0960691803777528\n",
      "------------------\n",
      "0.1 0.003184518513993595\n",
      "0.5 0.0026474271420748874\n",
      "0.75 0.0025466184378878376\n",
      "1.0 0.002488337729996015\n",
      "------------------\n"
     ]
    }
   ],
   "source": [
    "sub_ridge_preds = np.zeros(sub_class_preds.shape)\n",
    "from sklearn.linear_model import Ridge\n",
    "for cls in np.arange(n_classes):\n",
    "    for alpha in [0.1, 0.5, 0.75, 1.0]:\n",
    "        y = y_train[:, cls]\n",
    "        X = oof_class_preds\n",
    "        clf = Ridge(alpha=alpha)\n",
    "        clf.fit(X,y)\n",
    "        score_ = clf.score(X, y)\n",
    "        print(alpha, score_)\n",
    "    print('------------------')\n",
    "#         X_test = sub_class_preds[:, cls]\n",
    "#         preds_ = clf.predict(X_test)\n",
    "#         sub_ridge_preds[:,cls] = preds_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_ridge_preds = np.zeros(sub_class_preds.shape)\n",
    "from sklearn.linear_model import Ridge\n",
    "for cls in np.arange(n_classes):\n",
    "    y = y_train[:, cls]\n",
    "    X = oof_class_preds\n",
    "    clf = Ridge(alpha=1.0)\n",
    "    clf.fit(X,y)\n",
    "    X_test = sub_class_preds\n",
    "    preds_ = clf.predict(X_test)\n",
    "    sub_ridge_preds[:,cls] = preds_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00039284e-01, 1.17990415e-03, 9.99636507e-01, ...,\n",
       "        1.29729806e-03, 4.45128300e-05, 1.83242408e-09],\n",
       "       [5.12776233e-02, 6.77042314e-02, 5.64872707e-02, ...,\n",
       "        3.79496768e-01, 4.95238428e-03, 7.19379994e-04],\n",
       "       [9.01414943e-01, 3.52338608e-03, 6.46044161e-03, ...,\n",
       "        8.81369901e-01, 4.51639912e-03, 1.18063125e-04],\n",
       "       ...,\n",
       "       [1.55598224e-02, 1.30675434e-03, 5.59325572e-04, ...,\n",
       "        9.47414422e-03, 2.23753006e-04, 1.62329312e-06],\n",
       "       [4.32646036e-01, 9.83005440e-01, 2.32393433e-02, ...,\n",
       "        1.39799099e-02, 5.22908648e-03, 6.82432909e-06],\n",
       "       [5.79181534e-01, 2.58583431e-03, 6.77158823e-03, ...,\n",
       "        6.30617431e-01, 1.03785092e-02, 2.24508471e-06]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_class_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11702,)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_class_preds[:, 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.45753296e-01,  3.62983644e-02,  8.84358668e-01, ...,\n",
       "         1.94297450e-01,  1.24761124e-02, -3.66673039e-04],\n",
       "       [ 2.77064977e-01,  7.45731031e-02,  1.14356844e-01, ...,\n",
       "         4.52840405e-01,  1.39280828e-02,  1.22852482e-03],\n",
       "       [ 8.62137324e-01,  2.33744613e-02,  9.35121162e-02, ...,\n",
       "         8.06679838e-01,  8.58408516e-03,  8.51189659e-04],\n",
       "       ...,\n",
       "       [ 2.76361021e-01,  3.70848688e-02,  8.74717594e-02, ...,\n",
       "         2.12327144e-01,  1.07031498e-02,  8.76129349e-04],\n",
       "       [ 5.41232295e-01,  8.03546180e-01,  6.54105768e-02, ...,\n",
       "         2.11617752e-01,  1.39038025e-02,  1.00735100e-03],\n",
       "       [ 6.65414781e-01,  3.70336201e-02,  1.09595604e-01, ...,\n",
       "         6.37737230e-01,  1.44159650e-02, -3.23285538e-06]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_ridge_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11702/11702 [00:00<00:00, 94823.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../submissions/sub11-f.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "predicted = []\n",
    "alpha = 0.3\n",
    "for line in tqdm(sub_ridge_preds):\n",
    "    label_predict = np.arange(28)[line>=alpha]\n",
    "    str_predict_label = ' '.join(str(l) for l in label_predict)\n",
    "    predicted.append(str_predict_label)\n",
    "submit['Predicted'] = predicted\n",
    "name = '../submissions/sub11-f.csv'\n",
    "print(name)\n",
    "submit.to_csv(name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.4.7.1 / client 1.3.8)\n",
      "Successfully submitted to Human Protein Atlas Image ClassificationCPU times: user 300 ms, sys: 171 ms, total: 470 ms\n",
      "Wall time: 12.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!kaggle competitions submit -c human-protein-atlas-image-classification -f ../submissions/sub11-f.csv -m \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.4.7.1 / client 1.3.8)\n",
      "fileName     date                 description  status    publicScore  privateScore  \n",
      "-----------  -------------------  -----------  --------  -----------  ------------  \n",
      "sub11-f.csv  2018-10-23 09:11:15               complete  0.358        None          \n",
      "sub11-b.csv  2018-10-23 05:25:32               complete  0.437        None          \n",
      "sub12.csv    2018-10-23 05:18:36               complete  0.436        None          \n",
      "sub11.csv    2018-10-23 01:07:18               complete  0.431        None          \n",
      "sub10.csv    2018-10-22 17:16:40               complete  0.336        None          \n",
      "sub9.csv     2018-10-21 20:04:09               complete  0.098        None          \n",
      "sub9.csv     2018-10-21 19:44:17               complete  0.073        None          \n",
      "sub9.csv     2018-10-21 19:37:30               complete  0.043        None          \n",
      "sub9.csv     2018-10-21 19:27:51               complete  0.000        None          \n",
      "sub8.csv     2018-10-20 20:08:45               complete  0.422        None          \n",
      "sub7.csv     2018-10-20 17:06:09               complete  0.389        None          \n",
      "sub5.csv     2018-10-19 18:27:33               complete  0.387        None          \n",
      "sub4.csv     2018-10-19 14:45:15               complete  0.411        None          \n",
      "sub3.csv     2018-10-19 10:19:26               complete  0.377        None          \n",
      "sub2.csv     2018-10-19 08:07:30               complete  0.135        None          \n",
      "sub1.csv     2018-10-19 06:28:57               complete  0.374        None          \n"
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "sleep(10)\n",
    "!kaggle competitions submissions -c human-protein-atlas-image-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11702/11702 [00:00<00:00, 100564.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../submissions/sub11-g.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "predicted = []\n",
    "alpha = 0.35\n",
    "for line in tqdm(sub_ridge_preds):\n",
    "    label_predict = np.arange(28)[line>=alpha]\n",
    "    str_predict_label = ' '.join(str(l) for l in label_predict)\n",
    "    predicted.append(str_predict_label)\n",
    "submit['Predicted'] = predicted\n",
    "name = '../submissions/sub11-g.csv'\n",
    "print(name)\n",
    "submit.to_csv(name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.4.7.1 / client 1.3.8)\n",
      "Successfully submitted to Human Protein Atlas Image ClassificationWarning: Looks like you're using an outdated API Version, please consider updating (server 1.4.7.1 / client 1.3.8)\n",
      "fileName     date                 description  status    publicScore  privateScore  \n",
      "-----------  -------------------  -----------  --------  -----------  ------------  \n",
      "sub11-g.csv  2018-10-23 09:13:19               complete  0.347        None          \n",
      "sub11-f.csv  2018-10-23 09:11:15               complete  0.358        None          \n",
      "sub11-b.csv  2018-10-23 05:25:32               complete  0.437        None          \n",
      "sub12.csv    2018-10-23 05:18:36               complete  0.436        None          \n",
      "sub11.csv    2018-10-23 01:07:18               complete  0.431        None          \n",
      "sub10.csv    2018-10-22 17:16:40               complete  0.336        None          \n",
      "sub9.csv     2018-10-21 20:04:09               complete  0.098        None          \n",
      "sub9.csv     2018-10-21 19:44:17               complete  0.073        None          \n",
      "sub9.csv     2018-10-21 19:37:30               complete  0.043        None          \n",
      "sub9.csv     2018-10-21 19:27:51               complete  0.000        None          \n",
      "sub8.csv     2018-10-20 20:08:45               complete  0.422        None          \n",
      "sub7.csv     2018-10-20 17:06:09               complete  0.389        None          \n",
      "sub5.csv     2018-10-19 18:27:33               complete  0.387        None          \n",
      "sub4.csv     2018-10-19 14:45:15               complete  0.411        None          \n",
      "sub3.csv     2018-10-19 10:19:26               complete  0.377        None          \n",
      "sub2.csv     2018-10-19 08:07:30               complete  0.135        None          \n",
      "sub1.csv     2018-10-19 06:28:57               complete  0.374        None          \n",
      "CPU times: user 330 ms, sys: 320 ms, total: 650 ms\n",
      "Wall time: 25.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!kaggle competitions submit -c human-protein-atlas-image-classification -f ../submissions/sub11-g.csv -m \"\"\n",
    "from time import sleep\n",
    "sleep(10)\n",
    "!kaggle competitions submissions -c human-protein-atlas-image-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11702/11702 [00:00<00:00, 92276.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../submissions/sub11-h.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "predicted = []\n",
    "alpha = 0.25\n",
    "for line in tqdm(sub_ridge_preds):\n",
    "    label_predict = np.arange(28)[line>=alpha]\n",
    "    str_predict_label = ' '.join(str(l) for l in label_predict)\n",
    "    predicted.append(str_predict_label)\n",
    "submit['Predicted'] = predicted\n",
    "name = '../submissions/sub11-h.csv'\n",
    "print(name)\n",
    "submit.to_csv(name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.4.7.1 / client 1.3.8)\n",
      "Successfully submitted to Human Protein Atlas Image ClassificationWarning: Looks like you're using an outdated API Version, please consider updating (server 1.4.7.1 / client 1.3.8)\n",
      "fileName     date                 description  status    publicScore  privateScore  \n",
      "-----------  -------------------  -----------  --------  -----------  ------------  \n",
      "sub11-h.csv  2018-10-24 00:21:18               complete  0.371        None          \n",
      "sub11-g.csv  2018-10-23 09:13:19               complete  0.347        None          \n",
      "sub11-f.csv  2018-10-23 09:11:15               complete  0.358        None          \n",
      "sub11-b.csv  2018-10-23 05:25:32               complete  0.437        None          \n",
      "sub12.csv    2018-10-23 05:18:36               complete  0.436        None          \n",
      "sub11.csv    2018-10-23 01:07:18               complete  0.431        None          \n",
      "sub10.csv    2018-10-22 17:16:40               complete  0.336        None          \n",
      "sub9.csv     2018-10-21 20:04:09               complete  0.098        None          \n",
      "sub9.csv     2018-10-21 19:44:17               complete  0.073        None          \n",
      "sub9.csv     2018-10-21 19:37:30               complete  0.043        None          \n",
      "sub9.csv     2018-10-21 19:27:51               complete  0.000        None          \n",
      "sub8.csv     2018-10-20 20:08:45               complete  0.422        None          \n",
      "sub7.csv     2018-10-20 17:06:09               complete  0.389        None          \n",
      "sub5.csv     2018-10-19 18:27:33               complete  0.387        None          \n",
      "sub4.csv     2018-10-19 14:45:15               complete  0.411        None          \n",
      "sub3.csv     2018-10-19 10:19:26               complete  0.377        None          \n",
      "sub2.csv     2018-10-19 08:07:30               complete  0.135        None          \n",
      "sub1.csv     2018-10-19 06:28:57               complete  0.374        None          \n",
      "CPU times: user 286 ms, sys: 322 ms, total: 608 ms\n",
      "Wall time: 24.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!kaggle competitions submit -c human-protein-atlas-image-classification -f ../submissions/sub11-h.csv -m \"\"\n",
    "from time import sleep\n",
    "sleep(10)\n",
    "!kaggle competitions submissions -c human-protein-atlas-image-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11702/11702 [00:00<00:00, 87331.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../submissions/sub11-i.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "predicted = []\n",
    "alpha = 0.15\n",
    "for line in tqdm(sub_ridge_preds):\n",
    "    label_predict = np.arange(28)[line>=alpha]\n",
    "    str_predict_label = ' '.join(str(l) for l in label_predict)\n",
    "    predicted.append(str_predict_label)\n",
    "submit['Predicted'] = predicted\n",
    "name = '../submissions/sub11-i.csv'\n",
    "print(name)\n",
    "submit.to_csv(name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.4.7.1 / client 1.3.8)\n",
      "Successfully submitted to Human Protein Atlas Image ClassificationWarning: Looks like you're using an outdated API Version, please consider updating (server 1.4.7.1 / client 1.3.8)\n",
      "fileName     date                 description  status    publicScore  privateScore  \n",
      "-----------  -------------------  -----------  --------  -----------  ------------  \n",
      "sub11-i.csv  2018-10-24 00:24:24               complete  0.389        None          \n",
      "sub11-h.csv  2018-10-24 00:21:18               complete  0.371        None          \n",
      "sub11-g.csv  2018-10-23 09:13:19               complete  0.347        None          \n",
      "sub11-f.csv  2018-10-23 09:11:15               complete  0.358        None          \n",
      "sub11-b.csv  2018-10-23 05:25:32               complete  0.437        None          \n",
      "sub12.csv    2018-10-23 05:18:36               complete  0.436        None          \n",
      "sub11.csv    2018-10-23 01:07:18               complete  0.431        None          \n",
      "sub10.csv    2018-10-22 17:16:40               complete  0.336        None          \n",
      "sub9.csv     2018-10-21 20:04:09               complete  0.098        None          \n",
      "sub9.csv     2018-10-21 19:44:17               complete  0.073        None          \n",
      "sub9.csv     2018-10-21 19:37:30               complete  0.043        None          \n",
      "sub9.csv     2018-10-21 19:27:51               complete  0.000        None          \n",
      "sub8.csv     2018-10-20 20:08:45               complete  0.422        None          \n",
      "sub7.csv     2018-10-20 17:06:09               complete  0.389        None          \n",
      "sub5.csv     2018-10-19 18:27:33               complete  0.387        None          \n",
      "sub4.csv     2018-10-19 14:45:15               complete  0.411        None          \n",
      "sub3.csv     2018-10-19 10:19:26               complete  0.377        None          \n",
      "sub2.csv     2018-10-19 08:07:30               complete  0.135        None          \n",
      "sub1.csv     2018-10-19 06:28:57               complete  0.374        None          \n",
      "CPU times: user 294 ms, sys: 352 ms, total: 646 ms\n",
      "Wall time: 25.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!kaggle competitions submit -c human-protein-atlas-image-classification -f ../submissions/sub11-i.csv -m \"\"\n",
    "from time import sleep\n",
    "sleep(10)\n",
    "!kaggle competitions submissions -c human-protein-atlas-image-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e-06 0.3051675755114847\n",
      "1e-05 0.305144376000422\n",
      "0.0001 0.30505250180682486\n",
      "0.001 0.3041995216261415\n",
      "0.01 0.30132614510411415\n",
      "0.1 0.05535801830147291\n",
      "0.25 0.0\n",
      "0.5 0.0\n",
      "0.75 0.0\n",
      "1.0 0.0\n",
      "------------------\n",
      "1e-06 0.33746889229292953\n",
      "1e-05 0.33741565993666545\n",
      "0.0001 0.3371574485354396\n",
      "0.001 0.335685088699252\n",
      "0.01 0.2863562825647684\n",
      "0.1 0.0\n",
      "0.25 0.0\n",
      "0.5 0.0\n",
      "0.75 0.0\n",
      "1.0 0.0\n",
      "------------------\n",
      "1e-06 0.34782327756674636\n",
      "1e-05 0.3477948032137138\n",
      "0.0001 0.3475776983079414\n",
      "0.001 0.3462152360822507\n",
      "0.01 0.3373824233127851\n",
      "0.1 0.0\n",
      "0.25 0.0\n",
      "0.5 0.0\n",
      "0.75 0.0\n",
      "1.0 0.0\n",
      "------------------\n",
      "1e-06 0.2683562724662605\n",
      "1e-05 0.26834021416647713\n",
      "0.0001 0.2680539319635379\n",
      "0.001 0.2663948313938498\n",
      "0.01 0.2277392538020788\n",
      "0.1 0.0\n",
      "0.25 0.0\n",
      "0.5 0.0\n",
      "0.75 0.0\n",
      "1.0 0.0\n",
      "------------------\n",
      "1e-06 0.3581536893431313\n",
      "1e-05 0.3581301281001904\n",
      "0.0001 0.35799302647738984\n",
      "0.001 0.35711942069347236\n",
      "0.01 0.3317396164094919\n",
      "0.1 0.0\n",
      "0.25 0.0\n",
      "0.5 0.0\n",
      "0.75 0.0\n",
      "1.0 0.0\n",
      "------------------\n",
      "1e-06 0.22798732882065265\n",
      "1e-05 0.2278652173446717\n",
      "0.0001 0.22767122140976578\n",
      "0.001 0.22598968365128658\n",
      "0.01 0.20924105722488695\n",
      "0.1 0.0\n",
      "0.25 0.0\n",
      "0.5 0.0\n",
      "0.75 0.0\n",
      "1.0 0.0\n",
      "------------------\n",
      "1e-06 0.14893696780517018\n",
      "1e-05 0.14886595571325167\n",
      "0.0001 0.14859098359956124\n",
      "0.001 0.14630694221925022\n",
      "0.01 0.06720907460236969\n",
      "0.1 0.0\n",
      "0.25 0.0\n",
      "0.5 0.0\n",
      "0.75 0.0\n",
      "1.0 0.0\n",
      "------------------\n",
      "1e-06 0.31893595300195454\n",
      "1e-05 0.3186517837597468\n",
      "0.0001 0.3184373722003626\n",
      "0.001 0.316891879372877\n",
      "0.01 0.3051699977825922\n",
      "0.1 0.0\n",
      "0.25 0.0\n",
      "0.5 0.0\n",
      "0.75 0.0\n",
      "1.0 0.0\n",
      "------------------\n",
      "1e-06 0.05888448321108741\n",
      "1e-05 0.058327469737790134\n",
      "0.0001 0.05272449166291904\n",
      "0.001 0.0\n",
      "0.01 0.0\n",
      "0.1 0.0\n",
      "0.25 0.0\n",
      "0.5 0.0\n",
      "0.75 0.0\n",
      "1.0 0.0\n",
      "------------------\n",
      "1e-06 0.07142626107463834\n",
      "1e-05 0.07086788755195583\n",
      "0.0001 0.06013056603821898\n",
      "0.001 0.0\n",
      "0.01 0.0\n",
      "0.1 0.0\n",
      "0.25 0.0\n",
      "0.5 0.0\n",
      "0.75 0.0\n",
      "1.0 0.0\n",
      "------------------\n",
      "1e-06 0.06537558611568184\n",
      "1e-05 0.06478064492854585\n",
      "0.0001 0.04913786076530158\n",
      "0.001 0.0\n",
      "0.01 0.0\n",
      "0.1 0.0\n",
      "0.25 0.0\n",
      "0.5 0.0\n",
      "0.75 0.0\n",
      "1.0 0.0\n",
      "------------------\n",
      "1e-06 0.2973045309365189\n",
      "1e-05 0.2972888952357604\n",
      "0.0001 0.2969851133330197\n",
      "0.001 0.29486408925191443\n",
      "0.01 0.22467500039558783\n",
      "0.1 0.0\n",
      "0.25 0.0\n",
      "0.5 0.0\n",
      "0.75 0.0\n",
      "1.0 0.0\n",
      "------------------\n",
      "1e-06 0.19264226439557897\n",
      "1e-05 0.19262773395380262\n",
      "0.0001 0.19209672532940802\n",
      "0.001 0.18811345004126734\n",
      "0.01 0.0801615415636987\n",
      "0.1 0.0\n",
      "0.25 0.0\n",
      "0.5 0.0\n",
      "0.75 0.0\n",
      "1.0 0.0\n",
      "------------------\n",
      "1e-06 0.17479972803064048\n",
      "1e-05 0.17468653649428045\n",
      "0.0001 0.1736764280011318\n",
      "0.001 0.16939907179019298\n",
      "0.01 0.0\n",
      "0.1 0.0\n",
      "0.25 0.0\n",
      "0.5 0.0\n",
      "0.75 0.0\n",
      "1.0 0.0\n",
      "------------------\n",
      "1e-06 0.43803044835818394\n",
      "1e-05 0.4380184537999602\n",
      "0.0001 0.43773593606576766\n",
      "0.001 0.4290576073875303\n",
      "0.01 0.3641271249469153\n",
      "0.1 0.0\n",
      "0.25 0.0\n",
      "0.5 0.0\n",
      "0.75 0.0\n",
      "1.0 0.0\n",
      "------------------\n",
      "1e-06 0.0016101021918309977\n",
      "1e-05 0.0014354216463593472\n",
      "0.0001 8.298634234316093e-05\n",
      "0.001 0.0\n",
      "0.01 0.0\n",
      "0.1 0.0\n",
      "0.25 0.0\n",
      "0.5 0.0\n",
      "0.75 0.0\n",
      "1.0 0.0\n",
      "------------------\n",
      "1e-06 0.04558826179846476\n",
      "1e-05 0.04548904830765887\n",
      "0.0001 0.04510262492565575\n",
      "0.001 0.04032350018548148\n",
      "0.01 0.0\n",
      "0.1 0.0\n",
      "0.25 0.0\n",
      "0.5 0.0\n",
      "0.75 0.0\n",
      "1.0 0.0\n",
      "------------------\n",
      "1e-06 0.05816099655754425\n",
      "1e-05 0.058013537835540085\n",
      "0.0001 0.057260737959396894\n",
      "0.001 0.03928188370469876\n",
      "0.01 0.0\n",
      "0.1 0.0\n",
      "0.25 0.0\n",
      "0.5 0.0\n",
      "0.75 0.0\n",
      "1.0 0.0\n",
      "------------------\n",
      "1e-06 0.14208396705486825\n",
      "1e-05 0.14206922187777238\n",
      "0.0001 0.14149478426953366\n",
      "0.001 0.13871168094140096\n",
      "0.01 0.05342885694664091\n",
      "0.1 0.0\n",
      "0.25 0.0\n",
      "0.5 0.0\n",
      "0.75 0.0\n",
      "1.0 0.0\n",
      "------------------\n",
      "1e-06 0.19295448078921318\n",
      "1e-05 0.19289800713309324\n",
      "0.0001 0.1926525739590167\n",
      "0.001 0.19032474140500688\n",
      "0.01 0.15072189071714037\n",
      "0.1 0.0\n",
      "0.25 0.0\n",
      "0.5 0.0\n",
      "0.75 0.0\n",
      "1.0 0.0\n",
      "------------------\n",
      "1e-06 0.07110766035915073\n",
      "1e-05 0.07076084021342444\n",
      "0.0001 0.06782612142392308\n",
      "0.001 0.03560514288710903\n",
      "0.01 0.0\n",
      "0.1 0.0\n",
      "0.25 0.0\n",
      "0.5 0.0\n",
      "0.75 0.0\n",
      "1.0 0.0\n",
      "------------------\n",
      "1e-06 0.23888549350467503\n",
      "1e-05 0.23887141439708248\n",
      "0.0001 0.23870758608109566\n",
      "0.001 0.23735754207672544\n",
      "0.01 0.23017428681202642\n",
      "0.1 0.0\n",
      "0.25 0.0\n",
      "0.5 0.0\n",
      "0.75 0.0\n",
      "1.0 0.0\n",
      "------------------\n",
      "1e-06 0.16982045315667826\n",
      "1e-05 0.1693789845525724\n",
      "0.0001 0.168659275537832\n",
      "0.001 0.16564107111383375\n",
      "0.01 0.06685878253320177\n",
      "0.1 0.0\n",
      "0.25 0.0\n",
      "0.5 0.0\n",
      "0.75 0.0\n",
      "1.0 0.0\n",
      "------------------\n",
      "1e-06 0.34063847817367654\n",
      "1e-05 0.34057457583602646\n",
      "0.0001 0.340384653774493\n",
      "0.001 0.338563521592113\n",
      "0.01 0.3261527076494335\n",
      "0.1 0.0\n",
      "0.25 0.0\n",
      "0.5 0.0\n",
      "0.75 0.0\n",
      "1.0 0.0\n",
      "------------------\n",
      "1e-06 0.17498068004503786\n",
      "1e-05 0.17489110395660468\n",
      "0.0001 0.1734120979125493\n",
      "0.001 0.16576277701695652\n",
      "0.01 0.0\n",
      "0.1 0.0\n",
      "0.25 0.0\n",
      "0.5 0.0\n",
      "0.75 0.0\n",
      "1.0 0.0\n",
      "------------------\n",
      "1e-06 0.20889804541348111\n",
      "1e-05 0.20886076012979315\n",
      "0.0001 0.20865226150160177\n",
      "0.001 0.20733110623228224\n",
      "0.01 0.20236602001888407\n",
      "0.1 0.0\n",
      "0.25 0.0\n",
      "0.5 0.0\n",
      "0.75 0.0\n",
      "1.0 0.0\n",
      "------------------\n",
      "1e-06 0.09617620964050255\n",
      "1e-05 0.09591479017160132\n",
      "0.0001 0.09466565368540625\n",
      "0.001 0.0824643943754031\n",
      "0.01 0.0\n",
      "0.1 0.0\n",
      "0.25 0.0\n",
      "0.5 0.0\n",
      "0.75 0.0\n",
      "1.0 0.0\n",
      "------------------\n",
      "1e-06 0.0029352503760794457\n",
      "1e-05 0.0019619521666091044\n",
      "0.0001 9.20361667144931e-06\n",
      "0.001 0.0\n",
      "0.01 0.0\n",
      "0.1 0.0\n",
      "0.25 0.0\n",
      "0.5 0.0\n",
      "0.75 0.0\n",
      "1.0 0.0\n",
      "------------------\n"
     ]
    }
   ],
   "source": [
    "sub_ridge_preds = np.zeros(sub_class_preds.shape)\n",
    "from sklearn.linear_model import Lasso\n",
    "for cls in np.arange(n_classes):\n",
    "    for alpha in [1e-6, 0.00001, 0.0001, 0.001, 0.01, 0.1, 0.25, 0.5, 0.75, 1.0]:\n",
    "        y = y_train[:, cls]\n",
    "        X = oof_class_preds\n",
    "        clf = Lasso(alpha=alpha)\n",
    "        clf.fit(X,y)\n",
    "        score_ = clf.score(X, y)\n",
    "        print(alpha, score_)\n",
    "    print('------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_lasso_preds = np.zeros(sub_class_preds.shape)\n",
    "from sklearn.linear_model import Lasso\n",
    "for cls in np.arange(n_classes):\n",
    "    y = y_train[:, cls]\n",
    "    X = oof_class_preds\n",
    "    clf = Lasso(alpha=0.0001)\n",
    "    clf.fit(X,y)\n",
    "    X_test = sub_class_preds\n",
    "    preds_ = clf.predict(X_test)\n",
    "    sub_lasso_preds[:,cls] = preds_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.44429966e-01, 3.29890118e-02, 8.78434195e-01, ...,\n",
       "        1.93262240e-01, 1.03985480e-02, 6.09050269e-04],\n",
       "       [2.79492620e-01, 7.57434899e-02, 1.19624324e-01, ...,\n",
       "        4.50920065e-01, 1.25096596e-02, 6.28292950e-04],\n",
       "       [8.63054324e-01, 2.55347763e-02, 9.50523800e-02, ...,\n",
       "        8.07028056e-01, 1.02366936e-02, 6.19276270e-04],\n",
       "       ...,\n",
       "       [2.77679194e-01, 3.55172235e-02, 8.77119006e-02, ...,\n",
       "        2.10879483e-01, 9.58084540e-03, 6.09106243e-04],\n",
       "       [5.41686191e-01, 7.97803140e-01, 6.48745945e-02, ...,\n",
       "        2.12811326e-01, 1.22223679e-02, 6.10234894e-04],\n",
       "       [6.63490374e-01, 3.29306364e-02, 1.05517794e-01, ...,\n",
       "        6.35244635e-01, 1.37181906e-02, 6.09625472e-04]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_lasso_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11702/11702 [00:00<00:00, 86566.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../submissions/sub11-j.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "predicted = []\n",
    "alpha = 0.2\n",
    "for line in tqdm(sub_lasso_preds):\n",
    "    label_predict = np.arange(28)[line>=alpha]\n",
    "    str_predict_label = ' '.join(str(l) for l in label_predict)\n",
    "    predicted.append(str_predict_label)\n",
    "submit['Predicted'] = predicted\n",
    "name = '../submissions/sub11-j.csv'\n",
    "print(name)\n",
    "submit.to_csv(name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.4.7.1 / client 1.3.8)\n",
      "Successfully submitted to Human Protein Atlas Image ClassificationWarning: Looks like you're using an outdated API Version, please consider updating (server 1.4.7.1 / client 1.3.8)\n",
      "fileName     date                 description  status    publicScore  privateScore  \n",
      "-----------  -------------------  -----------  --------  -----------  ------------  \n",
      "sub11-j.csv  2018-10-24 00:34:46               complete  0.366        None          \n",
      "sub11-j.csv  2018-10-24 00:33:17               complete  0.000        None          \n",
      "sub11-i.csv  2018-10-24 00:24:24               complete  0.389        None          \n",
      "sub11-h.csv  2018-10-24 00:21:18               complete  0.371        None          \n",
      "sub11-g.csv  2018-10-23 09:13:19               complete  0.347        None          \n",
      "sub11-f.csv  2018-10-23 09:11:15               complete  0.358        None          \n",
      "sub11-b.csv  2018-10-23 05:25:32               complete  0.437        None          \n",
      "sub12.csv    2018-10-23 05:18:36               complete  0.436        None          \n",
      "sub11.csv    2018-10-23 01:07:18               complete  0.431        None          \n",
      "sub10.csv    2018-10-22 17:16:40               complete  0.336        None          \n",
      "sub9.csv     2018-10-21 20:04:09               complete  0.098        None          \n",
      "sub9.csv     2018-10-21 19:44:17               complete  0.073        None          \n",
      "sub9.csv     2018-10-21 19:37:30               complete  0.043        None          \n",
      "sub9.csv     2018-10-21 19:27:51               complete  0.000        None          \n",
      "sub8.csv     2018-10-20 20:08:45               complete  0.422        None          \n",
      "sub7.csv     2018-10-20 17:06:09               complete  0.389        None          \n",
      "sub5.csv     2018-10-19 18:27:33               complete  0.387        None          \n",
      "sub4.csv     2018-10-19 14:45:15               complete  0.411        None          \n",
      "sub3.csv     2018-10-19 10:19:26               complete  0.377        None          \n",
      "sub2.csv     2018-10-19 08:07:30               complete  0.135        None          \n",
      "CPU times: user 332 ms, sys: 285 ms, total: 617 ms\n",
      "Wall time: 24.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!kaggle competitions submit -c human-protein-atlas-image-classification -f ../submissions/sub11-j.csv -m \"\"\n",
    "from time import sleep\n",
    "sleep(10)\n",
    "!kaggle competitions submissions -c human-protein-atlas-image-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11702/11702 [00:00<00:00, 92002.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../submissions/sub11-k.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "predicted = []\n",
    "alpha = 0.35\n",
    "for line in tqdm(sub_lasso_preds):\n",
    "    label_predict = np.arange(28)[line>=alpha]\n",
    "    str_predict_label = ' '.join(str(l) for l in label_predict)\n",
    "    predicted.append(str_predict_label)\n",
    "submit['Predicted'] = predicted\n",
    "name = '../submissions/sub11-k.csv'\n",
    "print(name)\n",
    "submit.to_csv(name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.4.7.1 / client 1.3.8)\n",
      "Successfully submitted to Human Protein Atlas Image ClassificationWarning: Looks like you're using an outdated API Version, please consider updating (server 1.4.7.1 / client 1.3.8)\n",
      "fileName     date                 description  status    publicScore  privateScore  \n",
      "-----------  -------------------  -----------  --------  -----------  ------------  \n",
      "sub11-k.csv  2018-10-24 00:35:39               complete  0.346        None          \n",
      "sub11-j.csv  2018-10-24 00:34:46               complete  0.366        None          \n",
      "sub11-j.csv  2018-10-24 00:33:17               complete  0.000        None          \n",
      "sub11-i.csv  2018-10-24 00:24:24               complete  0.389        None          \n",
      "sub11-h.csv  2018-10-24 00:21:18               complete  0.371        None          \n",
      "sub11-g.csv  2018-10-23 09:13:19               complete  0.347        None          \n",
      "sub11-f.csv  2018-10-23 09:11:15               complete  0.358        None          \n",
      "sub11-b.csv  2018-10-23 05:25:32               complete  0.437        None          \n",
      "sub12.csv    2018-10-23 05:18:36               complete  0.436        None          \n",
      "sub11.csv    2018-10-23 01:07:18               complete  0.431        None          \n",
      "sub10.csv    2018-10-22 17:16:40               complete  0.336        None          \n",
      "sub9.csv     2018-10-21 20:04:09               complete  0.098        None          \n",
      "sub9.csv     2018-10-21 19:44:17               complete  0.073        None          \n",
      "sub9.csv     2018-10-21 19:37:30               complete  0.043        None          \n",
      "sub9.csv     2018-10-21 19:27:51               complete  0.000        None          \n",
      "sub8.csv     2018-10-20 20:08:45               complete  0.422        None          \n",
      "sub7.csv     2018-10-20 17:06:09               complete  0.389        None          \n",
      "sub5.csv     2018-10-19 18:27:33               complete  0.387        None          \n",
      "sub4.csv     2018-10-19 14:45:15               complete  0.411        None          \n",
      "sub3.csv     2018-10-19 10:19:26               complete  0.377        None          \n",
      "CPU times: user 298 ms, sys: 320 ms, total: 618 ms\n",
      "Wall time: 24.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!kaggle competitions submit -c human-protein-atlas-image-classification -f ../submissions/sub11-k.csv -m \"\"\n",
    "from time import sleep\n",
    "sleep(10)\n",
    "!kaggle competitions submissions -c human-protein-atlas-image-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e-07 0.30517198624325803\n",
      "1e-06 0.30516774580674744\n",
      "1e-05 0.30514618862874276\n",
      "------------------\n",
      "1e-07 0.3375364786687866\n",
      "1e-06 0.33748254475792866\n",
      "1e-05 0.3374263421478816\n",
      "------------------\n",
      "1e-07 0.34786604052700376\n",
      "1e-06 0.34783322649381787\n",
      "1e-05 0.3477989381724954\n",
      "------------------\n",
      "1e-07 0.26844766758924143\n",
      "1e-06 0.2683777350190989\n",
      "1e-05 0.26834353062419525\n",
      "------------------\n",
      "1e-07 0.3581716622471507\n",
      "1e-06 0.3581573666200002\n",
      "1e-05 0.35813814940153743\n",
      "------------------\n",
      "1e-07 0.22802335031175003\n",
      "1e-06 0.22797847846562522\n",
      "1e-05 0.22787254607824436\n",
      "------------------\n",
      "1e-07 0.1489708539219191\n",
      "1e-06 0.14893858372796565\n",
      "1e-05 0.1489118325409502\n",
      "------------------\n",
      "1e-07 0.3189865683838434\n",
      "1e-06 0.31887587504856074\n",
      "1e-05 0.3187025519995641\n",
      "------------------\n",
      "1e-07 0.05902418921044116\n",
      "1e-06 0.05889336938503854\n",
      "1e-05 0.058526393929919984\n",
      "------------------\n",
      "1e-07 0.07211817873010062\n",
      "1e-06 0.07157435909791265\n",
      "1e-05 0.07110603385724168\n",
      "------------------\n",
      "1e-07 0.0662061253927062\n",
      "1e-06 0.06550217765912292\n",
      "1e-05 0.06514710314094829\n",
      "------------------\n",
      "1e-07 0.2973148514509717\n",
      "1e-06 0.29730882052809326\n",
      "1e-05 0.297294370995801\n",
      "------------------\n",
      "1e-07 0.192660643734337\n",
      "1e-06 0.19264916586698233\n",
      "1e-05 0.19263353271648354\n",
      "------------------\n",
      "1e-07 0.17481463487059815\n",
      "1e-06 0.17480521998831755\n",
      "1e-05 0.1747580458989987\n",
      "------------------\n",
      "1e-07 0.4380373310656992\n",
      "1e-06 0.43803062829169437\n",
      "1e-05 0.4380265645541457\n",
      "------------------\n",
      "1e-07 0.0016219588536906526\n",
      "1e-06 0.0016122294433926765\n",
      "1e-05 0.0015472458649268273\n",
      "------------------\n",
      "1e-07 0.045648383366860834\n",
      "1e-06 0.0455996855413624\n",
      "1e-05 0.045506033097835075\n",
      "------------------\n",
      "1e-07 0.058200023647015604\n",
      "1e-06 0.05817583468019494\n",
      "1e-05 0.05805280365281696\n",
      "------------------\n",
      "1e-07 0.14211115332675361\n",
      "1e-06 0.14208577304361236\n",
      "1e-05 0.14207952791769274\n",
      "------------------\n",
      "1e-07 0.1929833429930593\n",
      "1e-06 0.19296119761006714\n",
      "1e-05 0.19292135410852762\n",
      "------------------\n",
      "1e-07 0.07119211305906825\n",
      "1e-06 0.0711096247949018\n",
      "1e-05 0.07096619427472439\n",
      "------------------\n",
      "1e-07 0.23892834033785446\n",
      "1e-06 0.23889659476821593\n",
      "1e-05 0.2388755925479353\n",
      "------------------\n",
      "1e-07 0.16983402807392645\n",
      "1e-06 0.16981304766250815\n",
      "1e-05 0.1694879132789393\n",
      "------------------\n",
      "1e-07 0.3406597502431118\n",
      "1e-06 0.3406385516578939\n",
      "1e-05 0.34057775738118384\n",
      "------------------\n",
      "1e-07 0.17504512104281356\n",
      "1e-06 0.17499506814818067\n",
      "1e-05 0.17493520519459627\n",
      "------------------\n",
      "1e-07 0.20890352808696233\n",
      "1e-06 0.20889805601291778\n",
      "1e-05 0.2088688169502677\n",
      "------------------\n",
      "1e-07 0.09633721634033376\n",
      "1e-06 0.09621844267293089\n",
      "1e-05 0.09604231711163691\n",
      "------------------\n",
      "1e-07 0.0036035975081282205\n",
      "1e-06 0.0032610313752562403\n",
      "1e-05 0.002078405310611542\n",
      "------------------\n"
     ]
    }
   ],
   "source": [
    "0.1 0.30516408800294936\n",
    "0.5 0.3051538272504285\n",
    "0.75 0.3051518822685677\n",
    "1.0 0.3051507429050234\n",
    "------------------\n",
    "0.1 0.3374655589990885\n",
    "0.5 0.33744313624695615\n",
    "0.75 0.3374391064751636\n",
    "1.0 0.3374365528223586\n",
    "------------------\n",
    "0.1 0.3478230052717737\n",
    "0.5 0.3478094213713602\n",
    "0.75 0.34780678970667567\n",
    "1.0 0.3478049883197386\n",
    "------------------\n",
    "0.1 0.2683626869914665\n",
    "0.5 0.268352899140183\n",
    "0.75 0.26835153112706067\n",
    "1.0 0.26835055216969317\n",
    "------------------\n",
    "0.1 0.35815723900035146\n",
    "0.5 0.35815048203003075\n",
    "0.75 0.35814891018769357\n",
    "1.0 0.358147739540993\n",
    "------------------\n",
    "0.1 0.22794961526676827\n",
    "0.5 0.2279078050326938\n",
    "0.75 0.22789955736433287\n",
    "1.0 0.22789429905693348\n",
    "------------------\n",
    "0.1 0.1489416133060476\n",
    "0.5 0.14893490102819695\n",
    "0.75 0.14893130098979046\n",
    "1.0 0.14892760759756607\n",
    "------------------\n",
    "0.1 0.3187985084046536\n",
    "0.5 0.3187129546214597\n",
    "0.75 0.31869812554763033\n",
    "1.0 0.31868961998265277\n",
    "------------------\n",
    "0.1 0.058919401412568344\n",
    "0.5 0.05882704633553349\n",
    "0.75 0.05875189987664576\n",
    "1.0 0.058667325243741186\n",
    "------------------\n",
    "0.1 0.07156615804290622\n",
    "0.5 0.07126853113559695\n",
    "0.75 0.07114270096439868\n",
    "1.0 0.07102207063561539\n",
    "------------------\n",
    "0.1 0.06559085371180973\n",
    "0.5 0.06525100734222178\n",
    "0.75 0.06504384705631672\n",
    "1.0 0.0648313943033505\n",
    "------------------\n",
    "0.1 0.29730807295334705\n",
    "0.5 0.297301140773105\n",
    "0.75 0.29729961303613406\n",
    "1.0 0.29729853739572365\n",
    "------------------\n",
    "0.1 0.19265048634247706\n",
    "0.5 0.1926452315425764\n",
    "0.75 0.19264412737004155\n",
    "1.0 0.19264334473553268\n",
    "------------------\n",
    "0.1 0.1748069164585282\n",
    "0.5 0.17478356028400102\n",
    "0.75 0.17476578474136595\n",
    "1.0 0.17474727494423503\n",
    "------------------\n",
    "0.1 0.43803229207332933\n",
    "0.5 0.4380307918749215\n",
    "0.75 0.43803014288665315\n",
    "1.0 0.4380293723259563\n",
    "------------------\n",
    "0.1 0.0016208068563269284\n",
    "0.5 0.0016163966773466987\n",
    "0.75 0.0016155744275534456\n",
    "1.0 0.00161507349089407\n",
    "------------------\n",
    "0.1 0.04558853246204809\n",
    "0.5 0.04554502188513587\n",
    "0.75 0.045536490517141696\n",
    "1.0 0.04553106759841841\n",
    "------------------\n",
    "0.1 0.05816076634096368\n",
    "0.5 0.058108272616448124\n",
    "0.75 0.05809704454806286\n",
    "1.0 0.05808928716012451\n",
    "------------------\n",
    "0.1 0.14208904234077158\n",
    "0.5 0.1420849131331977\n",
    "0.75 0.14208374111057687\n",
    "1.0 0.14208258100291293\n",
    "------------------\n",
    "0.1 0.19295768243802502\n",
    "0.5 0.19294281489982212\n",
    "0.75 0.1929390098982947\n",
    "1.0 0.19293606522939977\n",
    "------------------\n",
    "0.1 0.07111900207059951\n",
    "0.5 0.07102736351614891\n",
    "0.75 0.07095020179710965\n",
    "1.0 0.07086671256860966\n",
    "------------------\n",
    "0.1 0.23888927869855436\n",
    "0.5 0.23888189324608725\n",
    "0.75 0.23888070032259182\n",
    "1.0 0.23887992644699105\n",
    "------------------\n",
    "0.1 0.16972905799179328\n",
    "0.5 0.16954646611666568\n",
    "0.75 0.16951043174174074\n",
    "1.0 0.1694886806232755\n",
    "------------------\n",
    "0.1 0.34062597994691424\n",
    "0.5 0.3405976836523227\n",
    "0.75 0.34059218225129834\n",
    "1.0 0.3405887172820029\n",
    "------------------\n",
    "0.1 0.17499433471107195\n",
    "0.5 0.17496541950975486\n",
    "0.75 0.1749573271216207\n",
    "1.0 0.17495069349445258\n",
    "------------------\n",
    "0.1 0.20889288553887697\n",
    "0.5 0.20887857564836687\n",
    "0.75 0.20887385077125095\n",
    "1.0 0.20886983974791637\n",
    "------------------\n",
    "0.1 0.09619467836456175\n",
    "0.5 0.09611981933143054\n",
    "0.75 0.09609321585505415\n",
    "1.0 0.0960691803777528\n",
    "------------------\n",
    "0.1 0.003184518513993595\n",
    "0.5 0.0026474271420748874\n",
    "0.75 0.0025466184378878376\n",
    "1.0 0.002488337729996015\n",
    "------------------\n",
    "\n",
    "sub_ridge_preds = np.zeros(sub_class_preds.shape)\n",
    "from sklearn.linear_model import Ridge\n",
    "for cls in np.arange(n_classes):\n",
    "    y = y_train[:, cls]\n",
    "    X = oof_class_preds\n",
    "    clf = Ridge(alpha=1.0)\n",
    "    clf.fit(X,y)\n",
    "    X_test = sub_class_preds\n",
    "    preds_ = clf.predict(X_test)\n",
    "    sub_ridge_preds[:,cls] = preds_\n",
    "\n",
    "sub_ridge_preds = np.zeros(sub_class_preds.shape)\n",
    "from sklearn.linear_model import ElasticNet\n",
    "for cls in np.arange(n_classes):\n",
    "    for alpha in [1e-7, 1e-6, 0.00001]:\n",
    "        y = y_train[:, cls]\n",
    "        X = oof_class_preds\n",
    "        clf = ElasticNet(alpha=alpha)\n",
    "        clf.fit(X,y)\n",
    "        score_ = clf.score(X, y)\n",
    "        print(alpha, score_)\n",
    "    print('------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hpg",
   "language": "python",
   "name": "hpg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
