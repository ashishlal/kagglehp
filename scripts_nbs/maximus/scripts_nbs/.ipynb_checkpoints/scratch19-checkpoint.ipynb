{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/mathormad/inceptionv3-baseline-lb-0-379/code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.io\n",
    "from skimage.transform import resize\n",
    "from imgaug import augmenters as iaa\n",
    "from tqdm import tqdm\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from sklearn.utils import class_weight, shuffle\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "SIZE = 299"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/rejpalcz/best-loss-function-for-f1-score-metric/notebook\n",
    "import tensorflow as tf\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    y_pred = K.round(y_pred)\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n",
    "\n",
    "def f1_loss(y_true, y_pred):\n",
    "    \n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(K.binary_crossentropy(y_true, y_pred), axis=-1) + (1 - K.mean(f1))\n",
    "\n",
    "def weighted_f1_loss(weights):\n",
    "    def w_f1_loss(y_true, y_pred):\n",
    "        tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "        tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "        fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "        fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "        p = tp / (tp + fp + K.epsilon())\n",
    "        r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "        f1 = 2*p*r / (p+r+K.epsilon())\n",
    "        f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "        return K.mean((weights[:,0]**(1-y_true))*(weights[:,1]**(y_true))*K.binary_crossentropy(y_true, y_pred), axis=-1)\n",
    "    return w_f1_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset info\n",
    "path_to_train = '../data/train/'\n",
    "data = pd.read_csv('../data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00070df0-bbc3-11e8-b2bc-ac1f6b6435d0</td>\n",
       "      <td>16 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000a6c98-bb9b-11e8-b2b9-ac1f6b6435d0</td>\n",
       "      <td>7 1 2 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000a9596-bbc4-11e8-b2bc-ac1f6b6435d0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000c99ba-bba4-11e8-b2b9-ac1f6b6435d0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001838f8-bbca-11e8-b2bc-ac1f6b6435d0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Id   Target\n",
       "0  00070df0-bbc3-11e8-b2bc-ac1f6b6435d0     16 0\n",
       "1  000a6c98-bb9b-11e8-b2b9-ac1f6b6435d0  7 1 2 0\n",
       "2  000a9596-bbc4-11e8-b2bc-ac1f6b6435d0        5\n",
       "3  000c99ba-bba4-11e8-b2b9-ac1f6b6435d0        1\n",
       "4  001838f8-bbca-11e8-b2bc-ac1f6b6435d0       18"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_info = []\n",
    "for name, labels in zip(data['Id'], data['Target'].str.split(' ')):\n",
    "    train_dataset_info.append({\n",
    "        'path':os.path.join(path_to_train, name),\n",
    "        'labels':np.array([int(label) for label in labels])})\n",
    "train_dataset_info = np.array(train_dataset_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([{'path': '../data/train/00070df0-bbc3-11e8-b2bc-ac1f6b6435d0', 'labels': array([16,  0])},\n",
       "       {'path': '../data/train/000a6c98-bb9b-11e8-b2b9-ac1f6b6435d0', 'labels': array([7, 1, 2, 0])},\n",
       "       {'path': '../data/train/000a9596-bbc4-11e8-b2bc-ac1f6b6435d0', 'labels': array([5])},\n",
       "       ...,\n",
       "       {'path': '../data/train/fff189d8-bbab-11e8-b2ba-ac1f6b6435d0', 'labels': array([7])},\n",
       "       {'path': '../data/train/fffdf7e0-bbc4-11e8-b2bc-ac1f6b6435d0', 'labels': array([25,  2, 21])},\n",
       "       {'path': '../data/train/fffe0ffe-bbc0-11e8-b2bb-ac1f6b6435d0', 'labels': array([2, 0])}],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class data_generator:\n",
    "    \n",
    "    def create_train(dataset_info, batch_size, shape, augument=True):\n",
    "        assert shape[2] == 3\n",
    "        while True:\n",
    "            dataset_info = shuffle(dataset_info)\n",
    "            for start in range(0, len(dataset_info), batch_size):\n",
    "                end = min(start + batch_size, len(dataset_info))\n",
    "                batch_images = []\n",
    "                X_train_batch = dataset_info[start:end]\n",
    "                batch_labels = np.zeros((len(X_train_batch), 28))\n",
    "                for i in range(len(X_train_batch)):\n",
    "                    image = data_generator.load_image(\n",
    "                        X_train_batch[i]['path'], shape)   \n",
    "                    if augument:\n",
    "                        image = data_generator.augment(image)\n",
    "                    batch_images.append(image/255.)\n",
    "                    batch_labels[i][X_train_batch[i]['labels']] = 1\n",
    "#                 print(batch_labels)\n",
    "                yield np.array(batch_images, np.float32), batch_labels\n",
    "\n",
    "    def load_image(path, shape):\n",
    "        image_red_ch = Image.open(path+'_red.png')\n",
    "        image_yellow_ch = Image.open(path+'_yellow.png')\n",
    "        image_green_ch = Image.open(path+'_green.png')\n",
    "        image_blue_ch = Image.open(path+'_blue.png')\n",
    "        image = np.stack((\n",
    "            np.array(image_red_ch),\n",
    "            np.array(image_green_ch), \n",
    "            np.array(image_blue_ch)), -1)\n",
    "        w, h = 512, 512\n",
    "        zero_data = np.zeros((h, w), dtype=np.uint8)\n",
    "#         image2 = np.stack((\n",
    "#             np.array(image_yellow_ch),\n",
    "#             zero_data, zero_data), -1)\n",
    "#         print(image1.shape, image2.shape)\n",
    "#         image = np.vstack((image1, image2))\n",
    "        image = cv2.resize(image, (shape[0], shape[1]))\n",
    "        return image\n",
    "\n",
    "    def augment(image):\n",
    "        augment_img = iaa.Sequential([\n",
    "            iaa.OneOf([\n",
    "                iaa.Affine(rotate=0),\n",
    "                iaa.Affine(rotate=90),\n",
    "                iaa.Affine(rotate=180),\n",
    "                iaa.Affine(rotate=270),\n",
    "                iaa.Fliplr(0.5),\n",
    "                iaa.Flipud(0.5),\n",
    "            ])], random_order=True)\n",
    "\n",
    "        image_aug = augment_img.augment_image(image)\n",
    "        return image_aug\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, GlobalMaxPooling2D, BatchNormalization, Input, Conv2D\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import metrics\n",
    "from keras.optimizers import Adam \n",
    "from keras import backend as K\n",
    "import keras\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape, n_out):\n",
    "    input_tensor = Input(shape=input_shape)\n",
    "    base_model = InceptionV3(include_top=False,\n",
    "                   weights='imagenet',\n",
    "                   input_shape=input_shape)\n",
    "    bn = BatchNormalization()(input_tensor)\n",
    "    x = base_model(bn)\n",
    "    x = Conv2D(32, kernel_size=(1,1), activation='relu')(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(n_out, activation='sigmoid')(x)\n",
    "    model = Model(input_tensor, output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.ops import array_ops\n",
    "\n",
    "# https://github.com/ailias/Focal-Loss-implement-on-Tensorflow/blob/master/focal_loss.py\n",
    "def focal_loss_org(prediction_tensor, target_tensor, weights=None, alpha=0.25, gamma=2):\n",
    "    r\"\"\"Compute focal loss for predictions.\n",
    "        Multi-labels Focal loss formula:\n",
    "            FL = -alpha * (z-p)^gamma * log(p) -(1-alpha) * p^gamma * log(1-p)\n",
    "                 ,which alpha = 0.25, gamma = 2, p = sigmoid(x), z = target_tensor.\n",
    "    Args:\n",
    "     prediction_tensor: A float tensor of shape [batch_size, num_anchors,\n",
    "        num_classes] representing the predicted logits for each class\n",
    "     target_tensor: A float tensor of shape [batch_size, num_anchors,\n",
    "        num_classes] representing one-hot encoded classification targets\n",
    "     weights: A float tensor of shape [batch_size, num_anchors]\n",
    "     alpha: A scalar tensor for focal loss alpha hyper-parameter\n",
    "     gamma: A scalar tensor for focal loss gamma hyper-parameter\n",
    "    Returns:\n",
    "        loss: A (scalar) tensor representing the value of the loss function\n",
    "    \"\"\"\n",
    "    sigmoid_p = tf.nn.sigmoid(prediction_tensor)\n",
    "    zeros = array_ops.zeros_like(sigmoid_p, dtype=sigmoid_p.dtype)\n",
    "    \n",
    "    # For poitive prediction, only need consider front part loss, back part is 0;\n",
    "    # target_tensor > zeros <=> z=1, so poitive coefficient = z - p.\n",
    "    pos_p_sub = array_ops.where(target_tensor > zeros, target_tensor - sigmoid_p, zeros)\n",
    "    \n",
    "    # For negative prediction, only need consider back part loss, front part is 0;\n",
    "    # target_tensor > zeros <=> z=1, so negative coefficient = 0.\n",
    "    neg_p_sub = array_ops.where(target_tensor > zeros, zeros, sigmoid_p)\n",
    "    per_entry_cross_ent = - alpha * (pos_p_sub ** gamma) * tf.log(tf.clip_by_value(sigmoid_p, 1e-8, 1.0)) \\\n",
    "                          - (1 - alpha) * (neg_p_sub ** gamma) * tf.log(tf.clip_by_value(1.0 - sigmoid_p, 1e-8, 1.0))\n",
    "    return tf.reduce_sum(per_entry_cross_ent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def focal_loss(weights=None, alpha=0.25, gamma=2):\n",
    "    def focal_loss_my(target_tensor, prediction_tensor, ):\n",
    "        r\"\"\"Compute focal loss for predictions.\n",
    "            Multi-labels Focal loss formula:\n",
    "                FL = -alpha * (z-p)^gamma * log(p) -(1-alpha) * p^gamma * log(1-p)\n",
    "                     ,which alpha = 0.25, gamma = 2, p = sigmoid(x), z = target_tensor.\n",
    "        Args:\n",
    "         prediction_tensor: A float tensor of shape [batch_size, num_anchors,\n",
    "            num_classes] representing the predicted logits for each class\n",
    "         target_tensor: A float tensor of shape [batch_size, num_anchors,\n",
    "            num_classes] representing one-hot encoded classification targets\n",
    "         weights: A float tensor of shape [batch_size, num_anchors]\n",
    "         alpha: A scalar tensor for focal loss alpha hyper-parameter\n",
    "         gamma: A scalar tensor for focal loss gamma hyper-parameter\n",
    "        Returns:\n",
    "            loss: A (scalar) tensor representing the value of the loss function\n",
    "        \"\"\"\n",
    "        sigmoid_p = tf.nn.sigmoid(prediction_tensor)\n",
    "        zeros = array_ops.zeros_like(sigmoid_p, dtype=sigmoid_p.dtype)\n",
    "\n",
    "        # For poitive prediction, only need consider front part loss, back part is 0;\n",
    "        # target_tensor > zeros <=> z=1, so poitive coefficient = z - p.\n",
    "        pos_p_sub = array_ops.where(target_tensor > zeros, target_tensor - sigmoid_p, zeros)\n",
    "\n",
    "        # For negative prediction, only need consider back part loss, front part is 0;\n",
    "        # target_tensor > zeros <=> z=1, so negative coefficient = 0.\n",
    "        neg_p_sub = array_ops.where(target_tensor > zeros, zeros, sigmoid_p)\n",
    "        per_entry_cross_ent = - alpha * (pos_p_sub ** gamma) * tf.log(tf.clip_by_value(sigmoid_p, 1e-8, 1.0)) \\\n",
    "                              - (1 - alpha) * (neg_p_sub ** gamma) * tf.log(tf.clip_by_value(1.0 - sigmoid_p, 1e-8, 1.0))\n",
    "        return tf.reduce_sum(per_entry_cross_ent)\n",
    "#         return K.mean(K.binary_crossentropy(target_tensor, prediction_tensor), axis=-1) + tf.reduce_sum(per_entry_cross_ent)\n",
    "    return focal_loss_my"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def focal_loss_fixed(y_true, y_pred):\n",
    "    gamma = 2.\n",
    "    alpha = 0.25\n",
    "    print(y_pred)\n",
    "    print(y_true)\n",
    "    pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
    "    pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
    "\n",
    "#     pt_1 = K.clip(pt_1, 1e-3, .999)\n",
    "#     pt_0 = K.clip(pt_0, 1e-3, .999)\n",
    "\n",
    "    return -K.sum(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1))-K.sum((1-alpha) * K.pow( pt_0, gamma) * K.log(1. - pt_0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def focal_loss(gamma=2., alpha=.25):\n",
    "#     def focal_loss_fixed(y_true, y_pred):\n",
    "#         pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
    "#         pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
    "\n",
    "#         pt_1 = K.clip(pt_1, 1e-3, .999)\n",
    "#         pt_0 = K.clip(pt_0, 1e-3, .999)\n",
    "\n",
    "#         return -K.sum(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1))-K.sum((1-alpha) * K.pow( pt_0, gamma) * K.log(1. - pt_0))\n",
    "#     return focal_loss_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create callbacks list\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31072,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_info.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31072/31072 [00:00<00:00, 743230.19it/s]\n"
     ]
    }
   ],
   "source": [
    "n_classes = 28\n",
    "y_train = np.zeros((train_dataset_info.shape[0], 28))\n",
    "y_train.shape\n",
    "idx = 0\n",
    "for labels in tqdm(data['Target'].str.split(' ')):\n",
    "#     print(labels)\n",
    "    for label in labels:\n",
    "        y_train[idx][int(label)] = 1\n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31072"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 1., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 1., 0., 0.],\n",
       "       [1., 0., 1., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculating_class_weights(y_true):\n",
    "    from sklearn.utils.class_weight import compute_class_weight\n",
    "    number_dim = np.shape(y_true)[1]\n",
    "    weights = np.empty([number_dim, 2])\n",
    "    for i in range(number_dim):\n",
    "        weights[i] = compute_class_weight('balanced', [0.,1.], y_true[:, i])\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_weight = calculating_class_weights(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indexes = np.arange(train_dataset_info.shape[0])\n",
    "# y = [el['labels'] for el in list(train_dataset_info[indexes])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_weights = class_weight.compute_class_weight('balanced', np.arange(28), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_weighted_loss(weights):\n",
    "#     def weighted_loss(y_true, y_pred):\n",
    "#         return K.mean((weights[:,0]**(1-y_true))*(weights[:,1]**(y_true))*K.binary_crossentropy(y_true, y_pred), axis=-1)\n",
    "#     return weighted_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import Callback\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
    "class Metrics(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "     self.val_f1s = []\n",
    "     self.val_recalls = []\n",
    "     self.val_precisions = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "     val_predict = (np.asarray(self.model.predict(self.model.validation_data[0]))).round()\n",
    "     val_targ = self.model.validation_data[1]\n",
    "     _val_f1 = f1_score(val_targ, val_predict)\n",
    "     _val_recall = recall_score(val_targ, val_predict)\n",
    "     _val_precision = precision_score(val_targ, val_predict)\n",
    "     self.val_f1s.append(_val_f1)\n",
    "     self.val_recalls.append(_val_recall)\n",
    "     self.val_precisions.append(_val_precision)\n",
    "     print(\" — val_f1: %f — val_precision: %f — val_recall %f\" %(_val_f1, _val_precision, _val_recall))\n",
    "     return\n",
    "metrics = Metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1554/1554 [==============================] - 1558s 1s/step - loss: 0.7498 - f1: 0.0757 - val_loss: 0.7097 - val_f1: 0.0422\n",
      "Epoch 2/2\n",
      "1554/1554 [==============================] - 352s 226ms/step - loss: 0.7189 - f1: 0.0725 - val_loss: 0.8937 - val_f1: 0.0818\n",
      "Epoch 1/120\n",
      "1554/1554 [==============================] - 439s 282ms/step - loss: 0.7584 - f1: 0.0802 - val_loss: 0.7211 - val_f1: 0.0790\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.72112, saving model to ../cache/InceptionV3.h5\n",
      "Epoch 2/120\n",
      "1554/1554 [==============================] - 423s 272ms/step - loss: 0.7366 - f1: 0.0779 - val_loss: 0.7114 - val_f1: 0.0678\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.72112 to 0.71144, saving model to ../cache/InceptionV3.h5\n",
      "Epoch 3/120\n",
      "1554/1554 [==============================] - 418s 269ms/step - loss: 0.7204 - f1: 0.0798 - val_loss: 0.9170 - val_f1: 0.0814\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.71144\n",
      "Epoch 4/120\n",
      "1554/1554 [==============================] - 416s 268ms/step - loss: 0.6960 - f1: 0.0845 - val_loss: 0.7617 - val_f1: 0.0879\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.71144\n",
      "Epoch 5/120\n",
      "1554/1554 [==============================] - 413s 266ms/step - loss: 0.7405 - f1: 0.0748 - val_loss: 0.7207 - val_f1: 0.0612\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.71144\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "Epoch 6/120\n",
      "1554/1554 [==============================] - 414s 266ms/step - loss: 0.6947 - f1: 0.0731 - val_loss: 0.7024 - val_f1: 0.0669\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.71144 to 0.70240, saving model to ../cache/InceptionV3.h5\n",
      "Epoch 7/120\n",
      "1554/1554 [==============================] - 412s 265ms/step - loss: 0.7101 - f1: 0.0736 - val_loss: 0.7057 - val_f1: 0.0653\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.70240\n",
      "Epoch 8/120\n",
      "1554/1554 [==============================] - 411s 265ms/step - loss: 0.7082 - f1: 0.0725 - val_loss: 0.7025 - val_f1: 0.0672\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.70240\n",
      "Epoch 9/120\n",
      "1554/1554 [==============================] - 411s 265ms/step - loss: 0.6934 - f1: 0.0755 - val_loss: 0.7003 - val_f1: 0.0680\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.70240 to 0.70033, saving model to ../cache/InceptionV3.h5\n",
      "Epoch 10/120\n",
      "1554/1554 [==============================] - 412s 265ms/step - loss: 0.6953 - f1: 0.0751 - val_loss: 0.6983 - val_f1: 0.0679\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.70033 to 0.69827, saving model to ../cache/InceptionV3.h5\n",
      "Epoch 11/120\n",
      "1554/1554 [==============================] - 413s 265ms/step - loss: 0.6910 - f1: 0.0765 - val_loss: 0.6959 - val_f1: 0.0701\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.69827 to 0.69588, saving model to ../cache/InceptionV3.h5\n",
      "Epoch 12/120\n",
      "1439/1554 [==========================>...] - ETA: 22s - loss: 0.7021 - f1: 0.0777"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-2a211ed92471>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         callbacks=callbacks_list)\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_indexes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hpg/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hpg/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2228\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2229\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2230\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2232\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hpg/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1881\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1883\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1884\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1885\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hpg/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2482\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2483\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hpg/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hpg/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hpg/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hpg/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hpg/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hpg/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# split data into train, valid\n",
    "indexes = np.arange(train_dataset_info.shape[0])\n",
    "# np.random.shuffle(indexes)\n",
    "# train_indexes, valid_indexes = train_test_split(indexes, test_size=0.15, random_state=8)\n",
    "n_splits = 5\n",
    "kf = KFold(n_splits=n_splits, random_state=42, shuffle=True)\n",
    "submit = pd.read_csv('../data/sample_submission.csv')\n",
    "\n",
    "# train_generator = data_generator.create_train(\n",
    "#     train_dataset_info[train_indexes], batch_size, (SIZE,SIZE,3), augument=True)\n",
    "# validation_generator = data_generator.create_train(\n",
    "#     train_dataset_info[valid_indexes], 32, (SIZE,SIZE,3), augument=False)\n",
    "\n",
    "oof_class_preds = np.zeros((train_dataset_info.shape[0], 28))\n",
    "sub_class_preds = np.zeros((submit.shape[0], 28))\n",
    "\n",
    "fold_ = 0\n",
    "epochs = 10; batch_size = 16\n",
    "n_classes = 28\n",
    "for train_indexes, valid_indexes in kf.split(indexes):\n",
    "    \n",
    "#     y_train_fold = np.zeros((train_dataset_info[train_indexes].shape[0], n_classes))\n",
    "#     idx = 0\n",
    "#     my_train = list(train_dataset_info[train_indexes])\n",
    "#     for row in tqdm(my_train):\n",
    "#         path = row['path']\n",
    "#         labels = row['labels']\n",
    "# #         print(path, labels)\n",
    "#         for label in labels:\n",
    "#             y_train_fold[idx][int(label)] = 1\n",
    "#         idx += 1\n",
    "        \n",
    "#     y_valid_fold = np.zeros((train_dataset_info[valid_indexes].shape[0], n_classes))\n",
    "#     idx = 0\n",
    "#     my_valid = list(train_dataset_info[valid_indexes])\n",
    "#     for row in tqdm(my_valid):\n",
    "#         path = row['path']\n",
    "#         labels = row['labels']\n",
    "# #         print(path, labels)\n",
    "#         for label in labels:\n",
    "#             y_valid_fold[idx][int(label)] = 1\n",
    "#         idx += 1\n",
    "    \n",
    "#     train_fold_weights = calculating_class_weights(y_train_fold)\n",
    "#     valid_fold_weights = calculating_class_weights(y_valid_fold)\n",
    "    \n",
    "    checkpoint = ModelCheckpoint('../cache/InceptionV3.h5', monitor='val_loss', verbose=1, \n",
    "                                 save_best_only=True, mode='min', save_weights_only = True)\n",
    "    reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, \n",
    "                                       verbose=1, mode='auto', epsilon=0.0001)\n",
    "    early = EarlyStopping(monitor=\"val_loss\", \n",
    "                          mode=\"min\", \n",
    "                          patience=6)\n",
    "    callbacks_list = [checkpoint, early, reduceLROnPlat, metrics]\n",
    "\n",
    "\n",
    "    _preds = []\n",
    "    # create train and valid datagens\n",
    "    train_generator = data_generator.create_train(\n",
    "        train_dataset_info[train_indexes], batch_size, (SIZE,SIZE,3), augument=True)\n",
    "    validation_generator = data_generator.create_train(\n",
    "        train_dataset_info[valid_indexes], 32, (SIZE,SIZE,3), augument=False)\n",
    "\n",
    "    # warm up model\n",
    "    model = create_model(\n",
    "        input_shape=(SIZE,SIZE,3), \n",
    "        n_out=28)\n",
    "\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False\n",
    "    model.layers[-1].trainable = True\n",
    "    model.layers[-2].trainable = True\n",
    "    model.layers[-3].trainable = True\n",
    "    model.layers[-4].trainable = True\n",
    "    model.layers[-5].trainable = True\n",
    "    model.layers[-6].trainable = True\n",
    "    \n",
    "    \n",
    "    model.compile(\n",
    "        loss=weighted_f1_loss(y_train_weight), \n",
    "        optimizer=Adam(1e-03),\n",
    "        metrics=[f1])\n",
    "#     model.summary()\n",
    "\n",
    "    \n",
    "    model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=np.ceil(float(len(train_indexes)) / float(batch_size)),\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=np.ceil(float(len(valid_indexes)) / float(batch_size)),\n",
    "        epochs=2, \n",
    "        verbose=1)\n",
    "    \n",
    "    # train all layers\n",
    "    epochs=10\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = True\n",
    "    model.compile(loss=weighted_f1_loss(y_train_weight),\n",
    "                optimizer=Adam(lr=1e-4),\n",
    "                metrics=[f1])\n",
    "    model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=np.ceil(float(len(train_indexes)) / float(batch_size)),\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=np.ceil(float(len(valid_indexes)) / float(batch_size)),\n",
    "        epochs=epochs, \n",
    "        verbose=1,\n",
    "        callbacks=callbacks_list)\n",
    "    \n",
    "    for idx in tqdm(valid_indexes):\n",
    "        item = train_dataset_info[idx]\n",
    "        path = item['path']\n",
    "        labels = item['labels']\n",
    "        image = data_generator.load_image(path, (SIZE,SIZE,3))/255.\n",
    "#         model.load_weights('../cache/InceptionV3.h5')\n",
    "        score_predict = model.predict(image[np.newaxis])[0]\n",
    "        oof_class_preds[idx] = score_predict\n",
    "        np.save('../cache/oof_class_preds-19.npy', oof_class_preds)\n",
    "        \n",
    "    for idx, name in tqdm(enumerate(submit['Id'])):\n",
    "        path = os.path.join('../data/test/', name)\n",
    "        image = data_generator.load_image(path, (SIZE,SIZE,3))/255.\n",
    "        score_predict = model.predict(image[np.newaxis])[0]\n",
    "        sub_class_preds[idx] += score_predict\n",
    "        np.save('../cache/sub_class_preds-19.npy', sub_class_preds)\n",
    "        \n",
    "    fold_ += 1\n",
    "sub_class_preds /= n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../cache/oof_class_preds-19-1.npy', oof_class_preds)\n",
    "np.save('../cache/sub_class_preds-19-1.npy', sub_class_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oof_class_preds = np.zeros((train_dataset_info.shape[0], 28))\n",
    "# sub_class_preds = np.zeros((submit.shape[0], 28))\n",
    "# score_predict = model.predict(image[np.newaxis])[0]\n",
    "# oof_class_preds[idx] = score_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for train_index, test_index in kf.split(indexes):\n",
    "# ...    print(\"TRAIN:\", train_index, \"TEST:\", test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11702, 28)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_class_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11702/11702 [00:00<00:00, 89053.01it/s]\n"
     ]
    }
   ],
   "source": [
    "predicted = []\n",
    "for line in tqdm(sub_class_preds):\n",
    "    label_predict = np.arange(28)[line>=0.2]\n",
    "    str_predict_label = ' '.join(str(l) for l in label_predict)\n",
    "    predicted.append(str_predict_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11702"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2',\n",
       " '5 25',\n",
       " '0 5 25',\n",
       " '0 25',\n",
       " '0 7 25',\n",
       " '4 21',\n",
       " '0 4 23 25',\n",
       " '0 23 25',\n",
       " '0',\n",
       " '25',\n",
       " '18 25',\n",
       " '3 5',\n",
       " '0 25',\n",
       " '6 7 9 20',\n",
       " '23',\n",
       " '4 18 25',\n",
       " '2 14',\n",
       " '0 5',\n",
       " '14 21',\n",
       " '0 5',\n",
       " '6',\n",
       " '3 5 24',\n",
       " '0 11 16 25',\n",
       " '0',\n",
       " '0 4',\n",
       " '0 11 12 25 26',\n",
       " '0',\n",
       " '0 1',\n",
       " '0 25',\n",
       " '0',\n",
       " '13 21',\n",
       " '0 25',\n",
       " '14 16 17 18 21 25',\n",
       " '0 5 25',\n",
       " '0 7',\n",
       " '13',\n",
       " '0 25',\n",
       " '0 3',\n",
       " '0 12 21 25',\n",
       " '1',\n",
       " '0 16 17 25',\n",
       " '6 25',\n",
       " '0 5 21 25',\n",
       " '18 19 25',\n",
       " '0 16 17 21 22 25',\n",
       " '6',\n",
       " '0',\n",
       " '0',\n",
       " '6 23 25',\n",
       " '0',\n",
       " '0 17 25',\n",
       " '0 5',\n",
       " '20 23',\n",
       " '0 25',\n",
       " '3',\n",
       " '0 25',\n",
       " '0 17 25',\n",
       " '6 11 23',\n",
       " '0 25',\n",
       " '21 25',\n",
       " '2 21 22 23',\n",
       " '0 5',\n",
       " '14 16 21 25',\n",
       " '21 25',\n",
       " '23',\n",
       " '0 18 19 25',\n",
       " '3 6 21 25',\n",
       " '0 25',\n",
       " '0 16',\n",
       " '21 25',\n",
       " '2 3',\n",
       " '0 2',\n",
       " '14',\n",
       " '4',\n",
       " '0 21',\n",
       " '0',\n",
       " '4',\n",
       " '0 1',\n",
       " '0 25',\n",
       " '0 25',\n",
       " '6 25',\n",
       " '0 25',\n",
       " '0 21 25',\n",
       " '0 17 21 25',\n",
       " '17 18 19',\n",
       " '0 23 25',\n",
       " '23',\n",
       " '0 21',\n",
       " '14 16 17 25',\n",
       " '14',\n",
       " '0 25',\n",
       " '11 21',\n",
       " '23',\n",
       " '12 13',\n",
       " '0 16 17 25',\n",
       " '0 25',\n",
       " '7 18 23 25',\n",
       " '0 7 19 25',\n",
       " '24',\n",
       " '0 23 25',\n",
       " '0 11 25',\n",
       " '23',\n",
       " '21 23',\n",
       " '0 23',\n",
       " '7 11 25',\n",
       " '19 21 22 25',\n",
       " '0 14 16',\n",
       " '0 11 16 24',\n",
       " '7 20 26',\n",
       " '0 25',\n",
       " '2',\n",
       " '1',\n",
       " '16 17 18 25',\n",
       " '0 22 25',\n",
       " '21 25',\n",
       " '21 23',\n",
       " '0 2',\n",
       " '4 25',\n",
       " '6 14 25',\n",
       " '26',\n",
       " '0 18 23 25',\n",
       " '21 25',\n",
       " '2 11 21 25',\n",
       " '7 8 9 20',\n",
       " '0 2 4',\n",
       " '0',\n",
       " '0 21 25',\n",
       " '25',\n",
       " '0 4',\n",
       " '19',\n",
       " '16 17 25',\n",
       " '0 21',\n",
       " '0',\n",
       " '0 23',\n",
       " '0 11',\n",
       " '5',\n",
       " '0 14 16',\n",
       " '0',\n",
       " '5 21',\n",
       " '21 25',\n",
       " '0 19',\n",
       " '21 25',\n",
       " '0 1',\n",
       " '0 5',\n",
       " '0 25',\n",
       " '4 22 26',\n",
       " '0 12 21 25',\n",
       " '0 6 7 25',\n",
       " '0',\n",
       " '6 25',\n",
       " '0 23',\n",
       " '7 16 17 18',\n",
       " '0 7',\n",
       " '0 25',\n",
       " '6 7 25',\n",
       " '6',\n",
       " '0 7',\n",
       " '0 16 17 25',\n",
       " '1 21 25',\n",
       " '25',\n",
       " '0 19 25',\n",
       " '21 25',\n",
       " '0 11 19 25',\n",
       " '4 25',\n",
       " '5',\n",
       " '23',\n",
       " '0 19 22 25',\n",
       " '19',\n",
       " '17 21 25',\n",
       " '7 16 25',\n",
       " '5 25',\n",
       " '0 6 21 25',\n",
       " '0 16 17 25',\n",
       " '21 23',\n",
       " '0 2',\n",
       " '0 11 23',\n",
       " '21',\n",
       " '0 7 18 25',\n",
       " '0 12 21 25',\n",
       " '0 2 25',\n",
       " '0',\n",
       " '23',\n",
       " '0',\n",
       " '0 24 26',\n",
       " '14',\n",
       " '0 14 16 17 25',\n",
       " '0 16 25',\n",
       " '0 5 25',\n",
       " '23',\n",
       " '0 14 16 17 21 25',\n",
       " '14 25',\n",
       " '0 25',\n",
       " '5 25 26',\n",
       " '25 26',\n",
       " '5 25',\n",
       " '0 13 22',\n",
       " '0 25',\n",
       " '16 19 25 26',\n",
       " '23 25',\n",
       " '0 4 25',\n",
       " '2 21',\n",
       " '0 3',\n",
       " '0 25',\n",
       " '0 25',\n",
       " '0 3 5 19 25',\n",
       " '7 21',\n",
       " '0 25',\n",
       " '0 5',\n",
       " '0',\n",
       " '0 21',\n",
       " '0 14 16',\n",
       " '0 5',\n",
       " '7',\n",
       " '0 5',\n",
       " '18 19 25',\n",
       " '0 21',\n",
       " '24 26',\n",
       " '7 25',\n",
       " '21 22',\n",
       " '3',\n",
       " '0 2 3',\n",
       " '14 16 17 25',\n",
       " '0 26',\n",
       " '2 3 12 21',\n",
       " '6 8 20 23',\n",
       " '7 23',\n",
       " '21',\n",
       " '12 25',\n",
       " '0 19',\n",
       " '0 1 5',\n",
       " '11 25',\n",
       " '0 11',\n",
       " '0 2',\n",
       " '23',\n",
       " '0 23 25',\n",
       " '11',\n",
       " '13 20 26',\n",
       " '0 12',\n",
       " '0 18 21',\n",
       " '16 17 18',\n",
       " '21',\n",
       " '2 7',\n",
       " '21',\n",
       " '0 21 25',\n",
       " '2 4 7 11 14 16 17 25',\n",
       " '12 23',\n",
       " '25',\n",
       " '4',\n",
       " '13',\n",
       " '0 1',\n",
       " '0 25',\n",
       " '0 25',\n",
       " '2 6 25',\n",
       " '0 25',\n",
       " '0 25',\n",
       " '11',\n",
       " '23',\n",
       " '3 5',\n",
       " '25',\n",
       " '12 21 25',\n",
       " '14 16 17 18 21 25',\n",
       " '19',\n",
       " '4 26',\n",
       " '0 2 5 19',\n",
       " '13 21 22',\n",
       " '0',\n",
       " '12',\n",
       " '0',\n",
       " '0 23 25',\n",
       " '0 25',\n",
       " '0 19',\n",
       " '0 21 25',\n",
       " '0 12',\n",
       " '0 2 25',\n",
       " '2',\n",
       " '0 18 19 25',\n",
       " '0 2',\n",
       " '11',\n",
       " '0 25',\n",
       " '0 25',\n",
       " '0 21 25',\n",
       " '2',\n",
       " '3',\n",
       " '8 9 10 20 26',\n",
       " '0 19',\n",
       " '0 12 21',\n",
       " '0 2',\n",
       " '7',\n",
       " '1 2 6 25',\n",
       " '7 24',\n",
       " '0 5',\n",
       " '0 14 16',\n",
       " '0 18 21 25',\n",
       " '7',\n",
       " '0 4 19',\n",
       " '0 21 25',\n",
       " '0 23 25',\n",
       " '0 2 25',\n",
       " '0 5',\n",
       " '0 2',\n",
       " '26',\n",
       " '0 3 5 18',\n",
       " '11 25',\n",
       " '0 14',\n",
       " '25',\n",
       " '0 19',\n",
       " '1',\n",
       " '14 16 17 25',\n",
       " '0 21',\n",
       " '0',\n",
       " '11 23',\n",
       " '6 11',\n",
       " '0 4 7 25',\n",
       " '0',\n",
       " '0',\n",
       " '21 25',\n",
       " '14 16 17 18 25',\n",
       " '0 3 25',\n",
       " '0 25',\n",
       " '0 2 25',\n",
       " '19',\n",
       " '6',\n",
       " '0 25',\n",
       " '0 2',\n",
       " '0',\n",
       " '0 2 25',\n",
       " '21 22',\n",
       " '0 2',\n",
       " '0 2 3',\n",
       " '0 14 25',\n",
       " '5',\n",
       " '3 6 9 10 24 25',\n",
       " '25',\n",
       " '0 1 21',\n",
       " '11 21 25',\n",
       " '7',\n",
       " '24',\n",
       " '14 17 25',\n",
       " '0 25',\n",
       " '6',\n",
       " '21 25',\n",
       " '0 7 18',\n",
       " '0 2 4',\n",
       " '14 16 17',\n",
       " '4 12 21 25',\n",
       " '0 2 3 5 19 25',\n",
       " '18 24',\n",
       " '3 7',\n",
       " '0 2 21 25',\n",
       " '0 25',\n",
       " '0 7',\n",
       " '8 9 10 20 26',\n",
       " '25',\n",
       " '0 5 19',\n",
       " '0 2 25',\n",
       " '3',\n",
       " '0 7 24',\n",
       " '0 5 21',\n",
       " '25',\n",
       " '2 4 23',\n",
       " '11 24 25',\n",
       " '2 6 25',\n",
       " '0 25',\n",
       " '0 25',\n",
       " '7 25',\n",
       " '11',\n",
       " '11',\n",
       " '0',\n",
       " '0 5 25',\n",
       " '0 5',\n",
       " '14 16 17 18 25',\n",
       " '0 1 25',\n",
       " '0 21 25',\n",
       " '21 25',\n",
       " '0 23',\n",
       " '0 21',\n",
       " '0 3',\n",
       " '0 3 25',\n",
       " '12 21',\n",
       " '4 21 25',\n",
       " '0 21',\n",
       " '2 7',\n",
       " '0',\n",
       " '2 25',\n",
       " '4 5',\n",
       " '14 16 25',\n",
       " '0',\n",
       " '2 3',\n",
       " '18 19',\n",
       " '0 25',\n",
       " '14 16 17 18 25',\n",
       " '25',\n",
       " '0 14',\n",
       " '21 25',\n",
       " '0 5',\n",
       " '0 25',\n",
       " '0 21',\n",
       " '0 11',\n",
       " '14 16 17 21',\n",
       " '0 25',\n",
       " '0 21 23 25',\n",
       " '0 5 25',\n",
       " '21 23 25',\n",
       " '0 14 16 21',\n",
       " '0 21 22 25',\n",
       " '0 2 23',\n",
       " '0 20 23',\n",
       " '23 26',\n",
       " '21 25',\n",
       " '1',\n",
       " '6 25',\n",
       " '0',\n",
       " '23',\n",
       " '7 25',\n",
       " '0 25',\n",
       " '0',\n",
       " '5 21 25',\n",
       " '21 25',\n",
       " '0 21 25',\n",
       " '0 7 24',\n",
       " '0 7 25',\n",
       " '0 2 5',\n",
       " '21 23',\n",
       " '0 3 4 25',\n",
       " '0 21 25',\n",
       " '0 7 25',\n",
       " '18 25',\n",
       " '0 18 19',\n",
       " '0 3 24',\n",
       " '4 21 25',\n",
       " '0 12 21 25',\n",
       " '0 23 25',\n",
       " '23',\n",
       " '0 14 16',\n",
       " '0 18 25',\n",
       " '0 7 23 25',\n",
       " '0 4',\n",
       " '0 12 21 25',\n",
       " '2',\n",
       " '7',\n",
       " '1 25',\n",
       " '21 25',\n",
       " '17 25',\n",
       " '0 2',\n",
       " '0 25',\n",
       " '0 22 25 26',\n",
       " '0 19 25',\n",
       " '21',\n",
       " '14 16 17 18 25',\n",
       " '17 18 21 25',\n",
       " '12 21',\n",
       " '0 2 3',\n",
       " '0 4 21 25',\n",
       " '0',\n",
       " '0 3',\n",
       " '0',\n",
       " '0 3 5 25',\n",
       " '25',\n",
       " '6 11',\n",
       " '4',\n",
       " '0 25',\n",
       " '2 21 25',\n",
       " '0 2',\n",
       " '0 2 25',\n",
       " '7 9 10 20',\n",
       " '21',\n",
       " '23',\n",
       " '3 5 23',\n",
       " '0 2 11',\n",
       " '7 11',\n",
       " '3',\n",
       " '18 23 25',\n",
       " '0 2',\n",
       " '0 25',\n",
       " '14 17 25',\n",
       " '3 4',\n",
       " '0 11 25',\n",
       " '0 25',\n",
       " '6 23 25',\n",
       " '4',\n",
       " '14',\n",
       " '0 21 22 25',\n",
       " '4',\n",
       " '0',\n",
       " '0 21 22',\n",
       " '0 21 25',\n",
       " '2 25',\n",
       " '0 13',\n",
       " '4',\n",
       " '0 1',\n",
       " '0 25',\n",
       " '21 25',\n",
       " '0 25',\n",
       " '2 25',\n",
       " '0 25',\n",
       " '7',\n",
       " '21 25',\n",
       " '0 7',\n",
       " '0 23',\n",
       " '0 19 23',\n",
       " '16 17 25',\n",
       " '2',\n",
       " '0',\n",
       " '21',\n",
       " '21',\n",
       " '0',\n",
       " '0 21',\n",
       " '2 7 25',\n",
       " '0 25',\n",
       " '0 7',\n",
       " '0 21 25',\n",
       " '0 7 21 25',\n",
       " '12 13',\n",
       " '0 2 3 25',\n",
       " '0 13 16 21 22 25',\n",
       " '21 25',\n",
       " '7',\n",
       " '0',\n",
       " '13 16 25',\n",
       " '3',\n",
       " '0 19',\n",
       " '0 3 25',\n",
       " '1 25',\n",
       " '0 11 25',\n",
       " '0',\n",
       " '19 25',\n",
       " '0 4',\n",
       " '7',\n",
       " '0 25',\n",
       " '23',\n",
       " '18 19',\n",
       " '0 21 25',\n",
       " '0 16 17 25',\n",
       " '0 16 17 18 21',\n",
       " '4 25',\n",
       " '0 14',\n",
       " '2 25',\n",
       " '19',\n",
       " '0 25',\n",
       " '18 19',\n",
       " '12',\n",
       " '0 21',\n",
       " '5 26',\n",
       " '0',\n",
       " '0 25',\n",
       " '7',\n",
       " '4',\n",
       " '0 5',\n",
       " '2 7 21',\n",
       " '2',\n",
       " '23',\n",
       " '14',\n",
       " '0 2 25',\n",
       " '0 11 12 25',\n",
       " '2 7 21 25',\n",
       " '21',\n",
       " '12 21 25',\n",
       " '0 25',\n",
       " '0 18 21 25',\n",
       " '0 21 25',\n",
       " '7',\n",
       " '0',\n",
       " '21 23',\n",
       " '2 7',\n",
       " '0 25',\n",
       " '0 21 25',\n",
       " '18 21 25',\n",
       " '0 25',\n",
       " '6 25',\n",
       " '0 23 25',\n",
       " '18 21 25',\n",
       " '0 25',\n",
       " '14 16 17 25',\n",
       " '0 5 18',\n",
       " '7 25',\n",
       " '11 24',\n",
       " '0 16 17 25',\n",
       " '7 23',\n",
       " '0',\n",
       " '0 25',\n",
       " '0 25',\n",
       " '20 21 23 26',\n",
       " '6 11 25',\n",
       " '5 18 19 21 25',\n",
       " '21',\n",
       " '0 25',\n",
       " '21',\n",
       " '4',\n",
       " '23',\n",
       " '21',\n",
       " '0 7',\n",
       " '5 23',\n",
       " '0 13 20 22',\n",
       " '6 25',\n",
       " '21 22 25',\n",
       " '0 25',\n",
       " '5 19 25',\n",
       " '2 3',\n",
       " '2 14 16',\n",
       " '6 11 14',\n",
       " '0 2 25',\n",
       " '1 2',\n",
       " '23',\n",
       " '0 25',\n",
       " '0 21 25',\n",
       " '0 5 21',\n",
       " '0',\n",
       " '19',\n",
       " '0 4 7',\n",
       " '0 12 21',\n",
       " '0 25',\n",
       " '7 21 25',\n",
       " '14 16',\n",
       " '14 21',\n",
       " '5 19',\n",
       " '0 21',\n",
       " '23',\n",
       " '1 6 25',\n",
       " '0 5 25',\n",
       " '7',\n",
       " '23 25',\n",
       " '3 5',\n",
       " '0 12',\n",
       " '14',\n",
       " '23 25',\n",
       " '0 21',\n",
       " '5 21 22',\n",
       " '21 22',\n",
       " '0 25',\n",
       " '25',\n",
       " '0 12 21',\n",
       " '0 25',\n",
       " '0 5 7',\n",
       " '0 25',\n",
       " '3 5 25',\n",
       " '14 16 17',\n",
       " '0 7 18',\n",
       " '0 19',\n",
       " '5',\n",
       " '7',\n",
       " '21',\n",
       " '13',\n",
       " '0',\n",
       " '23 25',\n",
       " '0 7',\n",
       " '11 12 21 25',\n",
       " '0 1 25',\n",
       " '25',\n",
       " '0 5 7 25',\n",
       " '25 26',\n",
       " '21 25',\n",
       " '14 21 25',\n",
       " '0 21 25',\n",
       " '0 2 3 7',\n",
       " '2',\n",
       " '5 21',\n",
       " '0 23 25',\n",
       " '0 1 4',\n",
       " '0 1 18 19 21 25',\n",
       " '25',\n",
       " '0 18 19',\n",
       " '0 2',\n",
       " '0 19',\n",
       " '0 16 25',\n",
       " '0 25',\n",
       " '2 4 26',\n",
       " '7',\n",
       " '5 25',\n",
       " '5 25',\n",
       " '21 22',\n",
       " '14 16 17 25',\n",
       " '0 21 22',\n",
       " '0 2 5 25',\n",
       " '7',\n",
       " '5 25',\n",
       " '18 19',\n",
       " '0 1 6 25',\n",
       " '0 21',\n",
       " '19 26',\n",
       " '4 18 19 25',\n",
       " '23 25',\n",
       " '1 25',\n",
       " '0 2 14 16',\n",
       " '22',\n",
       " '0 6 21 25',\n",
       " '0 25',\n",
       " '0 22',\n",
       " '0 21',\n",
       " '0 25',\n",
       " '0 16 17 25',\n",
       " '0 25',\n",
       " '23',\n",
       " '0 5 21',\n",
       " '4',\n",
       " '13',\n",
       " '0 25',\n",
       " '6 11 21 25',\n",
       " '0 12 23 25',\n",
       " '0 1 6 21 25',\n",
       " '0 5 14 16 21 25',\n",
       " '5',\n",
       " '0',\n",
       " '21 23',\n",
       " '14',\n",
       " '0 2 3 11 25',\n",
       " '5 25',\n",
       " '11',\n",
       " '0 7',\n",
       " '0 22 25',\n",
       " '3',\n",
       " '0 21',\n",
       " '0 25',\n",
       " '21 25',\n",
       " '1 6 21 25',\n",
       " '25',\n",
       " '0 21 25',\n",
       " '11 12 21 24',\n",
       " '2',\n",
       " '3 4 5',\n",
       " '0 21',\n",
       " '0 2 18 19',\n",
       " '21',\n",
       " '25',\n",
       " '0 25',\n",
       " '19',\n",
       " '0 3',\n",
       " '0 2 25',\n",
       " '0 23',\n",
       " '0 1 2',\n",
       " '0',\n",
       " '0 11 25',\n",
       " '0 13 22 25',\n",
       " '5',\n",
       " '0 17 18 21',\n",
       " '0 2 7',\n",
       " '0 1 2',\n",
       " '7 21',\n",
       " '0 25',\n",
       " '0 18 19 25',\n",
       " '23',\n",
       " '7 25',\n",
       " '0 19 21 25',\n",
       " '23 25',\n",
       " '23',\n",
       " '21',\n",
       " '21 24',\n",
       " '0 13',\n",
       " '0 25',\n",
       " '2 16 17 25',\n",
       " '0 21 25',\n",
       " '0',\n",
       " '23',\n",
       " '0 2 21',\n",
       " '0 3',\n",
       " '0 25',\n",
       " '0 5',\n",
       " '21 25',\n",
       " '0 25',\n",
       " '0 25',\n",
       " '23',\n",
       " '13 25',\n",
       " '23 25',\n",
       " '0 2 21 25',\n",
       " '14',\n",
       " '5 7',\n",
       " '14 21 25',\n",
       " '0 7 21 25',\n",
       " '18 19',\n",
       " '7 23',\n",
       " '7 11',\n",
       " '7',\n",
       " '18 19',\n",
       " '23',\n",
       " '0 21 25',\n",
       " '0 25',\n",
       " '0',\n",
       " '14 16 17 25',\n",
       " '6 23 25',\n",
       " '0 2 16',\n",
       " '21 25',\n",
       " '0 25',\n",
       " '6 11 23',\n",
       " '14 16 17',\n",
       " '0 16 21',\n",
       " '14 16 17 25',\n",
       " '14 25',\n",
       " '0 18 19 25',\n",
       " '6 23',\n",
       " '5',\n",
       " '2 7',\n",
       " '7 23',\n",
       " '0',\n",
       " '0',\n",
       " '0 7 20',\n",
       " '0 25',\n",
       " '25',\n",
       " '23 25',\n",
       " '0 25',\n",
       " '21 22 25 26',\n",
       " '0 2 3 25',\n",
       " '0 18 19 25',\n",
       " '12 25',\n",
       " '0 21',\n",
       " '0 16 17 25',\n",
       " '0 4 21',\n",
       " '0 21',\n",
       " '23',\n",
       " '4 17 18 25',\n",
       " '0 25',\n",
       " '0 19 23',\n",
       " '23',\n",
       " '11',\n",
       " '2',\n",
       " '0 23 25',\n",
       " '0 7',\n",
       " '5 25',\n",
       " '0',\n",
       " '14 16 17 18',\n",
       " '0 5 7 21 25',\n",
       " '0 21 25',\n",
       " '21 22 25',\n",
       " '0 13 14 25',\n",
       " '0 25',\n",
       " '25',\n",
       " '0 1 21 25',\n",
       " '0 6 11 25',\n",
       " '25',\n",
       " '25',\n",
       " '6 25',\n",
       " '0 21',\n",
       " '25',\n",
       " '21 25',\n",
       " '0 25',\n",
       " '0 25',\n",
       " '0 1 2',\n",
       " '0 25',\n",
       " '3',\n",
       " '0 19',\n",
       " '0 5',\n",
       " '0 2 21',\n",
       " '0 25',\n",
       " '0 5',\n",
       " '0 25',\n",
       " '0 1 3 5 19',\n",
       " '7 9 10',\n",
       " '26',\n",
       " '0 23 25',\n",
       " '0 14 16 17 21 25',\n",
       " '18 19 21 25',\n",
       " '0 12 21',\n",
       " '0 23 25',\n",
       " '0 21 25',\n",
       " '14 16 17',\n",
       " '14 21 25',\n",
       " '0 21 25',\n",
       " '0 19',\n",
       " '6 25',\n",
       " '0',\n",
       " '21',\n",
       " '0 18 19',\n",
       " '21',\n",
       " '0 23',\n",
       " '0 18',\n",
       " '0 1',\n",
       " '19 25',\n",
       " '0 25',\n",
       " '0 5 12 21',\n",
       " '0 17 18 25',\n",
       " '0 11 14 16 17',\n",
       " '0 5 21 22',\n",
       " '11',\n",
       " '3 5 22 25',\n",
       " '0 3 5',\n",
       " '0 5',\n",
       " '6 11 25',\n",
       " '0',\n",
       " '0',\n",
       " '',\n",
       " '23',\n",
       " '6',\n",
       " '0 23 25',\n",
       " '0 2 25',\n",
       " '14 21',\n",
       " '0 25',\n",
       " '0 5 26',\n",
       " '12 21',\n",
       " '0 23',\n",
       " '0 20 23 25',\n",
       " '0 25',\n",
       " '21',\n",
       " '0 2 18 25',\n",
       " '5',\n",
       " '23',\n",
       " '12 21 25',\n",
       " '2 7 25',\n",
       " '0 1 7',\n",
       " '6',\n",
       " '20 26',\n",
       " '0 25',\n",
       " '0 25',\n",
       " '0 7',\n",
       " '0 21 25',\n",
       " '0 13 22',\n",
       " '23',\n",
       " '25',\n",
       " '14 25',\n",
       " '4',\n",
       " '0 25',\n",
       " '0 5',\n",
       " '19 21 25',\n",
       " '0 3',\n",
       " '18 19 25',\n",
       " '0 21 25',\n",
       " '0 5',\n",
       " '19 26',\n",
       " '0 7',\n",
       " '14',\n",
       " '25',\n",
       " '7',\n",
       " '2 25',\n",
       " '7',\n",
       " '23 25',\n",
       " '0',\n",
       " '23 25',\n",
       " '0 21 25',\n",
       " '0 3 5',\n",
       " '0 2 21 25',\n",
       " '0 25',\n",
       " '0 2 7 25',\n",
       " '0 25',\n",
       " '0 6 25',\n",
       " '11 19 25',\n",
       " '0 4',\n",
       " '4',\n",
       " '17 21',\n",
       " '14 16 17',\n",
       " '0 21',\n",
       " '0 3 13 21 22 25',\n",
       " '19',\n",
       " '21 23',\n",
       " '19 25',\n",
       " '0 21 25',\n",
       " '21 22',\n",
       " '0 21 25',\n",
       " '1 21 25',\n",
       " '25',\n",
       " '0 2 16',\n",
       " '7',\n",
       " '0 1 6 25',\n",
       " '21 25',\n",
       " '2 26',\n",
       " '0 25',\n",
       " '14 25',\n",
       " '0 2 3',\n",
       " '17 25',\n",
       " '4 21',\n",
       " '4 21',\n",
       " '0 25',\n",
       " '0 19',\n",
       " '0',\n",
       " '0 18 19',\n",
       " '0 11 23 25',\n",
       " '25',\n",
       " '7 16 18',\n",
       " '12',\n",
       " '7 19 23',\n",
       " '0 23',\n",
       " '0 25',\n",
       " '0 7',\n",
       " '7',\n",
       " '21 25',\n",
       " '0 12 14 25',\n",
       " '0 4 25',\n",
       " '0 4',\n",
       " '0 5 21 22',\n",
       " '0',\n",
       " '0 4',\n",
       " '0 16 17 18 25',\n",
       " '0 25',\n",
       " '0 18 21',\n",
       " '11',\n",
       " '0 7 14',\n",
       " '21 25',\n",
       " '3',\n",
       " '6 21 25',\n",
       " '0 2 3 5 23',\n",
       " '3',\n",
       " '18 25',\n",
       " '23',\n",
       " '5',\n",
       " '0 25',\n",
       " '0 2',\n",
       " '0 1 19',\n",
       " '0 2',\n",
       " '0 2',\n",
       " '5 7 25',\n",
       " '0 25 26',\n",
       " '0 21',\n",
       " '0 25',\n",
       " '23 25',\n",
       " ...]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit['Predicted'] = predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submit\n",
    "# submit = pd.read_csv('../data/sample_submission.csv')\n",
    "# predicted = []\n",
    "# draw_predict = []\n",
    "# # model.load_weights('../cache/InceptionV3.h5')\n",
    "# for name in tqdm(submit['Id']):\n",
    "#     path = os.path.join('../data/test/', name)\n",
    "#     image = data_generator.load_image(path, (SIZE,SIZE,3))/255.\n",
    "#     score_predict = model.predict(image[np.newaxis])[0]\n",
    "#     draw_predict.append(score_predict)\n",
    "#     label_predict = np.arange(28)[score_predict>=0.2]\n",
    "#     str_predict_label = ' '.join(str(l) for l in label_predict)\n",
    "#     predicted.append(str_predict_label)\n",
    "\n",
    "# submit['Predicted'] = predicted\n",
    "# np.save('../cache/draw_predict_InceptionV3-8.npy', score_predict)\n",
    "# submit.to_csv('../submissions/submit_InceptionV3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv('../submissions/sub17-a.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/1855095/how-to-create-a-zip-archive-of-a-directory\n",
    "def backup_project_as_zip(project_dir, zip_file):\n",
    "    assert(os.path.isdir(project_dir))\n",
    "    assert(os.path.isdir(os.path.dirname(zip_file)))\n",
    "    shutil.make_archive(zip_file.replace('.zip',''), 'zip', project_dir)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-11-02 11:04:00.238809\n"
     ]
    }
   ],
   "source": [
    "import datetime, shutil\n",
    "now = datetime.datetime.now()\n",
    "print(now)\n",
    "PROJECT_PATH = '/home/watts/lal/Kaggle/kagglehp/scripts_nbs'\n",
    "backup_project_as_zip(PROJECT_PATH, '../cache/code.scripts_nbs.%s.zip'%now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 492k/492k [00:13<00:00, 37.3kB/s]\n",
      "Successfully submitted to Human Protein Atlas Image ClassificationCPU times: user 492 ms, sys: 222 ms, total: 714 ms\n",
      "Wall time: 21.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!kaggle competitions submit -c human-protein-atlas-image-classification -f ../submissions/sub17-a.csv -m \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileName      date                 description  status    publicScore  privateScore  \r\n",
      "------------  -------------------  -----------  --------  -----------  ------------  \r\n",
      "sub17-a.csv   2018-11-02 05:34:31               complete  0.448        None          \r\n",
      "sub15-e.csv   2018-10-31 17:17:32               complete  0.453        None          \r\n",
      "sub15-d.csv   2018-10-31 17:16:24               complete  0.461        None          \r\n",
      "sub15-c.csv   2018-10-31 17:15:49               complete  0.457        None          \r\n",
      "sub15-b.csv   2018-10-31 17:14:03               complete  0.454        None          \r\n",
      "sub15-a.csv   2018-10-31 17:13:02               complete  0.446        None          \r\n",
      "sub14-d.csv   2018-10-30 16:36:00               complete  0.464        None          \r\n",
      "sub14-c.csv   2018-10-30 16:35:09               complete  0.466        None          \r\n",
      "sub14-bb.csv  2018-10-30 16:34:35               complete  0.461        None          \r\n",
      "sub14-b.csv   2018-10-30 16:33:35               complete  0.459        None          \r\n",
      "sub14-a.csv   2018-10-30 16:32:37               complete  0.452        None          \r\n",
      "sub13-c.csv   2018-10-29 19:24:00               complete  0.459        None          \r\n",
      "sub13-bb.csv  2018-10-29 19:23:01               complete  0.454        None          \r\n",
      "sub13-b.csv   2018-10-29 19:21:53               complete  0.448        None          \r\n",
      "sub13-a.csv   2018-10-29 19:20:40               complete  0.444        None          \r\n",
      "sub12-d.csv   2018-10-26 02:09:32               complete  0.466        None          \r\n",
      "sub12-h.csv   2018-10-26 02:07:56               complete  0.389        None          \r\n",
      "sub12-g.csv   2018-10-25 00:55:10               complete  0.433        None          \r\n",
      "sub12-c.csv   2018-10-25 00:45:32               complete  0.469        None          \r\n",
      "sub12-bb.csv  2018-10-25 00:43:34               complete  0.466        None          \r\n"
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "sleep(30)\n",
    "!kaggle competitions submissions -c human-protein-atlas-image-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11702/11702 [00:00<00:00, 98820.65it/s]\n"
     ]
    }
   ],
   "source": [
    "predicted = []\n",
    "for line in tqdm(sub_class_preds):\n",
    "    label_predict = np.arange(28)[line>=0.25]\n",
    "    str_predict_label = ' '.join(str(l) for l in label_predict)\n",
    "    predicted.append(str_predict_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit['Predicted'] = predicted\n",
    "submit.to_csv('../submissions/sub17-b.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-11-02 11:05:04.665317\n"
     ]
    }
   ],
   "source": [
    "import datetime, shutil\n",
    "now = datetime.datetime.now()\n",
    "print(now)\n",
    "PROJECT_PATH = '/home/watts/lal/Kaggle/kagglehp/scripts_nbs'\n",
    "backup_project_as_zip(PROJECT_PATH, '../cache/code.scripts_nbs.%s.zip'%now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 486k/486k [00:12<00:00, 39.4kB/s]\n",
      "Successfully submitted to Human Protein Atlas Image ClassificationCPU times: user 386 ms, sys: 145 ms, total: 530 ms\n",
      "Wall time: 15.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!kaggle competitions submit -c human-protein-atlas-image-classification -f ../submissions/sub17-b.csv -m \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileName      date                 description  status    publicScore  privateScore  \r\n",
      "------------  -------------------  -----------  --------  -----------  ------------  \r\n",
      "sub17-b.csv   2018-11-02 05:35:30               complete  0.456        None          \r\n",
      "sub17-a.csv   2018-11-02 05:34:31               complete  0.448        None          \r\n",
      "sub15-e.csv   2018-10-31 17:17:32               complete  0.453        None          \r\n",
      "sub15-d.csv   2018-10-31 17:16:24               complete  0.461        None          \r\n",
      "sub15-c.csv   2018-10-31 17:15:49               complete  0.457        None          \r\n",
      "sub15-b.csv   2018-10-31 17:14:03               complete  0.454        None          \r\n",
      "sub15-a.csv   2018-10-31 17:13:02               complete  0.446        None          \r\n",
      "sub14-d.csv   2018-10-30 16:36:00               complete  0.464        None          \r\n",
      "sub14-c.csv   2018-10-30 16:35:09               complete  0.466        None          \r\n",
      "sub14-bb.csv  2018-10-30 16:34:35               complete  0.461        None          \r\n",
      "sub14-b.csv   2018-10-30 16:33:35               complete  0.459        None          \r\n",
      "sub14-a.csv   2018-10-30 16:32:37               complete  0.452        None          \r\n",
      "sub13-c.csv   2018-10-29 19:24:00               complete  0.459        None          \r\n",
      "sub13-bb.csv  2018-10-29 19:23:01               complete  0.454        None          \r\n",
      "sub13-b.csv   2018-10-29 19:21:53               complete  0.448        None          \r\n",
      "sub13-a.csv   2018-10-29 19:20:40               complete  0.444        None          \r\n",
      "sub12-d.csv   2018-10-26 02:09:32               complete  0.466        None          \r\n",
      "sub12-h.csv   2018-10-26 02:07:56               complete  0.389        None          \r\n",
      "sub12-g.csv   2018-10-25 00:55:10               complete  0.433        None          \r\n",
      "sub12-c.csv   2018-10-25 00:45:32               complete  0.469        None          \r\n"
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "sleep(30)\n",
    "!kaggle competitions submissions -c human-protein-atlas-image-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {0.3:'bb', 0.35:'c', 0.4:'d', 0.45:'e', 0.5:'f'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11702/11702 [00:00<00:00, 97846.66it/s]\n",
      "100%|██████████| 11702/11702 [00:00<00:00, 107801.36it/s]\n",
      "  0%|          | 0/11702 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../submissions/sub17-bb.csv\n",
      "../submissions/sub17-c.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11702/11702 [00:00<00:00, 109296.67it/s]\n",
      "100%|██████████| 11702/11702 [00:00<00:00, 118110.74it/s]\n",
      "  0%|          | 0/11702 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../submissions/sub17-d.csv\n",
      "../submissions/sub17-e.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 11702/11702 [00:00<00:00, 119991.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../submissions/sub17-f.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for alpha in [0.3, 0.35, 0.4, 0.45, 0.5]:\n",
    "    predicted = []\n",
    "    for line in tqdm(sub_class_preds):\n",
    "        label_predict = np.arange(28)[line>=alpha]\n",
    "        str_predict_label = ' '.join(str(l) for l in label_predict)\n",
    "        predicted.append(str_predict_label)\n",
    "    submit['Predicted'] = predicted\n",
    "    name = '../submissions/sub17-' + d[alpha] + '.csv'\n",
    "    print(name)\n",
    "    submit.to_csv(name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 481k/481k [00:13<00:00, 37.2kB/s]\n",
      "Successfully submitted to Human Protein Atlas Image ClassificationCPU times: user 506 ms, sys: 201 ms, total: 707 ms\n",
      "Wall time: 21.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!kaggle competitions submit -c human-protein-atlas-image-classification -f ../submissions/sub17-bb.csv -m \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileName      date                 description  status    publicScore  privateScore  \r\n",
      "------------  -------------------  -----------  --------  -----------  ------------  \r\n",
      "sub17-bb.csv  2018-11-02 05:36:24               complete  0.464        None          \r\n",
      "sub17-b.csv   2018-11-02 05:35:30               complete  0.456        None          \r\n",
      "sub17-a.csv   2018-11-02 05:34:31               complete  0.448        None          \r\n",
      "sub15-e.csv   2018-10-31 17:17:32               complete  0.453        None          \r\n",
      "sub15-d.csv   2018-10-31 17:16:24               complete  0.461        None          \r\n",
      "sub15-c.csv   2018-10-31 17:15:49               complete  0.457        None          \r\n",
      "sub15-b.csv   2018-10-31 17:14:03               complete  0.454        None          \r\n",
      "sub15-a.csv   2018-10-31 17:13:02               complete  0.446        None          \r\n",
      "sub14-d.csv   2018-10-30 16:36:00               complete  0.464        None          \r\n",
      "sub14-c.csv   2018-10-30 16:35:09               complete  0.466        None          \r\n",
      "sub14-bb.csv  2018-10-30 16:34:35               complete  0.461        None          \r\n",
      "sub14-b.csv   2018-10-30 16:33:35               complete  0.459        None          \r\n",
      "sub14-a.csv   2018-10-30 16:32:37               complete  0.452        None          \r\n",
      "sub13-c.csv   2018-10-29 19:24:00               complete  0.459        None          \r\n",
      "sub13-bb.csv  2018-10-29 19:23:01               complete  0.454        None          \r\n",
      "sub13-b.csv   2018-10-29 19:21:53               complete  0.448        None          \r\n",
      "sub13-a.csv   2018-10-29 19:20:40               complete  0.444        None          \r\n",
      "sub12-d.csv   2018-10-26 02:09:32               complete  0.466        None          \r\n",
      "sub12-h.csv   2018-10-26 02:07:56               complete  0.389        None          \r\n",
      "sub12-g.csv   2018-10-25 00:55:10               complete  0.433        None          \r\n"
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "sleep(30)\n",
    "!kaggle competitions submissions -c human-protein-atlas-image-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 477k/477k [00:08<00:00, 50.1kB/s]\n",
      "Successfully submitted to Human Protein Atlas Image ClassificationfileName      date                 description  status    publicScore  privateScore  \n",
      "------------  -------------------  -----------  --------  -----------  ------------  \n",
      "sub17-c.csv   2018-11-02 05:37:12               complete  0.463        None          \n",
      "sub17-bb.csv  2018-11-02 05:36:24               complete  0.464        None          \n",
      "sub17-b.csv   2018-11-02 05:35:30               complete  0.456        None          \n",
      "sub17-a.csv   2018-11-02 05:34:31               complete  0.448        None          \n",
      "sub15-e.csv   2018-10-31 17:17:32               complete  0.453        None          \n",
      "sub15-d.csv   2018-10-31 17:16:24               complete  0.461        None          \n",
      "sub15-c.csv   2018-10-31 17:15:49               complete  0.457        None          \n",
      "sub15-b.csv   2018-10-31 17:14:03               complete  0.454        None          \n",
      "sub15-a.csv   2018-10-31 17:13:02               complete  0.446        None          \n",
      "sub14-d.csv   2018-10-30 16:36:00               complete  0.464        None          \n",
      "sub14-c.csv   2018-10-30 16:35:09               complete  0.466        None          \n",
      "sub14-bb.csv  2018-10-30 16:34:35               complete  0.461        None          \n",
      "sub14-b.csv   2018-10-30 16:33:35               complete  0.459        None          \n",
      "sub14-a.csv   2018-10-30 16:32:37               complete  0.452        None          \n",
      "sub13-c.csv   2018-10-29 19:24:00               complete  0.459        None          \n",
      "sub13-bb.csv  2018-10-29 19:23:01               complete  0.454        None          \n",
      "sub13-b.csv   2018-10-29 19:21:53               complete  0.448        None          \n",
      "sub13-a.csv   2018-10-29 19:20:40               complete  0.444        None          \n",
      "sub12-d.csv   2018-10-26 02:09:32               complete  0.466        None          \n",
      "sub12-h.csv   2018-10-26 02:07:56               complete  0.389        None          \n",
      "CPU times: user 434 ms, sys: 288 ms, total: 721 ms\n",
      "Wall time: 48.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!kaggle competitions submit -c human-protein-atlas-image-classification -f ../submissions/sub17-c.csv -m \"\"\n",
    "from time import sleep\n",
    "sleep(30)\n",
    "!kaggle competitions submissions -c human-protein-atlas-image-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31072, 28)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof_class_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00070df0-bbc3-11e8-b2bc-ac1f6b6435d0</td>\n",
       "      <td>16 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000a6c98-bb9b-11e8-b2b9-ac1f6b6435d0</td>\n",
       "      <td>7 1 2 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000a9596-bbc4-11e8-b2bc-ac1f6b6435d0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000c99ba-bba4-11e8-b2b9-ac1f6b6435d0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001838f8-bbca-11e8-b2bc-ac1f6b6435d0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Id   Target\n",
       "0  00070df0-bbc3-11e8-b2bc-ac1f6b6435d0     16 0\n",
       "1  000a6c98-bb9b-11e8-b2b9-ac1f6b6435d0  7 1 2 0\n",
       "2  000a9596-bbc4-11e8-b2bc-ac1f6b6435d0        5\n",
       "3  000c99ba-bba4-11e8-b2b9-ac1f6b6435d0        1\n",
       "4  001838f8-bbca-11e8-b2bc-ac1f6b6435d0       18"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31072, 2)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31072, 28)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_classes = 28\n",
    "y_train = np.zeros(oof_class_preds.shape)\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31072/31072 [00:00<00:00, 741901.66it/s]\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "for labels in tqdm(data['Target'].str.split(' ')):\n",
    "#     print(labels)\n",
    "    for label in labels:\n",
    "        y_train[idx][int(label)] = 1\n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 1., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 1., 0., 0.],\n",
       "       [1., 0., 1., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001 0.6174081518752018\n",
      "0.01 0.6174081494907646\n",
      "0.1 0.6174079419635514\n",
      "0.5 0.6174049197331472\n",
      "0.75 0.6174023910597577\n",
      "1.0 0.6173997536697944\n",
      "------------------\n",
      "0.001 0.7042131450176463\n",
      "0.01 0.7042131449021258\n",
      "0.1 0.7042131341504188\n",
      "0.5 0.7042129258072632\n",
      "0.75 0.7042126913081677\n",
      "1.0 0.7042123865546952\n",
      "------------------\n",
      "0.001 0.6405293650278552\n",
      "0.01 0.6405293643199262\n",
      "0.1 0.6405293035770623\n",
      "0.5 0.6405284696126301\n",
      "0.75 0.6405278129689744\n",
      "1.0 0.6405271539313317\n",
      "------------------\n",
      "0.001 0.5206868082561187\n",
      "0.01 0.5206868064937693\n",
      "0.1 0.5206866550090807\n",
      "0.5 0.5206845661735036\n",
      "0.75 0.5206829204240566\n",
      "1.0 0.5206812723936773\n",
      "------------------\n",
      "0.001 0.6225629182679313\n",
      "0.01 0.6225628870674288\n",
      "0.1 0.6225602493284829\n",
      "0.5 0.6225265347174933\n",
      "0.75 0.6225024258166685\n",
      "1.0 0.6224802007531789\n",
      "------------------\n",
      "0.001 0.47625033808763034\n",
      "0.01 0.4762503310360723\n",
      "0.1 0.47624973372408597\n",
      "0.5 0.4762420258070793\n",
      "0.75 0.4762364393569697\n",
      "1.0 0.47623122503579396\n",
      "------------------\n",
      "0.001 0.37015383088158105\n",
      "0.01 0.37015383051625794\n",
      "0.1 0.37015379589885844\n",
      "0.5 0.370153120483382\n",
      "0.75 0.3701523989904022\n",
      "1.0 0.3701515220047934\n",
      "------------------\n",
      "0.001 0.6278499957612576\n",
      "0.01 0.6278499933196181\n",
      "0.1 0.6278497675145762\n",
      "0.5 0.6278457789099899\n",
      "0.75 0.6278419420023433\n",
      "1.0 0.627837666925348\n",
      "------------------\n",
      "0.001 0.23972549325385814\n",
      "0.01 0.23972546015299\n",
      "0.1 0.23972230652354265\n",
      "0.5 0.2396593031542591\n",
      "0.75 0.23959034757832143\n",
      "1.0 0.23950497349498\n",
      "------------------\n",
      "0.001 0.31331172323399825\n",
      "0.01 0.3133113149919019\n",
      "0.1 0.3132732609784179\n",
      "0.5 0.3125863700441769\n",
      "0.75 0.3119170265340445\n",
      "1.0 0.31116713928425954\n",
      "------------------\n",
      "0.001 0.2558623247962669\n",
      "0.01 0.255861948626774\n",
      "0.1 0.2558268879333644\n",
      "0.5 0.2551944259969803\n",
      "0.75 0.254578676028139\n",
      "1.0 0.2538894622998168\n",
      "------------------\n",
      "0.001 0.5968983087672983\n",
      "0.01 0.5968983084398413\n",
      "0.1 0.5968982782239397\n",
      "0.5 0.5968977292368627\n",
      "0.75 0.5968971633273094\n",
      "1.0 0.5968964809073818\n",
      "------------------\n",
      "0.001 0.49290871329017727\n",
      "0.01 0.49290871298539585\n",
      "0.1 0.4929086845398815\n",
      "0.5 0.49290813804804207\n",
      "0.75 0.49290753815710786\n",
      "1.0 0.49290677775529046\n",
      "------------------\n",
      "0.001 0.3787539379466851\n",
      "0.01 0.37875392012227116\n",
      "0.1 0.37875241060554954\n",
      "0.5 0.3787329277123833\n",
      "0.75 0.37871876766614176\n",
      "1.0 0.37870547804838306\n",
      "------------------\n",
      "0.001 0.7506973147934757\n",
      "0.01 0.7506973136319354\n",
      "0.1 0.7506972086330781\n",
      "0.5 0.7506954269694857\n",
      "0.75 0.7506936901241192\n",
      "1.0 0.7506916736611128\n",
      "------------------\n",
      "0.001 0.01983763392161686\n",
      "0.01 0.019837535325928135\n",
      "0.1 0.019828450862805713\n",
      "0.5 0.019665777176268495\n",
      "0.75 0.01950321718332293\n",
      "1.0 0.019314882518966292\n",
      "------------------\n",
      "0.001 0.1751297622786967\n",
      "0.01 0.17512974759033484\n",
      "0.1 0.17512846022244855\n",
      "0.5 0.17510915339406974\n",
      "0.75 0.17509248192232651\n",
      "1.0 0.17507468614395694\n",
      "------------------\n",
      "0.001 0.1667931781498947\n",
      "0.01 0.16679317509693092\n",
      "0.1 0.1667928880710675\n",
      "0.5 0.1667873460571777\n",
      "0.75 0.1667814074139947\n",
      "1.0 0.16677415822966601\n",
      "------------------\n",
      "0.001 0.3087568657202341\n",
      "0.01 0.3087568642759011\n",
      "0.1 0.3087567290489941\n",
      "0.5 0.3087542387474458\n",
      "0.75 0.30875175512550346\n",
      "1.0 0.3087489153085835\n",
      "------------------\n",
      "0.001 0.38082130482961174\n",
      "0.01 0.380821304671176\n",
      "0.1 0.38082128970689655\n",
      "0.5 0.38082100099719085\n",
      "0.75 0.38082069536892904\n",
      "1.0 0.3808203259166289\n",
      "------------------\n",
      "0.001 0.1538312914148493\n",
      "0.01 0.15383122528024018\n",
      "0.1 0.1538250686849436\n",
      "0.5 0.15371444612700225\n",
      "0.75 0.15360709884995571\n",
      "1.0 0.15348721808287602\n",
      "------------------\n",
      "0.001 0.48557824579010384\n",
      "0.01 0.48557824528334803\n",
      "0.1 0.4855781985932974\n",
      "0.5 0.48557738349917456\n",
      "0.75 0.48557660601055197\n",
      "1.0 0.48557574340418097\n",
      "------------------\n",
      "0.001 0.3646582386899322\n",
      "0.01 0.3646582372378981\n",
      "0.1 0.364658112376793\n",
      "0.5 0.36465637881526125\n",
      "0.75 0.3646549894024714\n",
      "1.0 0.364653566661458\n",
      "------------------\n",
      "0.001 0.6577178864298491\n",
      "0.01 0.6577178855069651\n",
      "0.1 0.6577177994042775\n",
      "0.5 0.6577162388191071\n",
      "0.75 0.657714710592422\n",
      "1.0 0.6577129906824652\n",
      "------------------\n",
      "0.001 0.48347736718545864\n",
      "0.01 0.4834773624770783\n",
      "0.1 0.4834769405428032\n",
      "0.5 0.4834700745036658\n",
      "0.75 0.48346367708679355\n",
      "1.0 0.483456474479732\n",
      "------------------\n",
      "0.001 0.43786458026883995\n",
      "0.01 0.43786457972979137\n",
      "0.1 0.4378645337127519\n",
      "0.5 0.4378639170133599\n",
      "0.75 0.4378634463465395\n",
      "1.0 0.43786298621777675\n",
      "------------------\n",
      "0.001 0.21837253521077882\n",
      "0.01 0.2183724949425644\n",
      "0.1 0.21836905357883252\n",
      "0.5 0.21832290898991366\n",
      "0.75 0.21828791269733872\n",
      "1.0 0.21825408221249284\n",
      "------------------\n",
      "0.001 0.0019063946880274463\n",
      "0.01 0.0019063937044974109\n",
      "0.1 0.0019063073388934093\n",
      "0.5 0.0019050204660372438\n",
      "0.75 0.0019039365114243976\n",
      "1.0 0.0019028140324179876\n",
      "------------------\n"
     ]
    }
   ],
   "source": [
    "sub_ridge_preds = np.zeros(sub_class_preds.shape)\n",
    "from sklearn.linear_model import Ridge\n",
    "for cls in np.arange(n_classes):\n",
    "    for alpha in [0.001, 0.01, 0.1, 0.5, 0.75, 1.0]:\n",
    "        y = y_train[:, cls]\n",
    "        X = oof_class_preds\n",
    "        clf = Ridge(alpha=alpha)\n",
    "        clf.fit(X,y)\n",
    "        score_ = clf.score(X, y)\n",
    "        print(alpha, score_)\n",
    "    print('------------------')\n",
    "#         X_test = sub_class_preds[:, cls]\n",
    "#         preds_ = clf.predict(X_test)\n",
    "#         sub_ridge_preds[:,cls] = preds_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_ridge_preds = np.zeros(sub_class_preds.shape)\n",
    "from sklearn.linear_model import Ridge\n",
    "for cls in np.arange(n_classes):\n",
    "    y = y_train[:, cls]\n",
    "    X = oof_class_preds\n",
    "    clf = Ridge(alpha=0.1)\n",
    "    clf.fit(X,y)\n",
    "    X_test = sub_class_preds\n",
    "    preds_ = clf.predict(X_test)\n",
    "    sub_ridge_preds[:,cls] = preds_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.38001867e-02, 1.59430779e-04, 9.98871672e-01, ...,\n",
       "        1.77784316e-03, 1.12266340e-04, 5.20836841e-09],\n",
       "       [2.47062426e-02, 2.68127583e-04, 7.85995722e-04, ...,\n",
       "        6.51888692e-01, 8.71524611e-04, 3.26655725e-05],\n",
       "       [8.41529155e-01, 2.72278007e-04, 3.96186303e-03, ...,\n",
       "        9.23864961e-01, 2.01543609e-03, 1.92988443e-05],\n",
       "       ...,\n",
       "       [6.59056642e-04, 5.12143007e-05, 3.49444263e-05, ...,\n",
       "        1.77463120e-03, 5.20864920e-08, 5.91902866e-09],\n",
       "       [5.01914832e-01, 9.99162483e-01, 2.73049554e-03, ...,\n",
       "        1.16331837e-02, 1.53418808e-04, 1.20560289e-06],\n",
       "       [5.07521251e-01, 3.52088286e-04, 3.01849514e-03, ...,\n",
       "        6.92711103e-01, 1.99362053e-03, 1.05607675e-06]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_class_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11702,)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_class_preds[:, 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.26424064e-01,  8.84581981e-03,  8.85833838e-01, ...,\n",
       "         3.20592330e-02,  4.54385428e-03, -6.92529375e-05],\n",
       "       [ 5.51528260e-02,  2.13827355e-03,  1.63897473e-02, ...,\n",
       "         5.38178358e-01,  1.06812025e-03,  1.39571143e-03],\n",
       "       [ 7.77233272e-01, -1.67743788e-03,  1.87791802e-02, ...,\n",
       "         7.51411388e-01, -1.45306321e-03,  1.27131495e-03],\n",
       "       ...,\n",
       "       [ 2.62432560e-02,  4.66381707e-04,  7.97892029e-03, ...,\n",
       "         2.92185935e-02,  3.12140745e-03,  1.76712611e-04],\n",
       "       [ 4.95625470e-01,  8.71181686e-01,  1.99755452e-02, ...,\n",
       "         3.70837162e-02,  3.03441473e-03,  3.03600332e-05],\n",
       "       [ 4.96285545e-01,  1.04218405e-02,  2.67882221e-02, ...,\n",
       "         5.85205684e-01,  4.37290352e-03,  1.52204091e-06]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_ridge_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11702/11702 [00:00<00:00, 88242.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../submissions/sub12-g.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "predicted = []\n",
    "alpha = 0.35\n",
    "for line in tqdm(sub_ridge_preds):\n",
    "    label_predict = np.arange(28)[line>=alpha]\n",
    "    str_predict_label = ' '.join(str(l) for l in label_predict)\n",
    "    predicted.append(str_predict_label)\n",
    "submit['Predicted'] = predicted\n",
    "name = '../submissions/sub12-g.csv'\n",
    "print(name)\n",
    "submit.to_csv(name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.4.7.1 / client 1.3.8)\n",
      "Successfully submitted to Human Protein Atlas Image ClassificationCPU times: user 372 ms, sys: 201 ms, total: 573 ms\n",
      "Wall time: 17.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!kaggle competitions submit -c human-protein-atlas-image-classification -f ../submissions/sub12-g.csv -m \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.4.7.1 / client 1.3.8)\r\n",
      "fileName      date                 description  status    publicScore  privateScore  \r\n",
      "------------  -------------------  -----------  --------  -----------  ------------  \r\n",
      "sub12-g.csv   2018-10-25 00:55:10               complete  0.433        None          \r\n",
      "sub12-c.csv   2018-10-25 00:45:32               complete  0.469        None          \r\n",
      "sub12-bb.csv  2018-10-25 00:43:34               complete  0.466        None          \r\n",
      "sub12-b.csv   2018-10-25 00:41:50               complete  0.457        None          \r\n",
      "sub12-a.csv   2018-10-25 00:40:56               complete  0.449        None          \r\n",
      "sub11-k.csv   2018-10-24 00:35:39               complete  0.346        None          \r\n",
      "sub11-j.csv   2018-10-24 00:34:46               complete  0.366        None          \r\n",
      "sub11-j.csv   2018-10-24 00:33:17               complete  0.000        None          \r\n",
      "sub11-i.csv   2018-10-24 00:24:24               complete  0.389        None          \r\n",
      "sub11-h.csv   2018-10-24 00:21:18               complete  0.371        None          \r\n",
      "sub11-g.csv   2018-10-23 09:13:19               complete  0.347        None          \r\n",
      "sub11-f.csv   2018-10-23 09:11:15               complete  0.358        None          \r\n",
      "sub11-b.csv   2018-10-23 05:25:32               complete  0.437        None          \r\n",
      "sub12.csv     2018-10-23 05:18:36               complete  0.436        None          \r\n",
      "sub11.csv     2018-10-23 01:07:18               complete  0.431        None          \r\n",
      "sub10.csv     2018-10-22 17:16:40               complete  0.336        None          \r\n",
      "sub9.csv      2018-10-21 20:04:09               complete  0.098        None          \r\n",
      "sub9.csv      2018-10-21 19:44:17               complete  0.073        None          \r\n",
      "sub9.csv      2018-10-21 19:37:30               complete  0.043        None          \r\n",
      "sub9.csv      2018-10-21 19:27:51               complete  0.000        None          \r\n"
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "sleep(10)\n",
    "!kaggle competitions submissions -c human-protein-atlas-image-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11702/11702 [00:00<00:00, 79991.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../submissions/sub12-h.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "predicted = []\n",
    "alpha = 0.4\n",
    "for line in tqdm(sub_ridge_preds):\n",
    "    label_predict = np.arange(28)[line>=alpha]\n",
    "    str_predict_label = ' '.join(str(l) for l in label_predict)\n",
    "    predicted.append(str_predict_label)\n",
    "submit['Predicted'] = predicted\n",
    "name = '../submissions/sub12-h.csv'\n",
    "print(name)\n",
    "submit.to_csv(name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.0 / client 1.3.8)\n",
      "Successfully submitted to Human Protein Atlas Image ClassificationWarning: Looks like you're using an outdated API Version, please consider updating (server 1.5.0 / client 1.3.8)\n",
      "fileName      date                 description  status    publicScore  privateScore  \n",
      "------------  -------------------  -----------  --------  -----------  ------------  \n",
      "sub12-h.csv   2018-10-26 02:07:56               complete  0.389        None          \n",
      "sub12-g.csv   2018-10-25 00:55:10               complete  0.433        None          \n",
      "sub12-c.csv   2018-10-25 00:45:32               complete  0.469        None          \n",
      "sub12-bb.csv  2018-10-25 00:43:34               complete  0.466        None          \n",
      "sub12-b.csv   2018-10-25 00:41:50               complete  0.457        None          \n",
      "sub12-a.csv   2018-10-25 00:40:56               complete  0.449        None          \n",
      "sub11-k.csv   2018-10-24 00:35:39               complete  0.346        None          \n",
      "sub11-j.csv   2018-10-24 00:34:46               complete  0.366        None          \n",
      "sub11-j.csv   2018-10-24 00:33:17               complete  0.000        None          \n",
      "sub11-i.csv   2018-10-24 00:24:24               complete  0.389        None          \n",
      "sub11-h.csv   2018-10-24 00:21:18               complete  0.371        None          \n",
      "sub11-g.csv   2018-10-23 09:13:19               complete  0.347        None          \n",
      "sub11-f.csv   2018-10-23 09:11:15               complete  0.358        None          \n",
      "sub11-b.csv   2018-10-23 05:25:32               complete  0.437        None          \n",
      "sub12.csv     2018-10-23 05:18:36               complete  0.436        None          \n",
      "sub11.csv     2018-10-23 01:07:18               complete  0.431        None          \n",
      "sub10.csv     2018-10-22 17:16:40               complete  0.336        None          \n",
      "sub9.csv      2018-10-21 20:04:09               complete  0.098        None          \n",
      "sub9.csv      2018-10-21 19:44:17               complete  0.073        None          \n",
      "sub9.csv      2018-10-21 19:37:30               complete  0.043        None          \n",
      "CPU times: user 328 ms, sys: 282 ms, total: 610 ms\n",
      "Wall time: 24.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!kaggle competitions submit -c human-protein-atlas-image-classification -f ../submissions/sub12-h.csv -m \"\"\n",
    "from time import sleep\n",
    "sleep(10)\n",
    "!kaggle competitions submissions -c human-protein-atlas-image-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.0 / client 1.3.8)\n",
      "Successfully submitted to Human Protein Atlas Image ClassificationWarning: Looks like you're using an outdated API Version, please consider updating (server 1.5.0 / client 1.3.8)\n",
      "fileName      date                 description  status    publicScore  privateScore  \n",
      "------------  -------------------  -----------  --------  -----------  ------------  \n",
      "sub12-d.csv   2018-10-26 02:09:32               complete  0.466        None          \n",
      "sub12-h.csv   2018-10-26 02:07:56               complete  0.389        None          \n",
      "sub12-g.csv   2018-10-25 00:55:10               complete  0.433        None          \n",
      "sub12-c.csv   2018-10-25 00:45:32               complete  0.469        None          \n",
      "sub12-bb.csv  2018-10-25 00:43:34               complete  0.466        None          \n",
      "sub12-b.csv   2018-10-25 00:41:50               complete  0.457        None          \n",
      "sub12-a.csv   2018-10-25 00:40:56               complete  0.449        None          \n",
      "sub11-k.csv   2018-10-24 00:35:39               complete  0.346        None          \n",
      "sub11-j.csv   2018-10-24 00:34:46               complete  0.366        None          \n",
      "sub11-j.csv   2018-10-24 00:33:17               complete  0.000        None          \n",
      "sub11-i.csv   2018-10-24 00:24:24               complete  0.389        None          \n",
      "sub11-h.csv   2018-10-24 00:21:18               complete  0.371        None          \n",
      "sub11-g.csv   2018-10-23 09:13:19               complete  0.347        None          \n",
      "sub11-f.csv   2018-10-23 09:11:15               complete  0.358        None          \n",
      "sub11-b.csv   2018-10-23 05:25:32               complete  0.437        None          \n",
      "sub12.csv     2018-10-23 05:18:36               complete  0.436        None          \n",
      "sub11.csv     2018-10-23 01:07:18               complete  0.431        None          \n",
      "sub10.csv     2018-10-22 17:16:40               complete  0.336        None          \n",
      "sub9.csv      2018-10-21 20:04:09               complete  0.098        None          \n",
      "sub9.csv      2018-10-21 19:44:17               complete  0.073        None          \n",
      "CPU times: user 352 ms, sys: 328 ms, total: 680 ms\n",
      "Wall time: 26.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!kaggle competitions submit -c human-protein-atlas-image-classification -f ../submissions/sub12-d.csv -m \"\"\n",
    "from time import sleep\n",
    "sleep(10)\n",
    "!kaggle competitions submissions -c human-protein-atlas-image-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hpg",
   "language": "python",
   "name": "hpg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
