{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/mathormad/inceptionv3-baseline-lb-0-379/code\n",
    "# fork of scratch8, 29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.io\n",
    "from skimage.transform import resize\n",
    "from imgaug import augmenters as iaa\n",
    "from tqdm import tqdm\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from sklearn.utils import class_weight, shuffle\n",
    "import keras_metrics\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "SIZE = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/rejpalcz/best-loss-function-for-f1-score-metric/notebook\n",
    "import tensorflow as tf\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    y_pred = K.round(y_pred)\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n",
    "\n",
    "def f1_loss(y_true, y_pred):\n",
    "    \n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(K.binary_crossentropy(y_true, y_pred), axis=-1) + (1 - K.mean(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset info\n",
    "path_to_train = '../data/train/'\n",
    "data = pd.read_csv('../data/train.csv')\n",
    "# path_to_external_data = '../data/external_data/external_data_1/'\n",
    "# edata = pd.read_csv('../data/external_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00070df0-bbc3-11e8-b2bc-ac1f6b6435d0</td>\n",
       "      <td>16 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000a6c98-bb9b-11e8-b2b9-ac1f6b6435d0</td>\n",
       "      <td>7 1 2 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000a9596-bbc4-11e8-b2bc-ac1f6b6435d0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000c99ba-bba4-11e8-b2b9-ac1f6b6435d0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001838f8-bbca-11e8-b2bc-ac1f6b6435d0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Id   Target\n",
       "0  00070df0-bbc3-11e8-b2bc-ac1f6b6435d0     16 0\n",
       "1  000a6c98-bb9b-11e8-b2b9-ac1f6b6435d0  7 1 2 0\n",
       "2  000a9596-bbc4-11e8-b2bc-ac1f6b6435d0        5\n",
       "3  000c99ba-bba4-11e8-b2b9-ac1f6b6435d0        1\n",
       "4  001838f8-bbca-11e8-b2bc-ac1f6b6435d0       18"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_info = []\n",
    "\n",
    "for name, labels in zip(data['Id'], data['Target'].str.split(' ')):\n",
    "    train_dataset_info.append({\n",
    "        'path':os.path.join(path_to_train, name),\n",
    "        'labels':np.array([int(label) for label in labels])})\n",
    "    \n",
    "# for name, labels in zip(edata['id'], edata['labels'].str.strip('[]')):\n",
    "#     labels = labels.split(',')\n",
    "#     train_dataset_info.append({\n",
    "#         'path':os.path.join(path_to_external_data, name),\n",
    "#         'labels':np.array([int(label) for label in labels])})\n",
    "    \n",
    "train_dataset_info = np.array(train_dataset_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([{'path': '../data/train/00070df0-bbc3-11e8-b2bc-ac1f6b6435d0', 'labels': array([16,  0])},\n",
       "       {'path': '../data/train/000a6c98-bb9b-11e8-b2b9-ac1f6b6435d0', 'labels': array([7, 1, 2, 0])},\n",
       "       {'path': '../data/train/000a9596-bbc4-11e8-b2bc-ac1f6b6435d0', 'labels': array([5])},\n",
       "       ...,\n",
       "       {'path': '../data/train/fff189d8-bbab-11e8-b2ba-ac1f6b6435d0', 'labels': array([7])},\n",
       "       {'path': '../data/train/fffdf7e0-bbc4-11e8-b2bc-ac1f6b6435d0', 'labels': array([25,  2, 21])},\n",
       "       {'path': '../data/train/fffe0ffe-bbc0-11e8-b2bb-ac1f6b6435d0', 'labels': array([2, 0])}],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class data_generator:\n",
    "    \n",
    "    def create_train(dataset_info, batch_size, shape, augument=True):\n",
    "        assert shape[2] == 3\n",
    "        while True:\n",
    "            dataset_info = shuffle(dataset_info)\n",
    "            for start in range(0, len(dataset_info), batch_size):\n",
    "                end = min(start + batch_size, len(dataset_info))\n",
    "                batch_images = []\n",
    "                X_train_batch = dataset_info[start:end]\n",
    "                batch_labels = np.zeros((len(X_train_batch), 28))\n",
    "                for i in range(len(X_train_batch)):\n",
    "                    image = data_generator.load_image(\n",
    "                        X_train_batch[i]['path'], shape)\n",
    "#                     image = tdi[i+start]\n",
    "#                     image = cv2.resize(image, (shape[0], shape[1]))\n",
    "                    if augument:\n",
    "                        image = data_generator.augment(image)\n",
    "                    batch_images.append(image/255.)\n",
    "                    batch_labels[i][X_train_batch[i]['labels']] = 1\n",
    "                yield np.array(batch_images, np.float32), batch_labels\n",
    "\n",
    "    def load_image(path, shape):\n",
    "        image_red_ch = Image.open(path+'_red.png')\n",
    "        image_yellow_ch = Image.open(path+'_yellow.png')\n",
    "        image_green_ch = Image.open(path+'_green.png')\n",
    "        image_blue_ch = Image.open(path+'_blue.png')\n",
    "        image1 = np.stack((\n",
    "            np.array(image_red_ch),\n",
    "            np.array(image_green_ch), \n",
    "            np.array(image_blue_ch)), -1)\n",
    "        w, h = 512, 512\n",
    "#         zero_data = np.zeros((h, w), dtype=np.uint8)\n",
    "#         image2 = np.stack((\n",
    "#             np.array(image_red_ch),\n",
    "#             np.array(image_green_ch), \n",
    "#             np.array(image_yellow_ch)), -1)\n",
    "#         image3 = np.stack((\n",
    "#             np.array(image_yellow_ch),\n",
    "#             np.array(image_green_ch), \n",
    "#             np.array(image_blue_ch)), -1)\n",
    "# #         print(image1.shape, image2.shape)\n",
    "#         image = np.vstack((image1, image2, image3))\n",
    "#         print(image.shape)\n",
    "        image =image1\n",
    "#         image = canny_image4(image1)\n",
    "        image = cv2.resize(image, (shape[0], shape[1]))\n",
    "        return image\n",
    "    \n",
    "    def load_image2(path, shape):\n",
    "        image_red_ch = Image.open(path+'_red.png')\n",
    "        image_yellow_ch = Image.open(path+'_yellow.png')\n",
    "        image_green_ch = Image.open(path+'_green.png')\n",
    "        image_blue_ch = Image.open(path+'_blue.png')\n",
    "        image1 = np.stack((\n",
    "            np.array(image_red_ch),\n",
    "            np.array(image_green_ch), \n",
    "            np.array(image_blue_ch)), -1)\n",
    "        w, h = 512, 512\n",
    "#         zero_data = np.zeros((h, w), dtype=np.uint8)\n",
    "#         image2 = np.stack((\n",
    "#             np.array(image_red_ch),\n",
    "#             np.array(image_green_ch), \n",
    "#             np.array(image_yellow_ch)), -1)\n",
    "#         image3 = np.stack((\n",
    "#             np.array(image_yellow_ch),\n",
    "#             np.array(image_green_ch), \n",
    "#             np.array(image_blue_ch)), -1)\n",
    "# #         print(image1.shape, image2.shape)\n",
    "#         image = np.vstack((image1, image2, image3))\n",
    "#         print(image.shape)\n",
    "        image =image1\n",
    "#         image = canny_image4(image1)\n",
    "        image = cv2.resize(image, (shape[0], shape[1]))\n",
    "        return image\n",
    "    \n",
    "    def augment(image):\n",
    "        augment_img = iaa.Sequential([\n",
    "            iaa.OneOf([\n",
    "                iaa.Affine(rotate=0),\n",
    "                iaa.Affine(rotate=90),\n",
    "                iaa.Affine(rotate=180),\n",
    "                iaa.Affine(rotate=270),\n",
    "                iaa.Fliplr(0.5),\n",
    "                iaa.Flipud(0.5),\n",
    "            ])], random_order=True)\n",
    "\n",
    "        image_aug = augment_img.augment_image(image)\n",
    "        return image_aug\n",
    "    def augment2(image):\n",
    "        augment_img = iaa.Sequential([\n",
    "            iaa.OneOf([\n",
    "                    iaa.Fliplr(0.5), # horizontal flips\n",
    "                    iaa.Affine(rotate=0),\n",
    "                    iaa.Affine(rotate=90),\n",
    "                    iaa.Affine(rotate=180),\n",
    "                    iaa.Affine(rotate=270),\n",
    "                    iaa.Flipud(0.5),\n",
    "                    iaa.Crop(percent=(0, 0.1)), # random crops\n",
    "                    # Small gaussian blur with random sigma between 0 and 0.5.\n",
    "                    # But we only blur about 50% of all images.\n",
    "                    iaa.Sometimes(0.5,\n",
    "                        iaa.GaussianBlur(sigma=(0, 0.5))\n",
    "                    ),\n",
    "                    # Strengthen or weaken the contrast in each image.\n",
    "                    iaa.ContrastNormalization((0.75, 1.5)),\n",
    "                    # Add gaussian noise.\n",
    "                    # For 50% of all images, we sample the noise once per pixel.\n",
    "                    # For the other 50% of all images, we sample the noise per pixel AND\n",
    "                    # channel. This can change the color (not only brightness) of the\n",
    "                    # pixels.\n",
    "                    iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.05*255), per_channel=0.5),\n",
    "                    # Make some images brighter and some darker.\n",
    "                    # In 20% of all cases, we sample the multiplier once per channel,\n",
    "                    # which can end up changing the color of the images.\n",
    "                    iaa.Multiply((0.8, 1.2), per_channel=0.2),\n",
    "                    # Apply affine transformations to each image.\n",
    "                    # Scale/zoom them, translate/move them, rotate them and shear them.\n",
    "                    iaa.Affine(\n",
    "                        scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)},\n",
    "                        translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},\n",
    "                        rotate=(-180, 180),\n",
    "                        shear=(-8, 8)\n",
    "                    )\n",
    "                ])], random_order=True)\n",
    "\n",
    "        image_aug = augment_img.augment_image(image)\n",
    "        return image_aug\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, Lambda\n",
    "from keras.layers import GlobalMaxPooling2D, GlobalAveragePooling2D, BatchNormalization, Input, Conv2D\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import metrics\n",
    "from keras.optimizers import Adam \n",
    "from keras import backend as K\n",
    "import keras\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape, n_out):\n",
    "    input_tensor = Input(shape=input_shape)\n",
    "    base_model = ResNet50(include_top=False,\n",
    "                   weights='imagenet',\n",
    "                   input_shape=input_shape)\n",
    "    bn = BatchNormalization(name='bn1')(input_tensor)\n",
    "    x = base_model(bn)\n",
    "    x = Conv2D(8, kernel_size=(1,1), activation='relu', name='cam_conv1')(x)\n",
    "    x = GlobalAveragePooling2D(name='cam')(x)\n",
    "    output = Dense(n_out, activation='sigmoid')(x)\n",
    "    model = Model(input_tensor, output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 512, 512, 3)       0         \n",
      "_________________________________________________________________\n",
      "bn1 (BatchNormalization)     (None, 512, 512, 3)       12        \n",
      "_________________________________________________________________\n",
      "resnet50 (Model)             (None, 16, 16, 2048)      23587712  \n",
      "_________________________________________________________________\n",
      "cam_conv1 (Conv2D)           (None, 16, 16, 8)         16392     \n",
      "_________________________________________________________________\n",
      "cam (GlobalAveragePooling2D) (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 28)                252       \n",
      "=================================================================\n",
      "Total params: 23,604,368\n",
      "Trainable params: 23,551,242\n",
      "Non-trainable params: 53,126\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# warm up model\n",
    "model = create_model(\n",
    "    input_shape=(SIZE,SIZE,3), \n",
    "    n_out=28)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(loss=f1_loss,\n",
    "#             optimizer=Adam(lr=1e-4),\n",
    "#             metrics=[f1])\n",
    "# model.load_weights('../cache/IV3-34-maximus.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create callbacks list\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "epochs = 10; batch_size = 16\n",
    "checkpoint = ModelCheckpoint('../cache/R50-54-maximus.h5', monitor='val_loss', verbose=1, \n",
    "                             save_best_only=True, mode='min', save_weights_only = True)\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, \n",
    "                                   verbose=1, mode='auto', epsilon=0.0001)\n",
    "early = EarlyStopping(monitor=\"val_loss\", \n",
    "                      mode=\"min\", \n",
    "                      patience=6)\n",
    "callbacks_list = [checkpoint, early, reduceLROnPlat]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# split data into train, valid\n",
    "indexes = np.arange(train_dataset_info.shape[0])\n",
    "np.random.shuffle(indexes)\n",
    "train_indexes, valid_indexes = train_test_split(indexes, test_size=0.15, random_state=8)\n",
    "\n",
    "# create train and valid datagens\n",
    "train_generator = data_generator.create_train(\n",
    "    train_dataset_info[train_indexes], batch_size, (SIZE,SIZE,3), augument=True)\n",
    "validation_generator = data_generator.create_train(\n",
    "    train_dataset_info[valid_indexes], 32, (SIZE,SIZE,3), augument=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# warm up model\n",
    "# model = create_model(\n",
    "#     input_shape=(SIZE,SIZE,3), \n",
    "#     n_out=28)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "model.layers[-1].trainable = True\n",
    "model.layers[-2].trainable = True\n",
    "model.layers[-3].trainable = True\n",
    "# model.layers[-4].trainable = True\n",
    "# model.layers[-5].trainable = True\n",
    "# model.layers[-6].trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels = np.zeros((28))\n",
    "# labels[0] = 1\n",
    "model.compile(\n",
    "    loss=f1_loss, \n",
    "    optimizer=Adam(1e-03),\n",
    "    metrics=[f1])\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1651/1651 [==============================] - 556s 337ms/step - loss: 1.1296 - f1: 0.0397 - val_loss: 1.1550 - val_f1: 0.0213\n",
      "Epoch 2/2\n",
      "1651/1651 [==============================] - 532s 322ms/step - loss: 1.0581 - f1: 0.0855 - val_loss: 1.2984 - val_f1: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f192b08e748>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=np.ceil(float(len(train_indexes)) / float(batch_size)),\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=np.ceil(float(len(valid_indexes)) / float(batch_size)),\n",
    "    epochs=2, \n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "3302/3302 [==============================] - 1242s 376ms/step - loss: 1.0262 - f1: 0.1107 - val_loss: 0.9793 - val_f1: 0.1788\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.97928, saving model to ../cache/R50-54-maximus.h5\n",
      "Epoch 2/120\n",
      "3302/3302 [==============================] - 1224s 371ms/step - loss: 0.9836 - f1: 0.1446 - val_loss: 0.9667 - val_f1: 0.1991\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.97928 to 0.96671, saving model to ../cache/R50-54-maximus.h5\n",
      "Epoch 3/120\n",
      "3302/3302 [==============================] - 1218s 369ms/step - loss: 0.9631 - f1: 0.1572 - val_loss: 0.9336 - val_f1: 0.2135\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.96671 to 0.93363, saving model to ../cache/R50-54-maximus.h5\n",
      "Epoch 4/120\n",
      "3302/3302 [==============================] - 1222s 370ms/step - loss: 0.9488 - f1: 0.1661 - val_loss: 0.9143 - val_f1: 0.2294\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.93363 to 0.91434, saving model to ../cache/R50-54-maximus.h5\n",
      "Epoch 5/120\n",
      "3302/3302 [==============================] - 1225s 371ms/step - loss: 0.9389 - f1: 0.1727 - val_loss: 0.9154 - val_f1: 0.2276\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.91434\n",
      "Epoch 6/120\n",
      "3302/3302 [==============================] - 1229s 372ms/step - loss: 0.9294 - f1: 0.1783 - val_loss: 0.9044 - val_f1: 0.2421\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.91434 to 0.90441, saving model to ../cache/R50-54-maximus.h5\n",
      "Epoch 7/120\n",
      "3302/3302 [==============================] - 1232s 373ms/step - loss: 0.9224 - f1: 0.1828 - val_loss: 0.9200 - val_f1: 0.2365\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.90441\n",
      "Epoch 8/120\n",
      "3302/3302 [==============================] - 1232s 373ms/step - loss: 0.9159 - f1: 0.1870 - val_loss: 0.9141 - val_f1: 0.2450\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.90441\n",
      "Epoch 9/120\n",
      "3302/3302 [==============================] - 1225s 371ms/step - loss: 0.9096 - f1: 0.1907 - val_loss: 0.9008 - val_f1: 0.2467\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.90441 to 0.90077, saving model to ../cache/R50-54-maximus.h5\n",
      "Epoch 10/120\n",
      "3302/3302 [==============================] - 1228s 372ms/step - loss: 0.9074 - f1: 0.1911 - val_loss: 0.8955 - val_f1: 0.2473\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.90077 to 0.89552, saving model to ../cache/R50-54-maximus.h5\n",
      "Epoch 11/120\n",
      "3302/3302 [==============================] - 1217s 369ms/step - loss: 0.9016 - f1: 0.1939 - val_loss: 0.8885 - val_f1: 0.2564\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.89552 to 0.88854, saving model to ../cache/R50-54-maximus.h5\n",
      "Epoch 12/120\n",
      "3302/3302 [==============================] - 1229s 372ms/step - loss: 0.8953 - f1: 0.1985 - val_loss: 0.8864 - val_f1: 0.2525\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.88854 to 0.88645, saving model to ../cache/R50-54-maximus.h5\n",
      "Epoch 13/120\n",
      "3302/3302 [==============================] - 1234s 374ms/step - loss: 0.8924 - f1: 0.2000 - val_loss: 0.8777 - val_f1: 0.2561\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.88645 to 0.87769, saving model to ../cache/R50-54-maximus.h5\n",
      "Epoch 14/120\n",
      "3302/3302 [==============================] - 1234s 374ms/step - loss: 0.8873 - f1: 0.2026 - val_loss: 0.8596 - val_f1: 0.2638\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.87769 to 0.85956, saving model to ../cache/R50-54-maximus.h5\n",
      "Epoch 15/120\n",
      "3302/3302 [==============================] - 1230s 373ms/step - loss: 0.8845 - f1: 0.2034 - val_loss: 0.8801 - val_f1: 0.2624\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.85956\n",
      "Epoch 16/120\n",
      "3302/3302 [==============================] - 1235s 374ms/step - loss: 0.8791 - f1: 0.2067 - val_loss: 0.8818 - val_f1: 0.2571\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.85956\n",
      "Epoch 17/120\n",
      "3302/3302 [==============================] - 1234s 374ms/step - loss: 0.8763 - f1: 0.2086 - val_loss: 0.8773 - val_f1: 0.2615\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.85956\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "Epoch 18/120\n",
      "3302/3302 [==============================] - 1230s 373ms/step - loss: 0.8543 - f1: 0.2188 - val_loss: 0.8567 - val_f1: 0.2706\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.85956 to 0.85675, saving model to ../cache/R50-54-maximus.h5\n",
      "Epoch 19/120\n",
      "3302/3302 [==============================] - 1218s 369ms/step - loss: 0.8473 - f1: 0.2231 - val_loss: 0.8535 - val_f1: 0.2733\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.85675 to 0.85353, saving model to ../cache/R50-54-maximus.h5\n",
      "Epoch 20/120\n",
      "3302/3302 [==============================] - 1217s 369ms/step - loss: 0.8445 - f1: 0.2241 - val_loss: 0.8493 - val_f1: 0.2749\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.85353 to 0.84935, saving model to ../cache/R50-54-maximus.h5\n",
      "Epoch 21/120\n",
      "3302/3302 [==============================] - 1217s 369ms/step - loss: 0.8398 - f1: 0.2268 - val_loss: 0.8510 - val_f1: 0.2725\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.84935\n",
      "Epoch 22/120\n",
      "3302/3302 [==============================] - 1218s 369ms/step - loss: 0.8384 - f1: 0.2276 - val_loss: 0.8517 - val_f1: 0.2732\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.84935\n",
      "Epoch 23/120\n",
      "3302/3302 [==============================] - 1214s 368ms/step - loss: 0.8354 - f1: 0.2286 - val_loss: 0.8507 - val_f1: 0.2744\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.84935\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "Epoch 24/120\n",
      "3302/3302 [==============================] - 1217s 369ms/step - loss: 0.8315 - f1: 0.2306 - val_loss: 0.8514 - val_f1: 0.2750\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.84935\n",
      "Epoch 25/120\n",
      "3302/3302 [==============================] - 1229s 372ms/step - loss: 0.8313 - f1: 0.2305 - val_loss: 0.8499 - val_f1: 0.2736\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.84935\n",
      "Epoch 26/120\n",
      "3302/3302 [==============================] - 1226s 371ms/step - loss: 0.8307 - f1: 0.2311 - val_loss: 0.8519 - val_f1: 0.2744\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.84935\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f19076b7438>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train all layers\n",
    "epochs=120\n",
    "batch_size=8\n",
    "# create train and valid datagens\n",
    "train_generator = data_generator.create_train(\n",
    "    train_dataset_info[train_indexes], batch_size, (SIZE,SIZE,3), augument=True)\n",
    "validation_generator = data_generator.create_train(\n",
    "    train_dataset_info[valid_indexes], 16, (SIZE,SIZE,3), augument=True)\n",
    "for layer in model.layers:\n",
    "    layer.trainable = True\n",
    "model.compile(loss=f1_loss,\n",
    "            optimizer=Adam(lr=1e-4),\n",
    "            metrics=[f1])\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=np.ceil(float(len(train_indexes)) / float(batch_size)),\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=np.ceil(float(len(valid_indexes)) / float(batch_size)),\n",
    "    epochs=epochs, \n",
    "    verbose=1,\n",
    "    callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = load_image(train_dataset_info[1]['path'])\n",
    "preprocessed_input = image[np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_predict = model.predict(preprocessed_input)[0]\n",
    "# draw_predict.append(score_predict)\n",
    "label_predict = np.arange(28)[score_predict>=0.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_predict[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the symbolic outputs of each \"key\" layer (we gave them unique names).\n",
    "layer_dict = dict([(layer.name, layer) for layer in model.layers[1:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize2(x):\n",
    "    # utility function to normalize a tensor by its L2 norm\n",
    "    return x / (K.sqrt(K.mean(K.square(x))) + K.epsilon())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = model.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tqdm import tqdm_notebook\n",
    "kept_filters = []\n",
    "for filter_index in tqdm_notebook(range(8)):\n",
    "    # we only scan through the first 200 filters,\n",
    "    # but there are actually 512 of them\n",
    "#     print('Processing filter %d' % filter_index)\n",
    "    start_time = time.time()\n",
    "\n",
    "    # we build a loss function that maximizes the activation\n",
    "    # of the nth filter of the layer considered\n",
    "    layer_output = layer_dict[layer_name].output\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        loss = K.mean(layer_output[:, filter_index, :, :])\n",
    "    else:\n",
    "        loss = K.mean(layer_output[:, filter_index])\n",
    "\n",
    "    # we compute the gradient of the input picture wrt this loss\n",
    "    grads = K.gradients(loss, input_img)[0]\n",
    "\n",
    "    # normalization trick: we normalize the gradient\n",
    "    grads = normalize2(grads)\n",
    "\n",
    "    # this function returns the loss and grads given the input picture\n",
    "    iterate = K.function([input_img], [loss, grads])\n",
    "\n",
    "    # step size for gradient ascent\n",
    "    step = 1.\n",
    "\n",
    "    # we start from a gray image with some random noise\n",
    "#     if K.image_data_format() == 'channels_first':\n",
    "#         input_img_data = np.random.random((1, 3, img_width, img_height))\n",
    "#     else:\n",
    "#         input_img_data = np.random.random((1, img_width, img_height, 3))\n",
    "    \n",
    "    input_img_data = (input_img_data - 0.5) * 20 + 128\n",
    "\n",
    "    # we run gradient ascent for 20 steps\n",
    "    for i in range(100):\n",
    "        loss_value, grads_value = iterate([input_img_data])\n",
    "        input_img_data += grads_value * step\n",
    "\n",
    "#         print('Current loss value:', loss_value)\n",
    "        if loss_value <= 0.:\n",
    "            # some filters get stuck to 0, we can skip them\n",
    "            break\n",
    "\n",
    "    # decode the resulting input image\n",
    "    if loss_value > 0:\n",
    "        img = deprocess_image(input_img_data[0])\n",
    "        kept_filters.append((img, loss_value))\n",
    "    end_time = time.time()\n",
    "#     print('Filter %d processed in %ds' % (filter_index, end_time - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will stich the best 64 filters on a 8 x 8 grid.\n",
    "n = 3\n",
    "img_width = 512\n",
    "img_height = 512\n",
    "\n",
    "# the filters that have the highest loss are assumed to be better-looking.\n",
    "# we will only keep the top 64 filters.\n",
    "kept_filters.sort(key=lambda x: x[1], reverse=True)\n",
    "kept_filters = kept_filters[:n * n]\n",
    "\n",
    "# build a black picture with enough space for\n",
    "# our 8 x 8 filters of size 128 x 128, with a 5px margin in between\n",
    "margin = 5\n",
    "width = n * img_width + (n - 1) * margin\n",
    "height = n * img_height + (n - 1) * margin\n",
    "stitched_filters = np.zeros((width, height, 3))\n",
    "\n",
    "# fill the picture with our saved filters\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "#         print(i*n+j)\n",
    "        img, loss = kept_filters[i * n + j]\n",
    "        width_margin = (img_width + margin) * i\n",
    "        height_margin = (img_height + margin) * j\n",
    "        stitched_filters[\n",
    "            width_margin: width_margin + img_width,\n",
    "            height_margin: height_margin + img_height, :] = img\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.imshow(stitched_filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3\n",
    "image = np.zeros((512,512,3))\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        img, loss = kept_filters[i * n + j]\n",
    "        image = image + img\n",
    "img = img/8\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tqdm import tqdm_notebook\n",
    "single_label = []\n",
    "# kept_filters = []\n",
    "kept_filters = np.memmap('../cache/train_cam', dtype='float32', mode='w+', shape=(31072, 8, 512,512,3))\n",
    "filters_loss = np.memmap('../cache/train_loss', dtype='float32', mode='w+', shape=(31072, 8))\n",
    "for filter_index in tqdm_notebook(range(8)):\n",
    "    # we only scan through the first 200 filters,\n",
    "    # but there are actually 512 of them\n",
    "#     print('Processing filter %d' % filter_index)\n",
    "#     start_time = time.time()\n",
    "\n",
    "    # we build a loss function that maximizes the activation\n",
    "    # of the nth filter of the layer considered\n",
    "    layer_output = layer_dict[layer_name].output\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        loss = K.mean(layer_output[:, filter_index, :, :])\n",
    "    else:\n",
    "        loss = K.mean(layer_output[:, filter_index])\n",
    "\n",
    "    # we compute the gradient of the input picture wrt this loss\n",
    "    grads = K.gradients(loss, input_img)[0]\n",
    "\n",
    "    # normalization trick: we normalize the gradient\n",
    "    grads = normalize2(grads)\n",
    "\n",
    "    # this function returns the loss and grads given the input picture\n",
    "    iterate = K.function([input_img], [loss, grads])\n",
    "\n",
    "    # step size for gradient ascent\n",
    "    step = 1.\n",
    "\n",
    "    # we start from a gray image with some random noise\n",
    "#     if K.image_data_format() == 'channels_first':\n",
    "#         input_img_data = np.random.random((1, 3, img_width, img_height))\n",
    "#     else:\n",
    "#         input_img_data = np.random.random((1, img_width, img_height, 3))\n",
    "    for ii in range(len(train_dataset_info)):\n",
    "        path = train_dataset_info[ii]['path']\n",
    "        labels = train_dataset_info[ii]['labels']\n",
    "#         if len(labels) > 1:\n",
    "#             continue\n",
    "#         single_label.append(ii)\n",
    "        \n",
    "        image = load_image(path)\n",
    "        input_img_data = image[np.newaxis]\n",
    "        input_img_data = (input_img_data - 0.5) * 20 + 128\n",
    "\n",
    "        # we run gradient ascent for 20 steps\n",
    "        for _ in range(50):\n",
    "            loss_value, grads_value = iterate([input_img_data])\n",
    "            input_img_data += grads_value * step\n",
    "\n",
    "#         print('Current loss value:', loss_value)\n",
    "            if loss_value <= 0.:\n",
    "                # some filters get stuck to 0, we can skip them\n",
    "                break\n",
    "\n",
    "        # decode the resulting input image\n",
    "        img = np.zeros((512,512,3))\n",
    "        kept_filters[ii][filter_index] = img\n",
    "        filters_loss[ii][filter_index] = 0.0\n",
    "        if loss_value > 0:\n",
    "            img = deprocess_image(input_img_data[0])\n",
    "#             kept_filters.append(img)\n",
    "            kept_filters[ii][filter_index] = img\n",
    "            filters_loss[ii][filter_index] = loss_value\n",
    "#     end_time = time.time() \n",
    "#     print('Filter %d processed in %ds' % (filter_index, end_time - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 279/11702 [00:16<12:04, 15.76it/s]"
     ]
    }
   ],
   "source": [
    "# Create submit\n",
    "submit = pd.read_csv('../data/sample_submission.csv')\n",
    "predicted = []\n",
    "draw_predict = []\n",
    "# model = create_model(\n",
    "#     input_shape=(SIZE,SIZE,3), \n",
    "#     n_out=28)\n",
    "# for layer in model.layers:\n",
    "#     layer.trainable = True\n",
    "# model.compile(loss=f1_loss,\n",
    "#             optimizer=Adam(lr=1e-4),\n",
    "#             metrics=[f1])\n",
    "model.load_weights('../cache/R50-54-maximus.h5')\n",
    "for name in tqdm(submit['Id']):\n",
    "    path = os.path.join('../data/test/', name)\n",
    "    image = data_generator.load_image(path, (SIZE,SIZE,3))/255.\n",
    "    score_predict = model.predict(image[np.newaxis])[0]\n",
    "    draw_predict.append(score_predict)\n",
    "    label_predict = np.arange(28)[score_predict>=0.5]\n",
    "    str_predict_label = ' '.join(str(l) for l in label_predict)\n",
    "    predicted.append(str_predict_label)\n",
    "\n",
    "submit['Predicted'] = predicted\n",
    "# np.save('../cache/draw_predict_InceptionV3-30.npy', score_predict)\n",
    "# submit.to_csv('../submissions/submit_InceptionV3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11702/11702 [00:00<00:00, 90685.89it/s]\n"
     ]
    }
   ],
   "source": [
    "predicted = []\n",
    "for line in tqdm(draw_predict):\n",
    "    label_predict = np.arange(28)[line>=0.5]\n",
    "    str_predict_label = ' '.join(str(l) for l in label_predict)\n",
    "    predicted.append(str_predict_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv('../submissions/sub54-max-a.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/1855095/how-to-create-a-zip-archive-of-a-directory\n",
    "def backup_project_as_zip(project_dir, zip_file):\n",
    "    assert(os.path.isdir(project_dir))\n",
    "    assert(os.path.isdir(os.path.dirname(zip_file)))\n",
    "    shutil.make_archive(zip_file.replace('.zip',''), 'zip', project_dir)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-12 12:25:06.153704\n"
     ]
    }
   ],
   "source": [
    "import datetime, shutil\n",
    "now = datetime.datetime.now()\n",
    "print(now)\n",
    "PROJECT_PATH = '/home/watts/lal/Kaggle/kagglehp/scripts_nbs'\n",
    "backup_project_as_zip(PROJECT_PATH, '../cache/code.scripts_nbs.%s.zip'%now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 479k/479k [00:13<00:00, 36.8kB/s]\n",
      "Successfully submitted to Human Protein Atlas Image ClassificationCPU times: user 410 ms, sys: 162 ms, total: 572 ms\n",
      "Wall time: 17.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!kaggle competitions submit -c human-protein-atlas-image-classification -f ../submissions/sub48-max-a.csv -m \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileName          date                 description  status    publicScore  privateScore  \r\n",
      "----------------  -------------------  -----------  --------  -----------  ------------  \r\n",
      "sub48-max-a.csv   2018-12-12 06:55:45               complete  0.457        None          \r\n",
      "sub44-max-t.csv   2018-12-10 20:51:55               complete  0.019        None          \r\n",
      "sub41-t-l.csv     2018-12-08 09:27:37               complete  0.541        None          \r\n",
      "sub41-max-b.csv   2018-12-08 08:04:32               complete  0.478        None          \r\n",
      "sub41-max-a.csv   2018-12-08 08:03:03               complete  0.479        None          \r\n",
      "sub41-c.csv       2018-12-07 01:29:14               complete  0.493        None          \r\n",
      "sub41-f.csv       2018-12-07 01:28:39               complete  0.481        None          \r\n",
      "sub41-t.csv       2018-12-07 01:27:50               complete  0.498        None          \r\n",
      "sub41-v.csv       2018-12-07 01:27:04               complete  0.484        None          \r\n",
      "sub41.csv         2018-12-07 01:26:29               complete  0.494        None          \r\n",
      "sub33-mag-05.csv  2018-12-06 12:29:28               complete  0.492        None          \r\n",
      "sub33-mag-c.csv   2018-12-06 12:28:48               complete  0.491        None          \r\n",
      "sub33-mag-f.csv   2018-12-06 12:28:08               complete  0.488        None          \r\n",
      "sub33-mag-t.csv   2018-12-06 12:27:36               complete  0.481        None          \r\n",
      "sub33-mag.csv     2018-12-06 12:26:29               complete  0.491        None          \r\n",
      "sub40-a.csv       2018-12-02 07:28:08               complete  0.447        None          \r\n",
      "sub40-a.csv       2018-12-02 07:18:27               complete  0.477        None          \r\n",
      "sub41-a.csv       2018-12-01 19:07:17               complete  0.477        None          \r\n",
      "sub40-a.csv       2018-11-29 14:06:01               complete  0.417        None          \r\n",
      "sub38-a.csv       2018-11-29 02:08:54               complete  0.356        None          \r\n"
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "sleep(10)\n",
    "!kaggle competitions submissions -c human-protein-atlas-image-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11702/11702 [00:00<00:00, 86817.64it/s]\n"
     ]
    }
   ],
   "source": [
    "predicted = []\n",
    "for line in tqdm(draw_predict):\n",
    "    label_predict = np.arange(28)[line>=0.35]\n",
    "    str_predict_label = ' '.join(str(l) for l in label_predict)\n",
    "    predicted.append(str_predict_label)\n",
    "submit['Predicted'] = predicted\n",
    "submit.to_csv('../submissions/sub48-max-b.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 470k/470k [00:14<00:00, 33.7kB/s]\n",
      "Successfully submitted to Human Protein Atlas Image ClassificationfileName          date                 description  status    publicScore  privateScore  \n",
      "----------------  -------------------  -----------  --------  -----------  ------------  \n",
      "sub48-max-b.csv   2018-12-12 06:57:44               complete  0.449        None          \n",
      "sub48-max-a.csv   2018-12-12 06:55:45               complete  0.457        None          \n",
      "sub44-max-t.csv   2018-12-10 20:51:55               complete  0.019        None          \n",
      "sub41-t-l.csv     2018-12-08 09:27:37               complete  0.541        None          \n",
      "sub41-max-b.csv   2018-12-08 08:04:32               complete  0.478        None          \n",
      "sub41-max-a.csv   2018-12-08 08:03:03               complete  0.479        None          \n",
      "sub41-c.csv       2018-12-07 01:29:14               complete  0.493        None          \n",
      "sub41-f.csv       2018-12-07 01:28:39               complete  0.481        None          \n",
      "sub41-t.csv       2018-12-07 01:27:50               complete  0.498        None          \n",
      "sub41-v.csv       2018-12-07 01:27:04               complete  0.484        None          \n",
      "sub41.csv         2018-12-07 01:26:29               complete  0.494        None          \n",
      "sub33-mag-05.csv  2018-12-06 12:29:28               complete  0.492        None          \n",
      "sub33-mag-c.csv   2018-12-06 12:28:48               complete  0.491        None          \n",
      "sub33-mag-f.csv   2018-12-06 12:28:08               complete  0.488        None          \n",
      "sub33-mag-t.csv   2018-12-06 12:27:36               complete  0.481        None          \n",
      "sub33-mag.csv     2018-12-06 12:26:29               complete  0.491        None          \n",
      "sub40-a.csv       2018-12-02 07:28:08               complete  0.447        None          \n",
      "sub40-a.csv       2018-12-02 07:18:27               complete  0.477        None          \n",
      "sub41-a.csv       2018-12-01 19:07:17               complete  0.477        None          \n",
      "sub40-a.csv       2018-11-29 14:06:01               complete  0.417        None          \n",
      "CPU times: user 427 ms, sys: 282 ms, total: 709 ms\n",
      "Wall time: 29.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!kaggle competitions submit -c human-protein-atlas-image-classification -f ../submissions/sub48-max-b.csv -m \"\"\n",
    "\n",
    "from time import sleep\n",
    "sleep(10)\n",
    "!kaggle competitions submissions -c human-protein-atlas-image-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11702/11702 [08:21<00:00, 23.34it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create submit\n",
    "\n",
    "submit = pd.read_csv('../data/sample_submission.csv')\n",
    "predicted = []\n",
    "draw_predict = []\n",
    "model = create_model(\n",
    "    input_shape=(SIZE,SIZE,3), \n",
    "    n_out=28)\n",
    "for layer in model.layers:\n",
    "    layer.trainable = True\n",
    "model.compile(loss=f1_loss,\n",
    "            optimizer=Adam(lr=1e-4),\n",
    "            metrics=[f1])\n",
    "model.load_weights('../cache/IV3-34-maximus.h5')\n",
    "for name in tqdm(submit['Id']):\n",
    "    path = os.path.join('../data/test/', name)\n",
    "    image = data_generator.load_image(path, (SIZE,SIZE,3))/255.\n",
    "    score_predict = model.predict(image[np.newaxis])[0]\n",
    "    draw_predict.append(score_predict)\n",
    "    label_predict = np.arange(28)[score_predict>=0.35]\n",
    "    str_predict_label = ' '.join(str(l) for l in label_predict)\n",
    "    predicted.append(str_predict_label)\n",
    "\n",
    "submit['Predicted'] = predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv('../submissions/sub34a-max.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 472k/472k [00:12<00:00, 37.5kB/s]\n",
      "Successfully submitted to Human Protein Atlas Image ClassificationfileName        date                 description  status    publicScore  privateScore  \n",
      "--------------  -------------------  -----------  --------  -----------  ------------  \n",
      "sub34a-max.csv  2018-11-24 18:50:22               complete  0.469        None          \n",
      "sub34-max.csv   2018-11-24 17:27:36               complete  0.473        None          \n",
      "sub33-h.csv     2018-11-24 06:48:41               complete  0.464        None          \n",
      "sub33-g.csv     2018-11-24 06:46:19               complete  0.472        None          \n",
      "sub33-c.csv     2018-11-23 11:48:41               complete  0.493        None          \n",
      "sub33-bb.csv    2018-11-23 11:47:32               complete  0.493        None          \n",
      "sub33-b.csv     2018-11-23 11:46:26               complete  0.498        None          \n",
      "sub33-a.csv     2018-11-23 11:45:09               complete  0.496        None          \n",
      "sub36-a.csv     2018-11-23 10:12:45               complete  0.287        None          \n",
      "sub35b-c.csv    2018-11-22 08:00:23               complete  0.417        None          \n",
      "sub35b-b.csv    2018-11-22 07:59:44               complete  0.415        None          \n",
      "sub35b-a.csv    2018-11-22 07:58:57               complete  0.432        None          \n",
      "sub35-a.csv     2018-11-20 06:54:01               complete  0.315        None          \n",
      "sub8i1-e.csv    2018-11-19 07:12:37               complete  0.457        None          \n",
      "sub8i1-d.csv    2018-11-19 07:09:46               complete  0.459        None          \n",
      "sub8i1-c.csv    2018-11-19 07:08:49               complete  0.462        None          \n",
      "sub8i1-b.csv    2018-11-19 07:08:05               complete  0.462        None          \n",
      "sub8i1-a.csv    2018-11-19 07:07:14               complete  0.460        None          \n",
      "sub32-c.csv     2018-11-15 11:47:19               complete  0.463        None          \n",
      "sub32-bb.csv    2018-11-15 11:46:01               complete  0.465        None          \n",
      "CPU times: user 454 ms, sys: 214 ms, total: 668 ms\n",
      "Wall time: 1min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!kaggle competitions submit -c human-protein-atlas-image-classification -f ../submissions/sub34a-max.csv -m \"\"\n",
    "\n",
    "from time import sleep\n",
    "sleep(60)\n",
    "!kaggle competitions submissions -c human-protein-atlas-image-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11702/11702 [09:22<00:00, 20.79it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create submit\n",
    "\n",
    "submit = pd.read_csv('../data/sample_submission.csv')\n",
    "predicted = []\n",
    "draw_predict = []\n",
    "model = create_model(\n",
    "    input_shape=(SIZE,SIZE,3), \n",
    "    n_out=28)\n",
    "for layer in model.layers:\n",
    "    layer.trainable = True\n",
    "model.compile(loss=f1_loss,\n",
    "            optimizer=Adam(lr=1e-4),\n",
    "            metrics=[f1])\n",
    "model.load_weights('../cache/IV3-34-maximus.h5')\n",
    "for name in tqdm(submit['Id']):\n",
    "    path = os.path.join('../data/test/', name)\n",
    "    image = data_generator.load_image(path, (SIZE,SIZE,3))\n",
    "    image = data_generator.augment(image)\n",
    "    image = image/255.\n",
    "    score_predict = model.predict(image[np.newaxis])[0]\n",
    "    draw_predict.append(score_predict)\n",
    "    label_predict = np.arange(28)[score_predict>=0.25]\n",
    "    str_predict_label = ' '.join(str(l) for l in label_predict)\n",
    "    predicted.append(str_predict_label)\n",
    "\n",
    "submit['Predicted'] = predicted\n",
    "\n",
    "submit.to_csv('../submissions/sub34b-max.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 476k/476k [00:13<00:00, 36.9kB/s]\n",
      "Successfully submitted to Human Protein Atlas Image ClassificationfileName        date                 description  status    publicScore  privateScore  \n",
      "--------------  -------------------  -----------  --------  -----------  ------------  \n",
      "sub34b-max.csv  2018-11-24 19:03:59               complete  0.459        None          \n",
      "sub34a-max.csv  2018-11-24 18:50:22               complete  0.469        None          \n",
      "sub34-max.csv   2018-11-24 17:27:36               complete  0.473        None          \n",
      "sub33-h.csv     2018-11-24 06:48:41               complete  0.464        None          \n",
      "sub33-g.csv     2018-11-24 06:46:19               complete  0.472        None          \n",
      "sub33-c.csv     2018-11-23 11:48:41               complete  0.493        None          \n",
      "sub33-bb.csv    2018-11-23 11:47:32               complete  0.493        None          \n",
      "sub33-b.csv     2018-11-23 11:46:26               complete  0.498        None          \n",
      "sub33-a.csv     2018-11-23 11:45:09               complete  0.496        None          \n",
      "sub36-a.csv     2018-11-23 10:12:45               complete  0.287        None          \n",
      "sub35b-c.csv    2018-11-22 08:00:23               complete  0.417        None          \n",
      "sub35b-b.csv    2018-11-22 07:59:44               complete  0.415        None          \n",
      "sub35b-a.csv    2018-11-22 07:58:57               complete  0.432        None          \n",
      "sub35-a.csv     2018-11-20 06:54:01               complete  0.315        None          \n",
      "sub8i1-e.csv    2018-11-19 07:12:37               complete  0.457        None          \n",
      "sub8i1-d.csv    2018-11-19 07:09:46               complete  0.459        None          \n",
      "sub8i1-c.csv    2018-11-19 07:08:49               complete  0.462        None          \n",
      "sub8i1-b.csv    2018-11-19 07:08:05               complete  0.462        None          \n",
      "sub8i1-a.csv    2018-11-19 07:07:14               complete  0.460        None          \n",
      "sub32-c.csv     2018-11-15 11:47:19               complete  0.463        None          \n",
      "CPU times: user 426 ms, sys: 230 ms, total: 656 ms\n",
      "Wall time: 1min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!kaggle competitions submit -c human-protein-atlas-image-classification -f ../submissions/sub34b-max.csv -m \"\"\n",
    "\n",
    "from time import sleep\n",
    "sleep(60)\n",
    "!kaggle competitions submissions -c human-protein-atlas-image-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submit\n",
    "submit = pd.read_csv('../data/sample_submission.csv')\n",
    "predicted = []\n",
    "draw_predict = []\n",
    "# model = create_model(\n",
    "#     input_shape=(SIZE,SIZE,3), \n",
    "#     n_out=28)\n",
    "# for layer in model.layers:\n",
    "#     layer.trainable = True\n",
    "# model.compile(loss=f1_loss,\n",
    "#             optimizer=Adam(lr=1e-4),\n",
    "#             metrics=[f1])\n",
    "model.load_weights('../cache/IV3-34-maximus.h5')\n",
    "for name in tqdm(submit['Id']):\n",
    "    path = os.path.join('../data/test/', name)\n",
    "    image = data_generator.load_image(path, (SIZE,SIZE,3))\n",
    "    image = data_generator.augment(image)\n",
    "    image = image/255.\n",
    "    score_predict = model.predict(image[np.newaxis])[0]\n",
    "    draw_predict.append(score_predict)\n",
    "    label_predict = np.arange(28)[score_predict>=0.2]\n",
    "    str_predict_label = ' '.join(str(l) for l in label_predict)\n",
    "    predicted.append(str_predict_label)\n",
    "\n",
    "submit['Predicted'] = predicted\n",
    "# np.save('../cache/draw_predict_InceptionV3-30.npy', score_predict)\n",
    "# submit.to_csv('../submissions/submit_InceptionV3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileName       date                 description  status    publicScore  privateScore  \r\n",
      "-------------  -------------------  -----------  --------  -----------  ------------  \r\n",
      "sub34-max.csv  2018-11-24 17:27:36               complete  0.473        None          \r\n",
      "sub33-h.csv    2018-11-24 06:48:41               complete  0.464        None          \r\n",
      "sub33-g.csv    2018-11-24 06:46:19               complete  0.472        None          \r\n",
      "sub33-c.csv    2018-11-23 11:48:41               complete  0.493        None          \r\n",
      "sub33-bb.csv   2018-11-23 11:47:32               complete  0.493        None          \r\n",
      "sub33-b.csv    2018-11-23 11:46:26               complete  0.498        None          \r\n",
      "sub33-a.csv    2018-11-23 11:45:09               complete  0.496        None          \r\n",
      "sub36-a.csv    2018-11-23 10:12:45               complete  0.287        None          \r\n",
      "sub35b-c.csv   2018-11-22 08:00:23               complete  0.417        None          \r\n",
      "sub35b-b.csv   2018-11-22 07:59:44               complete  0.415        None          \r\n",
      "sub35b-a.csv   2018-11-22 07:58:57               complete  0.432        None          \r\n",
      "sub35-a.csv    2018-11-20 06:54:01               complete  0.315        None          \r\n",
      "sub8i1-e.csv   2018-11-19 07:12:37               complete  0.457        None          \r\n",
      "sub8i1-d.csv   2018-11-19 07:09:46               complete  0.459        None          \r\n",
      "sub8i1-c.csv   2018-11-19 07:08:49               complete  0.462        None          \r\n",
      "sub8i1-b.csv   2018-11-19 07:08:05               complete  0.462        None          \r\n",
      "sub8i1-a.csv   2018-11-19 07:07:14               complete  0.460        None          \r\n",
      "sub32-c.csv    2018-11-15 11:47:19               complete  0.463        None          \r\n",
      "sub32-bb.csv   2018-11-15 11:46:01               complete  0.465        None          \r\n",
      "sub32-b.csv    2018-11-15 11:44:43               complete  0.456        None          \r\n"
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "sleep(60)\n",
    "!kaggle competitions submissions -c human-protein-atlas-image-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.4.7.1 / client 1.3.8)\r\n",
      "fileName  date                 description  status    publicScore  privateScore  \r\n",
      "--------  -------------------  -----------  --------  -----------  ------------  \r\n",
      "sub8.csv  2018-10-20 20:08:45               complete  0.422        None          \r\n",
      "sub7.csv  2018-10-20 17:06:09               complete  0.389        None          \r\n",
      "sub5.csv  2018-10-19 18:27:33               complete  0.387        None          \r\n",
      "sub4.csv  2018-10-19 14:45:15               complete  0.411        None          \r\n",
      "sub3.csv  2018-10-19 10:19:26               complete  0.377        None          \r\n",
      "sub2.csv  2018-10-19 08:07:30               complete  0.135        None          \r\n",
      "sub1.csv  2018-10-19 06:28:57               complete  0.374        None          \r\n"
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "sleep(60)\n",
    "!kaggle competitions submissions -c human-protein-atlas-image-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hpg",
   "language": "python",
   "name": "hpg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
