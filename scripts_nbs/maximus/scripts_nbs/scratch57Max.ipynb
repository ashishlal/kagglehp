{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/mathormad/inceptionv3-baseline-lb-0-379/code\n",
    "# fork of scratch8, 29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.io\n",
    "from skimage.transform import resize\n",
    "from imgaug import augmenters as iaa\n",
    "from tqdm import tqdm\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from sklearn.utils import class_weight, shuffle\n",
    "import keras_metrics\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "SIZE = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/rejpalcz/best-loss-function-for-f1-score-metric/notebook\n",
    "import tensorflow as tf\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    y_pred = K.round(y_pred)\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n",
    "\n",
    "def f1_loss(y_true, y_pred):\n",
    "    \n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(K.binary_crossentropy(y_true, y_pred), axis=-1) + (1 - K.mean(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset info\n",
    "path_to_train = '../data/train/'\n",
    "data = pd.read_csv('../data/train.csv')\n",
    "# path_to_external_data = '../data/external_data/external_data_1/'\n",
    "# edata = pd.read_csv('../data/external_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00070df0-bbc3-11e8-b2bc-ac1f6b6435d0</td>\n",
       "      <td>16 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000a6c98-bb9b-11e8-b2b9-ac1f6b6435d0</td>\n",
       "      <td>7 1 2 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000a9596-bbc4-11e8-b2bc-ac1f6b6435d0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000c99ba-bba4-11e8-b2b9-ac1f6b6435d0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001838f8-bbca-11e8-b2bc-ac1f6b6435d0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Id   Target\n",
       "0  00070df0-bbc3-11e8-b2bc-ac1f6b6435d0     16 0\n",
       "1  000a6c98-bb9b-11e8-b2b9-ac1f6b6435d0  7 1 2 0\n",
       "2  000a9596-bbc4-11e8-b2bc-ac1f6b6435d0        5\n",
       "3  000c99ba-bba4-11e8-b2b9-ac1f6b6435d0        1\n",
       "4  001838f8-bbca-11e8-b2bc-ac1f6b6435d0       18"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31072, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_info = []\n",
    "\n",
    "for name, labels in zip(data['Id'], data['Target'].str.split(' ')):\n",
    "    train_dataset_info.append({\n",
    "        'path':os.path.join(path_to_train, name),\n",
    "        'labels':np.array([int(label) for label in labels])})\n",
    "    \n",
    "# for name, labels in zip(edata['id'], edata['labels'].str.strip('[]')):\n",
    "#     labels = labels.split(',')\n",
    "#     train_dataset_info.append({\n",
    "#         'path':os.path.join(path_to_external_data, name),\n",
    "#         'labels':np.array([int(label) for label in labels])})\n",
    "    \n",
    "train_dataset_info = np.array(train_dataset_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31072,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_info.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "\n",
    "# class data_generator:\n",
    "    \n",
    "class threadsafe_iter:\n",
    "    \"\"\"\n",
    "    Takes an iterator/generator and makes it thread-safe by\n",
    "    serializing call to the `next` method of given iterator/generator.\n",
    "    \"\"\"\n",
    "    def __init__(self, it):\n",
    "        self.it = it\n",
    "        self.lock = threading.Lock()\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        with self.lock:\n",
    "            return self.it.__next__()\n",
    "\n",
    "def threadsafe_generator(f):\n",
    "    \"\"\"\n",
    "    A decorator that takes a generator function and makes it thread-safe.\n",
    "    \"\"\"\n",
    "    def g(*a, **kw):\n",
    "        return threadsafe_iter(f(*a, **kw))\n",
    "    return g\n",
    "\n",
    "@threadsafe_generator\n",
    "def create_train(dataset_info, batch_size, shape, augument=True):\n",
    "    assert shape[2] == 3\n",
    "    while True:\n",
    "        dataset_info = shuffle(dataset_info)\n",
    "        for start in range(0, len(dataset_info), batch_size):\n",
    "            end = min(start + batch_size, len(dataset_info))\n",
    "            batch_images = []\n",
    "            X_train_batch = dataset_info[start:end]\n",
    "            batch_labels = np.zeros((len(X_train_batch), 28))\n",
    "            for i in range(len(X_train_batch)):\n",
    "                image = load_image2(\n",
    "                    X_train_batch[i]['path'], shape)\n",
    "#                     image = tdi[i+start]\n",
    "#                     image = cv2.resize(image, (shape[0], shape[1]))\n",
    "                if augument:\n",
    "                    image = augment2(image)\n",
    "\n",
    "                batch_images.append(image/255.)\n",
    "                batch_labels[i][X_train_batch[i]['labels']] = 1\n",
    "            yield np.array(batch_images, np.float32), batch_labels\n",
    "\n",
    "def load_image(path, shape):\n",
    "\n",
    "    if len(path.split('/')[3]) != 36:\n",
    "        print(path)\n",
    "    image_red_ch = Image.open(path+'_red.png')\n",
    "    image_yellow_ch = Image.open(path+'_yellow.png')\n",
    "    image_green_ch = Image.open(path+'_green.png')\n",
    "    image_blue_ch = Image.open(path+'_blue.png')\n",
    "    image1 = np.stack((\n",
    "        np.array(image_red_ch),\n",
    "        np.array(image_green_ch), \n",
    "        np.array(image_blue_ch)), -1)\n",
    "    if len(path.split('/')[3]) != 36:\n",
    "        print(image1.shape)\n",
    "    w, h = 512, 512\n",
    "#         zero_data = np.zeros((h, w), dtype=np.uint8)\n",
    "#         image2 = np.stack((\n",
    "#             np.array(image_red_ch),\n",
    "#             np.array(image_green_ch), \n",
    "#             np.array(image_yellow_ch)), -1)\n",
    "#         image3 = np.stack((\n",
    "#             np.array(image_yellow_ch),\n",
    "#             np.array(image_green_ch), \n",
    "#             np.array(image_blue_ch)), -1)\n",
    "# #         print(image1.shape, image2.shape)\n",
    "#         image = np.vstack((image1, image2, image3))\n",
    "#         print(image.shape)\n",
    "    image =image1\n",
    "#         image = canny_image4(image1)\n",
    "    image = cv2.resize(image, (shape[0], shape[1]))\n",
    "    if len(path.split('/')[3]) != 36:\n",
    "        print(image.shape)\n",
    "    return image\n",
    "\n",
    "def load_image2(path, shape):\n",
    "    colors = ['red','green','blue']\n",
    "    flags = cv2.IMREAD_GRAYSCALE\n",
    "    img = [cv2.imread(path+'_'+color+'.png', flags).astype(np.float32)\n",
    "       for color in colors]\n",
    "    return np.stack(img, axis=-1)\n",
    "\n",
    "\n",
    "def augment2(image):\n",
    "    augment_img = iaa.Sequential([\n",
    "        iaa.OneOf([\n",
    "            iaa.Affine(rotate=0),\n",
    "            iaa.Affine(rotate=90),\n",
    "            iaa.Affine(rotate=180),\n",
    "            iaa.Affine(rotate=270),\n",
    "            iaa.Fliplr(0.5),\n",
    "            iaa.Flipud(0.5),\n",
    "        ])], random_order=True)\n",
    "\n",
    "    image_aug = augment_img.augment_image(image)\n",
    "    return image_aug\n",
    "def augment(image):\n",
    "    augment_img = iaa.Sequential([\n",
    "        iaa.OneOf([\n",
    "                iaa.Fliplr(0.5), # horizontal flips\n",
    "                iaa.Affine(rotate=0),\n",
    "                iaa.Affine(rotate=90),\n",
    "                iaa.Affine(rotate=180),\n",
    "                iaa.Affine(rotate=270),\n",
    "                iaa.Flipud(0.5),\n",
    "                iaa.Crop(percent=(0, 0.1)), # random crops\n",
    "                # Small gaussian blur with random sigma between 0 and 0.5.\n",
    "                # But we only blur about 50% of all images.\n",
    "                iaa.Sometimes(0.5,\n",
    "                    iaa.GaussianBlur(sigma=(0, 0.5))\n",
    "                ),\n",
    "                # Strengthen or weaken the contrast in each image.\n",
    "                iaa.ContrastNormalization((0.75, 1.5)),\n",
    "                # Add gaussian noise.\n",
    "                # For 50% of all images, we sample the noise once per pixel.\n",
    "                # For the other 50% of all images, we sample the noise per pixel AND\n",
    "                # channel. This can change the color (not only brightness) of the\n",
    "                # pixels.\n",
    "                iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.05*255), per_channel=0.5),\n",
    "                # Make some images brighter and some darker.\n",
    "                # In 20% of all cases, we sample the multiplier once per channel,\n",
    "                # which can end up changing the color of the images.\n",
    "                iaa.Multiply((0.8, 1.2), per_channel=0.2),\n",
    "                # Apply affine transformations to each image.\n",
    "                # Scale/zoom them, translate/move them, rotate them and shear them.\n",
    "                iaa.Affine(\n",
    "                    scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)},\n",
    "                    translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},\n",
    "                    rotate=(-180, 180),\n",
    "                    shear=(-8, 8)\n",
    "                )\n",
    "            ])], random_order=True)\n",
    "\n",
    "    image_aug = augment_img.augment_image(image)\n",
    "    return image_aug\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, Lambda, multiply\n",
    "from keras.layers import GlobalMaxPooling2D, GlobalAveragePooling2D, BatchNormalization, Input, Conv2D\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import metrics\n",
    "from keras.optimizers import Adam \n",
    "from keras import backend as K\n",
    "import keras\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape, n_out):\n",
    "    in_lay = Input(input_shape)\n",
    "    base_pretrained_model = ResNet50(input_shape =  input_shape, include_top = False, weights = 'imagenet')\n",
    "    base_pretrained_model.trainable = False\n",
    "    pt_depth = base_pretrained_model.get_output_shape_at(0)[-1]\n",
    "    pt_features = base_pretrained_model(in_lay)\n",
    "    from keras.layers import BatchNormalization\n",
    "    bn_features = BatchNormalization()(pt_features)\n",
    "\n",
    "    # here we do an attention mechanism to turn pixels in the GAP on an off\n",
    "\n",
    "    attn_layer = Conv2D(64, kernel_size = (1,1), padding = 'same', activation = 'relu')(Dropout(0.5)(bn_features))\n",
    "    attn_layer = Conv2D(16, kernel_size = (1,1), padding = 'same', activation = 'relu')(attn_layer)\n",
    "    attn_layer = Conv2D(8, kernel_size = (1,1), padding = 'same', activation = 'relu')(attn_layer)\n",
    "    attn_layer = Conv2D(1, kernel_size = (1,1), padding = 'valid', activation = 'sigmoid')(attn_layer)\n",
    "    # fan it out to all of the channels\n",
    "    up_c2_w = np.ones((1, 1, 1, pt_depth))\n",
    "    up_c2 = Conv2D(pt_depth, kernel_size = (1,1), padding = 'same', \n",
    "                   activation = 'linear', use_bias = False, weights = [up_c2_w])\n",
    "    up_c2.trainable = False\n",
    "    attn_layer = up_c2(attn_layer)\n",
    "\n",
    "    mask_features = multiply([attn_layer, bn_features])\n",
    "    gap_features = GlobalAveragePooling2D()(mask_features)\n",
    "    gap_mask = GlobalAveragePooling2D()(attn_layer)\n",
    "    # to account for missing values from the attention model\n",
    "    gap = Lambda(lambda x: x[0]/x[1], name = 'RescaleGAP')([gap_features, gap_mask])\n",
    "    gap_dr = Dropout(0.25)(gap)\n",
    "    dr_steps = Dropout(0.25)(Dense(128, activation = 'relu')(gap_dr))\n",
    "    out_layer = Dense(n_out, activation = 'sigmoid')(dr_steps)\n",
    "    model = Model(inputs = [in_lay], outputs = [out_layer])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 512, 512, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "resnet50 (Model)                (None, 16, 16, 2048) 23587712    input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 16, 16, 2048) 8192        resnet50[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 16, 16, 2048) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 16, 16, 64)   131136      dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 16, 16, 16)   1040        conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 16, 16, 8)    136         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 16, 16, 1)    9           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 16, 16, 2048) 2048        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 16, 16, 2048) 0           conv2d_5[0][0]                   \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 2048)         0           multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glo (None, 2048)         0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "RescaleGAP (Lambda)             (None, 2048)         0           global_average_pooling2d_1[0][0] \n",
      "                                                                 global_average_pooling2d_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 2048)         0           RescaleGAP[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          262272      dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 128)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 28)           3612        dropout_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 23,996,157\n",
      "Trainable params: 402,301\n",
      "Non-trainable params: 23,593,856\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# warm up model\n",
    "model = create_model(\n",
    "    input_shape=(SIZE,SIZE,3), \n",
    "    n_out=28)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=f1_loss,\n",
    "            optimizer=Adam(lr=1e-3),\n",
    "            metrics=[f1])\n",
    "# model.load_weights('../cache/R50-57-maximus.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create callbacks list\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "epochs = 10; batch_size = 16\n",
    "checkpoint = ModelCheckpoint('../cache/R50-57-maximus.h5', monitor='val_loss', verbose=1, \n",
    "                             save_best_only=True, mode='min', save_weights_only = True)\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, \n",
    "                                   verbose=1, mode='auto', epsilon=0.0001)\n",
    "early = EarlyStopping(monitor=\"val_loss\", \n",
    "                      mode=\"min\", \n",
    "                      patience=6)\n",
    "callbacks_list = [checkpoint, early, reduceLROnPlat]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train, valid\n",
    "indexes = np.arange(train_dataset_info.shape[0])\n",
    "np.random.shuffle(indexes)\n",
    "train_indexes, valid_indexes = train_test_split(indexes, test_size=0.15, random_state=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "\n",
    "# create train and valid datagens\n",
    "# train_generator = data_generator.create_train(\n",
    "#     train_dataset_info[train_indexes], batch_size, (SIZE,SIZE,3), augument=True)\n",
    "# validation_generator = data_generator.create_train(\n",
    "#     train_dataset_info[valid_indexes], 16, (SIZE,SIZE,3), augument=True)\n",
    "\n",
    "train_generator = create_train(\n",
    "    train_dataset_info[train_indexes], batch_size, (SIZE,SIZE,3), augument=True)\n",
    "validation_generator = create_train(\n",
    "    train_dataset_info[valid_indexes], 32, (SIZE,SIZE,3), augument=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    layer.trainable = True\n",
    "model.layers[0].trainable = False\n",
    "model.layers[1].trainable = False\n",
    "model.layers[2].trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1651/1651 [==============================] - 551s 334ms/step - loss: 1.0309 - f1: 0.1277 - val_loss: 1.2087 - val_f1: 0.0000e+00\n",
      "Epoch 2/2\n",
      "1651/1651 [==============================] - 526s 319ms/step - loss: 0.9839 - f1: 0.1651 - val_loss: 1.2263 - val_f1: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1a5865e240>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=np.ceil(float(len(train_indexes)) / float(batch_size)),\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=np.ceil(float(len(valid_indexes)) / float(batch_size)),\n",
    "    epochs=2, \n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train all layers\n",
    "epochs=120\n",
    "for layer in model.layers:\n",
    "    layer.trainable = True\n",
    "model.compile(loss=f1_loss,\n",
    "            optimizer=Adam(lr=1e-4),\n",
    "            metrics=[f1])\n",
    "# model.fit_generator(\n",
    "#     train_generator,\n",
    "#     steps_per_epoch=np.ceil(float(len(train_indexes)) / float(batch_size)),\n",
    "#     validation_data=validation_generator,\n",
    "#     validation_steps=np.ceil(float(len(valid_indexes)) / float(batch_size)),\n",
    "#     epochs=epochs, \n",
    "#     verbose=1,\n",
    "#     workers=10,\n",
    "#     callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "3302/3302 [==============================] - 1247s 378ms/step - loss: 0.9836 - f1: 0.1480 - val_loss: 0.8872 - val_f1: 0.2336\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.88720, saving model to ../cache/R50-57-maximus.h5\n",
      "Epoch 2/120\n",
      "3302/3302 [==============================] - 1237s 375ms/step - loss: 0.9469 - f1: 0.1702 - val_loss: 0.8900 - val_f1: 0.2363\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.88720\n",
      "Epoch 3/120\n",
      "3302/3302 [==============================] - 1234s 374ms/step - loss: 0.9325 - f1: 0.1780 - val_loss: 0.8545 - val_f1: 0.2582\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.88720 to 0.85455, saving model to ../cache/R50-57-maximus.h5\n",
      "Epoch 4/120\n",
      "3302/3302 [==============================] - 1230s 373ms/step - loss: 0.9222 - f1: 0.1842 - val_loss: 0.8575 - val_f1: 0.2614\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.85455\n",
      "Epoch 5/120\n",
      "3302/3302 [==============================] - 1231s 373ms/step - loss: 0.9153 - f1: 0.1888 - val_loss: 0.8492 - val_f1: 0.2668\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.85455 to 0.84923, saving model to ../cache/R50-57-maximus.h5\n",
      "Epoch 6/120\n",
      "3302/3302 [==============================] - 1228s 372ms/step - loss: 0.9074 - f1: 0.1926 - val_loss: 0.8393 - val_f1: 0.2682\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.84923 to 0.83935, saving model to ../cache/R50-57-maximus.h5\n",
      "Epoch 7/120\n",
      "3302/3302 [==============================] - 1231s 373ms/step - loss: 0.9006 - f1: 0.1966 - val_loss: 0.8333 - val_f1: 0.2714\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.83935 to 0.83328, saving model to ../cache/R50-57-maximus.h5\n",
      "Epoch 8/120\n",
      "3302/3302 [==============================] - 1232s 373ms/step - loss: 0.8956 - f1: 0.1992 - val_loss: 0.8574 - val_f1: 0.2593\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.83328\n",
      "Epoch 9/120\n",
      "3302/3302 [==============================] - 1230s 373ms/step - loss: 0.8900 - f1: 0.2026 - val_loss: 0.8313 - val_f1: 0.2794\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.83328 to 0.83128, saving model to ../cache/R50-57-maximus.h5\n",
      "Epoch 10/120\n",
      "3302/3302 [==============================] - 1229s 372ms/step - loss: 0.8869 - f1: 0.2041 - val_loss: 0.8363 - val_f1: 0.2677\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.83128\n",
      "Epoch 11/120\n",
      "3302/3302 [==============================] - 1230s 373ms/step - loss: 0.8820 - f1: 0.2066 - val_loss: 0.8269 - val_f1: 0.2745\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.83128 to 0.82690, saving model to ../cache/R50-57-maximus.h5\n",
      "Epoch 12/120\n",
      "3302/3302 [==============================] - 1230s 372ms/step - loss: 0.8771 - f1: 0.2096 - val_loss: 0.8219 - val_f1: 0.2836\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.82690 to 0.82187, saving model to ../cache/R50-57-maximus.h5\n",
      "Epoch 13/120\n",
      "3302/3302 [==============================] - 1232s 373ms/step - loss: 0.8737 - f1: 0.2116 - val_loss: 0.8283 - val_f1: 0.2773\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.82187\n",
      "Epoch 14/120\n",
      "3302/3302 [==============================] - 1230s 372ms/step - loss: 0.8702 - f1: 0.2132 - val_loss: 0.8330 - val_f1: 0.2744\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.82187\n",
      "Epoch 15/120\n",
      "3302/3302 [==============================] - 1229s 372ms/step - loss: 0.8661 - f1: 0.2161 - val_loss: 0.8138 - val_f1: 0.2874\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.82187 to 0.81378, saving model to ../cache/R50-57-maximus.h5\n",
      "Epoch 16/120\n",
      "3302/3302 [==============================] - 1237s 375ms/step - loss: 0.8629 - f1: 0.2172 - val_loss: 0.8257 - val_f1: 0.2801\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.81378\n",
      "Epoch 17/120\n",
      "3302/3302 [==============================] - 1234s 374ms/step - loss: 0.8592 - f1: 0.2195 - val_loss: 0.8111 - val_f1: 0.2934\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.81378 to 0.81110, saving model to ../cache/R50-57-maximus.h5\n",
      "Epoch 18/120\n",
      "3302/3302 [==============================] - 1230s 373ms/step - loss: 0.8552 - f1: 0.2211 - val_loss: 0.8170 - val_f1: 0.2862\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.81110\n",
      "Epoch 19/120\n",
      "3302/3302 [==============================] - 1229s 372ms/step - loss: 0.8512 - f1: 0.2232 - val_loss: 0.8095 - val_f1: 0.2917\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.81110 to 0.80948, saving model to ../cache/R50-57-maximus.h5\n",
      "Epoch 20/120\n",
      "3302/3302 [==============================] - 1231s 373ms/step - loss: 0.8490 - f1: 0.2245 - val_loss: 0.8111 - val_f1: 0.2929\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.80948\n",
      "Epoch 21/120\n",
      "3302/3302 [==============================] - 1233s 373ms/step - loss: 0.8457 - f1: 0.2267 - val_loss: 0.8071 - val_f1: 0.2944\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.80948 to 0.80713, saving model to ../cache/R50-57-maximus.h5\n",
      "Epoch 22/120\n",
      "3302/3302 [==============================] - 1201s 364ms/step - loss: 0.8417 - f1: 0.2282 - val_loss: 0.8161 - val_f1: 0.2898\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.80713\n",
      "Epoch 23/120\n",
      "3302/3302 [==============================] - 1202s 364ms/step - loss: 0.8395 - f1: 0.2294 - val_loss: 0.8150 - val_f1: 0.2897\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.80713\n",
      "Epoch 24/120\n",
      "3302/3302 [==============================] - 1204s 365ms/step - loss: 0.8358 - f1: 0.2311 - val_loss: 0.8193 - val_f1: 0.2823\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.80713\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "Epoch 25/120\n",
      "3302/3302 [==============================] - 1205s 365ms/step - loss: 0.8175 - f1: 0.2404 - val_loss: 0.7976 - val_f1: 0.2988\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.80713 to 0.79760, saving model to ../cache/R50-57-maximus.h5\n",
      "Epoch 26/120\n",
      "3302/3302 [==============================] - 1207s 365ms/step - loss: 0.8123 - f1: 0.2428 - val_loss: 0.7957 - val_f1: 0.3001\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.79760 to 0.79570, saving model to ../cache/R50-57-maximus.h5\n",
      "Epoch 27/120\n",
      "3302/3302 [==============================] - 1208s 366ms/step - loss: 0.8083 - f1: 0.2445 - val_loss: 0.7961 - val_f1: 0.3020\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.79570\n",
      "Epoch 28/120\n",
      "3302/3302 [==============================] - 1208s 366ms/step - loss: 0.8058 - f1: 0.2453 - val_loss: 0.7991 - val_f1: 0.2980\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.79570\n",
      "Epoch 29/120\n",
      "3302/3302 [==============================] - 1208s 366ms/step - loss: 0.8034 - f1: 0.2466 - val_loss: 0.8004 - val_f1: 0.2982\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.79570\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "Epoch 30/120\n",
      "3302/3302 [==============================] - 1209s 366ms/step - loss: 0.8003 - f1: 0.2481 - val_loss: 0.8006 - val_f1: 0.2993\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.79570\n",
      "Epoch 31/120\n",
      "3302/3302 [==============================] - 1208s 366ms/step - loss: 0.8002 - f1: 0.2478 - val_loss: 0.7955 - val_f1: 0.3020\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.79570 to 0.79545, saving model to ../cache/R50-57-maximus.h5\n",
      "Epoch 32/120\n",
      "3302/3302 [==============================] - 1209s 366ms/step - loss: 0.7993 - f1: 0.2486 - val_loss: 0.8027 - val_f1: 0.2983\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.79545\n",
      "Epoch 33/120\n",
      "3302/3302 [==============================] - 1208s 366ms/step - loss: 0.7993 - f1: 0.2484 - val_loss: 0.7986 - val_f1: 0.3007\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.79545\n",
      "Epoch 34/120\n",
      "3302/3302 [==============================] - 1257s 381ms/step - loss: 0.7988 - f1: 0.2489 - val_loss: 0.7950 - val_f1: 0.3043\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.79545 to 0.79505, saving model to ../cache/R50-57-maximus.h5\n",
      "Epoch 35/120\n",
      "3302/3302 [==============================] - 1229s 372ms/step - loss: 0.7997 - f1: 0.2480 - val_loss: 0.7966 - val_f1: 0.3032\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.79505\n",
      "Epoch 36/120\n",
      "3302/3302 [==============================] - 1223s 370ms/step - loss: 0.7981 - f1: 0.2491 - val_loss: 0.8004 - val_f1: 0.3001\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.79505\n",
      "Epoch 37/120\n",
      "3302/3302 [==============================] - 1222s 370ms/step - loss: 0.7976 - f1: 0.2492 - val_loss: 0.8011 - val_f1: 0.2994\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.79505\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
      "Epoch 38/120\n",
      "3302/3302 [==============================] - 1223s 370ms/step - loss: 0.7972 - f1: 0.2497 - val_loss: 0.7978 - val_f1: 0.3028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00038: val_loss did not improve from 0.79505\n",
      "Epoch 39/120\n",
      "3302/3302 [==============================] - 1198s 363ms/step - loss: 0.7971 - f1: 0.2495 - val_loss: 0.8011 - val_f1: 0.3005\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.79505\n",
      "Epoch 40/120\n",
      "3302/3302 [==============================] - 1198s 363ms/step - loss: 0.7980 - f1: 0.2492 - val_loss: 0.8017 - val_f1: 0.2985\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.79505\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 1.0000000116860975e-08.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f19e9431a20>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 8\n",
    "\n",
    "\n",
    "# create train and valid datagens\n",
    "# train_generator = data_generator.create_train(\n",
    "#     train_dataset_info[train_indexes], batch_size, (SIZE,SIZE,3), augument=True)\n",
    "# validation_generator = data_generator.create_train(\n",
    "#     train_dataset_info[valid_indexes], 16, (SIZE,SIZE,3), augument=True)\n",
    "\n",
    "train_generator = create_train(\n",
    "    train_dataset_info[train_indexes], batch_size, (SIZE,SIZE,3), augument=True)\n",
    "validation_generator = create_train(\n",
    "    train_dataset_info[valid_indexes], 16, (SIZE,SIZE,3), augument=True)\n",
    "\n",
    "\n",
    "model.fit_generator(\n",
    "    generator=train_generator,\n",
    "    steps_per_epoch=np.ceil(float(len(train_indexes)) / float(batch_size)),\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=np.ceil(float(len(valid_indexes)) / float(batch_size)),\n",
    "    epochs=epochs, \n",
    "    verbose=1,\n",
    "    callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ee8b167674d4203add8cab8ab8bc3f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=11702), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Create submit\n",
    "from tqdm import tqdm_notebook\n",
    "submit = pd.read_csv('../data/sample_submission.csv')\n",
    "predicted = []\n",
    "draw_predict = []\n",
    "# model = create_model(\n",
    "#     input_shape=(SIZE,SIZE,3), \n",
    "#     n_out=28)\n",
    "# for layer in model.layers:\n",
    "#     layer.trainable = True\n",
    "# model.compile(loss=f1_loss,\n",
    "#             optimizer=Adam(lr=1e-4),\n",
    "#             metrics=[f1])\n",
    "model.load_weights('../cache/R50-57-maximus.h5')\n",
    "for name in tqdm_notebook(submit['Id']):\n",
    "    path = os.path.join('../data/test/', name)\n",
    "    image = load_image2(path, (SIZE,SIZE,3))/255.\n",
    "    score_predict = model.predict(image[np.newaxis])[0]\n",
    "    draw_predict.append(score_predict)\n",
    "    label_predict = np.arange(28)[score_predict>=0.5]\n",
    "    str_predict_label = ' '.join(str(l) for l in label_predict)\n",
    "    predicted.append(str_predict_label)\n",
    "\n",
    "submit['Predicted'] = predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv('../submissions/sub57-max-a.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 468k/468k [00:13<00:00, 36.7kB/s]\n",
      "Successfully submitted to Human Protein Atlas Image ClassificationfileName                date                 description  status    publicScore  privateScore  \n",
      "----------------------  -------------------  -----------  --------  -----------  ------------  \n",
      "sub57-max-a.csv         2018-12-21 23:46:32               complete  0.455        None          \n",
      "sub57-max.csv           2018-12-21 08:43:25               complete  0.000        None          \n",
      "sub50-max-055.csv       2018-12-18 20:29:16               complete  0.510        None          \n",
      "sub50-max-f.csv         2018-12-18 20:15:51               complete  0.513        None          \n",
      "sub50-max-f-1-l.csv     2018-12-18 16:40:56               complete  0.546        None          \n",
      "sub50-max-f-1.csv       2018-12-18 16:38:26               complete  0.525        None          \n",
      "sub50-max-f-1.csv       2018-12-18 15:53:31               complete  0.061        None          \n",
      "sub55-max-045-l.csv     2018-12-17 20:34:48               complete  0.574        None          \n",
      "sub55-max-05-l.csv      2018-12-17 20:32:23               complete  0.581        None          \n",
      "sub55-max-045.csv       2018-12-17 20:31:53               complete  0.567        None          \n",
      "sub55-max-05.csv        2018-12-17 20:31:18               complete  0.559        None          \n",
      "sub55-max-05.csv        2018-12-17 20:30:37               complete  0.559        None          \n",
      "sub50_22.csv            2018-12-16 02:56:59               complete  0.579        None          \n",
      "sub50_22.csv            2018-12-16 02:32:16               complete  0.578        None          \n",
      "sub50_22.csv            2018-12-16 02:16:49               complete  0.059        None          \n",
      "sub50_22.csv            2018-12-16 02:00:57               complete  0.059        None          \n",
      "sub50-max-05-notta.csv  2018-12-15 08:41:36               complete  0.020        None          \n",
      "sub50-max-05-notta.csv  2018-12-15 08:22:48               complete  0.020        None          \n",
      "sub54-max-a.csv         2018-12-15 06:06:02               complete  0.365        None          \n",
      "sub50-max-05-l.csv      2018-12-15 05:44:54               complete  0.578        None          \n",
      "CPU times: user 352 ms, sys: 306 ms, total: 658 ms\n",
      "Wall time: 38 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!kaggle competitions submit -c human-protein-atlas-image-classification -f ../submissions/sub57-max-a.csv -m \"\"\n",
    "\n",
    "from time import sleep\n",
    "sleep(20)\n",
    "!kaggle competitions submissions -c human-protein-atlas-image-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b85401477c55438da8aaaf7cdd8b05ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "submit = pd.read_csv('../data/sample_submission.csv')\n",
    "predicted = []\n",
    "for ii, name in tqdm_notebook(enumerate(submit['Id'])):\n",
    "    \n",
    "    score_predict = draw_predict[ii]\n",
    "    label_predict = np.arange(28)[score_predict>=0.45]\n",
    "    str_predict_label = ' '.join(str(l) for l in label_predict)\n",
    "    predicted.append(str_predict_label)\n",
    "\n",
    "submit['Predicted'] = predicted\n",
    "submit.to_csv('../submissions/sub57-max-b.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 469k/469k [00:12<00:00, 39.0kB/s]\n",
      "Successfully submitted to Human Protein Atlas Image ClassificationfileName                date                 description  status    publicScore  privateScore  \n",
      "----------------------  -------------------  -----------  --------  -----------  ------------  \n",
      "sub57-max-b.csv         2018-12-22 01:45:44               complete  0.456        None          \n",
      "sub57-max-a.csv         2018-12-21 23:46:32               complete  0.455        None          \n",
      "sub57-max.csv           2018-12-21 08:43:25               complete  0.000        None          \n",
      "sub50-max-055.csv       2018-12-18 20:29:16               complete  0.510        None          \n",
      "sub50-max-f.csv         2018-12-18 20:15:51               complete  0.513        None          \n",
      "sub50-max-f-1-l.csv     2018-12-18 16:40:56               complete  0.546        None          \n",
      "sub50-max-f-1.csv       2018-12-18 16:38:26               complete  0.525        None          \n",
      "sub50-max-f-1.csv       2018-12-18 15:53:31               complete  0.061        None          \n",
      "sub55-max-045-l.csv     2018-12-17 20:34:48               complete  0.574        None          \n",
      "sub55-max-05-l.csv      2018-12-17 20:32:23               complete  0.581        None          \n",
      "sub55-max-045.csv       2018-12-17 20:31:53               complete  0.567        None          \n",
      "sub55-max-05.csv        2018-12-17 20:31:18               complete  0.559        None          \n",
      "sub55-max-05.csv        2018-12-17 20:30:37               complete  0.559        None          \n",
      "sub50_22.csv            2018-12-16 02:56:59               complete  0.579        None          \n",
      "sub50_22.csv            2018-12-16 02:32:16               complete  0.578        None          \n",
      "sub50_22.csv            2018-12-16 02:16:49               complete  0.059        None          \n",
      "sub50_22.csv            2018-12-16 02:00:57               complete  0.059        None          \n",
      "sub50-max-05-notta.csv  2018-12-15 08:41:36               complete  0.020        None          \n",
      "sub50-max-05-notta.csv  2018-12-15 08:22:48               complete  0.020        None          \n",
      "sub54-max-a.csv         2018-12-15 06:06:02               complete  0.365        None          \n",
      "CPU times: user 368 ms, sys: 300 ms, total: 668 ms\n",
      "Wall time: 37.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!kaggle competitions submit -c human-protein-atlas-image-classification -f ../submissions/sub57-max-b.csv -m \"\"\n",
    "\n",
    "from time import sleep\n",
    "sleep(20)\n",
    "!kaggle competitions submissions -c human-protein-atlas-image-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fbde853429641d193f23205739eb3eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "submit = pd.read_csv('../data/sample_submission.csv')\n",
    "predicted = []\n",
    "for ii, name in tqdm_notebook(enumerate(submit['Id'])):\n",
    "    \n",
    "    score_predict = draw_predict[ii]\n",
    "    label_predict = np.arange(28)[score_predict>=0.40]\n",
    "    str_predict_label = ' '.join(str(l) for l in label_predict)\n",
    "    predicted.append(str_predict_label)\n",
    "\n",
    "submit['Predicted'] = predicted\n",
    "submit.to_csv('../submissions/sub57-max-c.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 471k/471k [00:13<00:00, 37.0kB/s]\n",
      "Successfully submitted to Human Protein Atlas Image ClassificationfileName                date                 description  status    publicScore  privateScore  \n",
      "----------------------  -------------------  -----------  --------  -----------  ------------  \n",
      "sub57-max-c.csv         2018-12-22 01:47:16               complete  0.463        None          \n",
      "sub57-max-b.csv         2018-12-22 01:45:44               complete  0.456        None          \n",
      "sub57-max-a.csv         2018-12-21 23:46:32               complete  0.455        None          \n",
      "sub57-max.csv           2018-12-21 08:43:25               complete  0.000        None          \n",
      "sub50-max-055.csv       2018-12-18 20:29:16               complete  0.510        None          \n",
      "sub50-max-f.csv         2018-12-18 20:15:51               complete  0.513        None          \n",
      "sub50-max-f-1-l.csv     2018-12-18 16:40:56               complete  0.546        None          \n",
      "sub50-max-f-1.csv       2018-12-18 16:38:26               complete  0.525        None          \n",
      "sub50-max-f-1.csv       2018-12-18 15:53:31               complete  0.061        None          \n",
      "sub55-max-045-l.csv     2018-12-17 20:34:48               complete  0.574        None          \n",
      "sub55-max-05-l.csv      2018-12-17 20:32:23               complete  0.581        None          \n",
      "sub55-max-045.csv       2018-12-17 20:31:53               complete  0.567        None          \n",
      "sub55-max-05.csv        2018-12-17 20:31:18               complete  0.559        None          \n",
      "sub55-max-05.csv        2018-12-17 20:30:37               complete  0.559        None          \n",
      "sub50_22.csv            2018-12-16 02:56:59               complete  0.579        None          \n",
      "sub50_22.csv            2018-12-16 02:32:16               complete  0.578        None          \n",
      "sub50_22.csv            2018-12-16 02:16:49               complete  0.059        None          \n",
      "sub50_22.csv            2018-12-16 02:00:57               complete  0.059        None          \n",
      "sub50-max-05-notta.csv  2018-12-15 08:41:36               complete  0.020        None          \n",
      "sub50-max-05-notta.csv  2018-12-15 08:22:48               complete  0.020        None          \n",
      "CPU times: user 408 ms, sys: 275 ms, total: 683 ms\n",
      "Wall time: 39.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!kaggle competitions submit -c human-protein-atlas-image-classification -f ../submissions/sub57-max-c.csv -m \"\"\n",
    "\n",
    "from time import sleep\n",
    "sleep(20)\n",
    "!kaggle competitions submissions -c human-protein-atlas-image-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b85ae5575f742fa9b95779e5a42e831",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "submit = pd.read_csv('../data/sample_submission.csv')\n",
    "predicted = []\n",
    "for ii, name in tqdm_notebook(enumerate(submit['Id'])):\n",
    "    \n",
    "    score_predict = draw_predict[ii]\n",
    "    label_predict = np.arange(28)[score_predict>=0.35]\n",
    "    str_predict_label = ' '.join(str(l) for l in label_predict)\n",
    "    predicted.append(str_predict_label)\n",
    "\n",
    "submit['Predicted'] = predicted\n",
    "submit.to_csv('../submissions/sub57-max-d.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 473k/473k [00:12<00:00, 37.3kB/s]\n",
      "Successfully submitted to Human Protein Atlas Image ClassificationfileName                date                 description  status    publicScore  privateScore  \n",
      "----------------------  -------------------  -----------  --------  -----------  ------------  \n",
      "sub57-max-d.csv         2018-12-22 01:57:31               complete  0.464        None          \n",
      "sub57-max-c.csv         2018-12-22 01:47:16               complete  0.463        None          \n",
      "sub57-max-b.csv         2018-12-22 01:45:44               complete  0.456        None          \n",
      "sub57-max-a.csv         2018-12-21 23:46:32               complete  0.455        None          \n",
      "sub57-max.csv           2018-12-21 08:43:25               complete  0.000        None          \n",
      "sub50-max-055.csv       2018-12-18 20:29:16               complete  0.510        None          \n",
      "sub50-max-f.csv         2018-12-18 20:15:51               complete  0.513        None          \n",
      "sub50-max-f-1-l.csv     2018-12-18 16:40:56               complete  0.546        None          \n",
      "sub50-max-f-1.csv       2018-12-18 16:38:26               complete  0.525        None          \n",
      "sub50-max-f-1.csv       2018-12-18 15:53:31               complete  0.061        None          \n",
      "sub55-max-045-l.csv     2018-12-17 20:34:48               complete  0.574        None          \n",
      "sub55-max-05-l.csv      2018-12-17 20:32:23               complete  0.581        None          \n",
      "sub55-max-045.csv       2018-12-17 20:31:53               complete  0.567        None          \n",
      "sub55-max-05.csv        2018-12-17 20:31:18               complete  0.559        None          \n",
      "sub55-max-05.csv        2018-12-17 20:30:37               complete  0.559        None          \n",
      "sub50_22.csv            2018-12-16 02:56:59               complete  0.579        None          \n",
      "sub50_22.csv            2018-12-16 02:32:16               complete  0.578        None          \n",
      "sub50_22.csv            2018-12-16 02:16:49               complete  0.059        None          \n",
      "sub50_22.csv            2018-12-16 02:00:57               complete  0.059        None          \n",
      "sub50-max-05-notta.csv  2018-12-15 08:41:36               complete  0.020        None          \n",
      "CPU times: user 373 ms, sys: 323 ms, total: 696 ms\n",
      "Wall time: 38.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!kaggle competitions submit -c human-protein-atlas-image-classification -f ../submissions/sub57-max-d.csv -m \"\"\n",
    "\n",
    "from time import sleep\n",
    "sleep(20)\n",
    "!kaggle competitions submissions -c human-protein-atlas-image-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a609c4edd1be452e9efd611622a0f242",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=11702), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Create submit\n",
    "from tqdm import tqdm_notebook\n",
    "submit = pd.read_csv('../data/sample_submission.csv')\n",
    "predicted = []\n",
    "draw_predict = []\n",
    "# model = create_model(\n",
    "#     input_shape=(SIZE,SIZE,3), \n",
    "#     n_out=28)\n",
    "# for layer in model.layers:\n",
    "#     layer.trainable = True\n",
    "# model.compile(loss=f1_loss,\n",
    "#             optimizer=Adam(lr=1e-4),\n",
    "#             metrics=[f1])\n",
    "# model.load_weights('../cache/R50-57-maximus.h5')\n",
    "for name in tqdm_notebook(submit['Id']):\n",
    "    path = os.path.join('../data/test/', name)\n",
    "    image = load_image2(path, (SIZE,SIZE,3))\n",
    "    image = augment2(image)\n",
    "    imgae = image/255.\n",
    "    score_predict = model.predict(image[np.newaxis])[0]\n",
    "    draw_predict.append(score_predict)\n",
    "    label_predict = np.arange(28)[score_predict>=0.35]\n",
    "    str_predict_label = ' '.join(str(l) for l in label_predict)\n",
    "    predicted.append(str_predict_label)\n",
    "\n",
    "submit['Predicted'] = predicted\n",
    "submit.to_csv('../submissions/sub57-max-e.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileName             date                 description  status    publicScore  privateScore  \r\n",
      "-------------------  -------------------  -----------  --------  -----------  ------------  \r\n",
      "sub57-max-e.csv      2018-12-22 02:08:14               complete  0.075        None          \r\n",
      "sub57-max-d.csv      2018-12-22 01:57:31               complete  0.464        None          \r\n",
      "sub57-max-c.csv      2018-12-22 01:47:16               complete  0.463        None          \r\n",
      "sub57-max-b.csv      2018-12-22 01:45:44               complete  0.456        None          \r\n",
      "sub57-max-a.csv      2018-12-21 23:46:32               complete  0.455        None          \r\n",
      "sub57-max.csv        2018-12-21 08:43:25               complete  0.000        None          \r\n",
      "sub50-max-055.csv    2018-12-18 20:29:16               complete  0.510        None          \r\n",
      "sub50-max-f.csv      2018-12-18 20:15:51               complete  0.513        None          \r\n",
      "sub50-max-f-1-l.csv  2018-12-18 16:40:56               complete  0.546        None          \r\n",
      "sub50-max-f-1.csv    2018-12-18 16:38:26               complete  0.525        None          \r\n",
      "sub50-max-f-1.csv    2018-12-18 15:53:31               complete  0.061        None          \r\n",
      "sub55-max-045-l.csv  2018-12-17 20:34:48               complete  0.574        None          \r\n",
      "sub55-max-05-l.csv   2018-12-17 20:32:23               complete  0.581        None          \r\n",
      "sub55-max-045.csv    2018-12-17 20:31:53               complete  0.567        None          \r\n",
      "sub55-max-05.csv     2018-12-17 20:31:18               complete  0.559        None          \r\n",
      "sub55-max-05.csv     2018-12-17 20:30:37               complete  0.559        None          \r\n",
      "sub50_22.csv         2018-12-16 02:56:59               complete  0.579        None          \r\n",
      "sub50_22.csv         2018-12-16 02:32:16               complete  0.578        None          \r\n",
      "sub50_22.csv         2018-12-16 02:16:49               complete  0.059        None          \r\n",
      "sub50_22.csv         2018-12-16 02:00:57               complete  0.059        None          \r\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!kaggle competitions submit -c human-protein-atlas-image-classification -f ../submissions/sub57-max-e.csv -m \"\"\n",
    "\n",
    "from time import sleep\n",
    "sleep(20)\n",
    "!kaggle competitions submissions -c human-protein-atlas-image-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hpg",
   "language": "python",
   "name": "hpg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
