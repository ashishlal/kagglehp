{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/mathormad/inceptionv3-baseline-lb-0-379/code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.io\n",
    "from skimage.transform import resize\n",
    "from imgaug import augmenters as iaa\n",
    "from tqdm import tqdm\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from sklearn.utils import class_weight, shuffle\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "SIZE = 299"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/rejpalcz/best-loss-function-for-f1-score-metric/notebook\n",
    "import tensorflow as tf\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    y_pred = K.round(y_pred)\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n",
    "\n",
    "def f1_loss(y_true, y_pred):\n",
    "    \n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(K.binary_crossentropy(y_true, y_pred), axis=-1) + (1 - K.mean(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset info\n",
    "path_to_train = '../data/train/'\n",
    "data = pd.read_csv('../data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00070df0-bbc3-11e8-b2bc-ac1f6b6435d0</td>\n",
       "      <td>16 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000a6c98-bb9b-11e8-b2b9-ac1f6b6435d0</td>\n",
       "      <td>7 1 2 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000a9596-bbc4-11e8-b2bc-ac1f6b6435d0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000c99ba-bba4-11e8-b2b9-ac1f6b6435d0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001838f8-bbca-11e8-b2bc-ac1f6b6435d0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Id   Target\n",
       "0  00070df0-bbc3-11e8-b2bc-ac1f6b6435d0     16 0\n",
       "1  000a6c98-bb9b-11e8-b2b9-ac1f6b6435d0  7 1 2 0\n",
       "2  000a9596-bbc4-11e8-b2bc-ac1f6b6435d0        5\n",
       "3  000c99ba-bba4-11e8-b2b9-ac1f6b6435d0        1\n",
       "4  001838f8-bbca-11e8-b2bc-ac1f6b6435d0       18"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_info = []\n",
    "for name, labels in zip(data['Id'], data['Target'].str.split(' ')):\n",
    "    train_dataset_info.append({\n",
    "        'path':os.path.join(path_to_train, name),\n",
    "        'labels':np.array([int(label) for label in labels])})\n",
    "train_dataset_info = np.array(train_dataset_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([{'path': '../data/train/00070df0-bbc3-11e8-b2bc-ac1f6b6435d0', 'labels': array([16,  0])},\n",
       "       {'path': '../data/train/000a6c98-bb9b-11e8-b2b9-ac1f6b6435d0', 'labels': array([7, 1, 2, 0])},\n",
       "       {'path': '../data/train/000a9596-bbc4-11e8-b2bc-ac1f6b6435d0', 'labels': array([5])},\n",
       "       ...,\n",
       "       {'path': '../data/train/fff189d8-bbab-11e8-b2ba-ac1f6b6435d0', 'labels': array([7])},\n",
       "       {'path': '../data/train/fffdf7e0-bbc4-11e8-b2bc-ac1f6b6435d0', 'labels': array([25,  2, 21])},\n",
       "       {'path': '../data/train/fffe0ffe-bbc0-11e8-b2bb-ac1f6b6435d0', 'labels': array([2, 0])}],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class data_generator:\n",
    "    \n",
    "    def create_train(dataset_info, batch_size, shape, augument=True):\n",
    "        assert shape[2] == 3\n",
    "        while True:\n",
    "            dataset_info = shuffle(dataset_info)\n",
    "            for start in range(0, len(dataset_info), batch_size):\n",
    "                end = min(start + batch_size, len(dataset_info))\n",
    "                batch_images = []\n",
    "                X_train_batch = dataset_info[start:end]\n",
    "                batch_labels = np.zeros((len(X_train_batch), 28))\n",
    "                for i in range(len(X_train_batch)):\n",
    "                    image = data_generator.load_image(\n",
    "                        X_train_batch[i]['path'], shape)   \n",
    "                    if augument:\n",
    "                        image = data_generator.augment(image)\n",
    "                    batch_images.append(image/255.)\n",
    "                    batch_labels[i][X_train_batch[i]['labels']] = 1\n",
    "                yield np.array(batch_images, np.float32), batch_labels\n",
    "\n",
    "    def load_image(path, shape):\n",
    "        image_red_ch = Image.open(path+'_red.png')\n",
    "        image_yellow_ch = Image.open(path+'_yellow.png')\n",
    "        image_green_ch = Image.open(path+'_green.png')\n",
    "        image_blue_ch = Image.open(path+'_blue.png')\n",
    "        image = np.stack((\n",
    "            np.array(image_red_ch),\n",
    "            np.array(image_green_ch), \n",
    "            np.array(image_blue_ch)), -1)\n",
    "        w, h = 512, 512\n",
    "        zero_data = np.zeros((h, w), dtype=np.uint8)\n",
    "#         image2 = np.stack((\n",
    "#             np.array(image_yellow_ch),\n",
    "#             zero_data, zero_data), -1)\n",
    "#         print(image1.shape, image2.shape)\n",
    "#         image = np.vstack((image1, image2))\n",
    "        image = cv2.resize(image, (shape[0], shape[1]))\n",
    "        return image\n",
    "\n",
    "    def augment(image):\n",
    "        augment_img = iaa.Sequential([\n",
    "            iaa.OneOf([\n",
    "                iaa.Affine(rotate=0),\n",
    "                iaa.Affine(rotate=90),\n",
    "                iaa.Affine(rotate=180),\n",
    "                iaa.Affine(rotate=270),\n",
    "                iaa.Fliplr(0.5),\n",
    "                iaa.Flipud(0.5),\n",
    "            ])], random_order=True)\n",
    "\n",
    "        image_aug = augment_img.augment_image(image)\n",
    "        return image_aug\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, GlobalMaxPooling2D, BatchNormalization, Input, Conv2D\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import metrics\n",
    "from keras.optimizers import Adam \n",
    "from keras import backend as K\n",
    "import keras\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape, n_out):\n",
    "    input_tensor = Input(shape=input_shape)\n",
    "    base_model = InceptionV3(include_top=False,\n",
    "                   weights='imagenet',\n",
    "                   input_shape=input_shape)\n",
    "    bn = BatchNormalization()(input_tensor)\n",
    "    x = base_model(bn)\n",
    "    x = Conv2D(32, kernel_size=(1,1), activation='relu')(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(n_out, activation='sigmoid')(x)\n",
    "    model = Model(input_tensor, output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.ops import array_ops\n",
    "\n",
    "# https://github.com/ailias/Focal-Loss-implement-on-Tensorflow/blob/master/focal_loss.py\n",
    "def focal_loss_org(prediction_tensor, target_tensor, weights=None, alpha=0.25, gamma=2):\n",
    "    r\"\"\"Compute focal loss for predictions.\n",
    "        Multi-labels Focal loss formula:\n",
    "            FL = -alpha * (z-p)^gamma * log(p) -(1-alpha) * p^gamma * log(1-p)\n",
    "                 ,which alpha = 0.25, gamma = 2, p = sigmoid(x), z = target_tensor.\n",
    "    Args:\n",
    "     prediction_tensor: A float tensor of shape [batch_size, num_anchors,\n",
    "        num_classes] representing the predicted logits for each class\n",
    "     target_tensor: A float tensor of shape [batch_size, num_anchors,\n",
    "        num_classes] representing one-hot encoded classification targets\n",
    "     weights: A float tensor of shape [batch_size, num_anchors]\n",
    "     alpha: A scalar tensor for focal loss alpha hyper-parameter\n",
    "     gamma: A scalar tensor for focal loss gamma hyper-parameter\n",
    "    Returns:\n",
    "        loss: A (scalar) tensor representing the value of the loss function\n",
    "    \"\"\"\n",
    "    sigmoid_p = tf.nn.sigmoid(prediction_tensor)\n",
    "    zeros = array_ops.zeros_like(sigmoid_p, dtype=sigmoid_p.dtype)\n",
    "    \n",
    "    # For poitive prediction, only need consider front part loss, back part is 0;\n",
    "    # target_tensor > zeros <=> z=1, so poitive coefficient = z - p.\n",
    "    pos_p_sub = array_ops.where(target_tensor > zeros, target_tensor - sigmoid_p, zeros)\n",
    "    \n",
    "    # For negative prediction, only need consider back part loss, front part is 0;\n",
    "    # target_tensor > zeros <=> z=1, so negative coefficient = 0.\n",
    "    neg_p_sub = array_ops.where(target_tensor > zeros, zeros, sigmoid_p)\n",
    "    per_entry_cross_ent = - alpha * (pos_p_sub ** gamma) * tf.log(tf.clip_by_value(sigmoid_p, 1e-8, 1.0)) \\\n",
    "                          - (1 - alpha) * (neg_p_sub ** gamma) * tf.log(tf.clip_by_value(1.0 - sigmoid_p, 1e-8, 1.0))\n",
    "    return tf.reduce_sum(per_entry_cross_ent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def focal_loss(weights=None, alpha=0.25, gamma=2):\n",
    "    def focal_loss_my(target_tensor, prediction_tensor, ):\n",
    "        r\"\"\"Compute focal loss for predictions.\n",
    "            Multi-labels Focal loss formula:\n",
    "                FL = -alpha * (z-p)^gamma * log(p) -(1-alpha) * p^gamma * log(1-p)\n",
    "                     ,which alpha = 0.25, gamma = 2, p = sigmoid(x), z = target_tensor.\n",
    "        Args:\n",
    "         prediction_tensor: A float tensor of shape [batch_size, num_anchors,\n",
    "            num_classes] representing the predicted logits for each class\n",
    "         target_tensor: A float tensor of shape [batch_size, num_anchors,\n",
    "            num_classes] representing one-hot encoded classification targets\n",
    "         weights: A float tensor of shape [batch_size, num_anchors]\n",
    "         alpha: A scalar tensor for focal loss alpha hyper-parameter\n",
    "         gamma: A scalar tensor for focal loss gamma hyper-parameter\n",
    "        Returns:\n",
    "            loss: A (scalar) tensor representing the value of the loss function\n",
    "        \"\"\"\n",
    "        sigmoid_p = tf.nn.sigmoid(prediction_tensor)\n",
    "        zeros = array_ops.zeros_like(sigmoid_p, dtype=sigmoid_p.dtype)\n",
    "\n",
    "        # For poitive prediction, only need consider front part loss, back part is 0;\n",
    "        # target_tensor > zeros <=> z=1, so poitive coefficient = z - p.\n",
    "        pos_p_sub = array_ops.where(target_tensor > zeros, target_tensor - sigmoid_p, zeros)\n",
    "\n",
    "        # For negative prediction, only need consider back part loss, front part is 0;\n",
    "        # target_tensor > zeros <=> z=1, so negative coefficient = 0.\n",
    "        neg_p_sub = array_ops.where(target_tensor > zeros, zeros, sigmoid_p)\n",
    "        per_entry_cross_ent = - alpha * (pos_p_sub ** gamma) * tf.log(tf.clip_by_value(sigmoid_p, 1e-8, 1.0)) \\\n",
    "                              - (1 - alpha) * (neg_p_sub ** gamma) * tf.log(tf.clip_by_value(1.0 - sigmoid_p, 1e-8, 1.0))\n",
    "        return tf.reduce_sum(per_entry_cross_ent)\n",
    "#         return K.mean(K.binary_crossentropy(target_tensor, prediction_tensor), axis=-1) + tf.reduce_sum(per_entry_cross_ent)\n",
    "    return focal_loss_my"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def focal_loss_fixed(y_true, y_pred):\n",
    "    gamma = 2.\n",
    "    alpha = 0.25\n",
    "    print(y_pred)\n",
    "    print(y_true)\n",
    "    pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
    "    pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
    "\n",
    "#     pt_1 = K.clip(pt_1, 1e-3, .999)\n",
    "#     pt_0 = K.clip(pt_0, 1e-3, .999)\n",
    "\n",
    "    return -K.sum(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1))-K.sum((1-alpha) * K.pow( pt_0, gamma) * K.log(1. - pt_0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def focal_loss(gamma=2., alpha=.25):\n",
    "#     def focal_loss_fixed(y_true, y_pred):\n",
    "#         pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
    "#         pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
    "\n",
    "#         pt_1 = K.clip(pt_1, 1e-3, .999)\n",
    "#         pt_0 = K.clip(pt_0, 1e-3, .999)\n",
    "\n",
    "#         return -K.sum(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1))-K.sum((1-alpha) * K.pow( pt_0, gamma) * K.log(1. - pt_0))\n",
    "#     return focal_loss_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create callbacks list\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "epochs = 10; batch_size = 16\n",
    "checkpoint = ModelCheckpoint('../cache/InceptionV3.h5', monitor='val_loss', verbose=1, \n",
    "                             save_best_only=True, mode='min', save_weights_only = True)\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, \n",
    "                                   verbose=1, mode='auto', epsilon=0.0001)\n",
    "early = EarlyStopping(monitor=\"val_loss\", \n",
    "                      mode=\"min\", \n",
    "                      patience=6)\n",
    "callbacks_list = [checkpoint, early, reduceLROnPlat]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31072,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_info.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1554/1554 [==============================] - 372s 240ms/step - loss: 1.1202 - f1: 0.0373 - val_loss: 1.2955 - val_f1: 0.0395\n",
      "Epoch 2/2\n",
      "1554/1554 [==============================] - 360s 231ms/step - loss: 1.1048 - f1: 0.0495 - val_loss: 1.1427 - val_f1: 0.0314\n",
      "Epoch 1/10\n",
      "1554/1554 [==============================] - 426s 274ms/step - loss: 1.0607 - f1: 0.0917 - val_loss: 1.0183 - val_f1: 0.1393\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.01828, saving model to ../cache/InceptionV3.h5\n",
      "Epoch 2/10\n",
      "1554/1554 [==============================] - 407s 262ms/step - loss: 0.9904 - f1: 0.1597 - val_loss: 0.9650 - val_f1: 0.2090\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.01828 to 0.96498, saving model to ../cache/InceptionV3.h5\n",
      "Epoch 3/10\n",
      "1554/1554 [==============================] - 409s 263ms/step - loss: 0.9408 - f1: 0.2034 - val_loss: 0.8904 - val_f1: 0.2623\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.96498 to 0.89041, saving model to ../cache/InceptionV3.h5\n",
      "Epoch 4/10\n",
      "1554/1554 [==============================] - 410s 264ms/step - loss: 0.9124 - f1: 0.2252 - val_loss: 0.8504 - val_f1: 0.2903\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.89041 to 0.85041, saving model to ../cache/InceptionV3.h5\n",
      "Epoch 5/10\n",
      "1554/1554 [==============================] - 410s 264ms/step - loss: 0.8911 - f1: 0.2408 - val_loss: 0.8529 - val_f1: 0.2953\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.85041\n",
      "Epoch 6/10\n",
      "1554/1554 [==============================] - 410s 264ms/step - loss: 0.8781 - f1: 0.2488 - val_loss: 0.8187 - val_f1: 0.3143\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.85041 to 0.81873, saving model to ../cache/InceptionV3.h5\n",
      "Epoch 7/10\n",
      "1554/1554 [==============================] - 411s 265ms/step - loss: 0.8671 - f1: 0.2566 - val_loss: 0.8505 - val_f1: 0.2990\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.81873\n",
      "Epoch 8/10\n",
      "1554/1554 [==============================] - 412s 265ms/step - loss: 0.8535 - f1: 0.2648 - val_loss: 0.8365 - val_f1: 0.3097\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.81873\n",
      "Epoch 9/10\n",
      "1554/1554 [==============================] - 411s 264ms/step - loss: 0.8461 - f1: 0.2700 - val_loss: 0.8100 - val_f1: 0.3255\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.81873 to 0.80996, saving model to ../cache/InceptionV3.h5\n",
      "Epoch 10/10\n",
      "1554/1554 [==============================] - 411s 265ms/step - loss: 0.8388 - f1: 0.2741 - val_loss: 0.8088 - val_f1: 0.3219\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.80996 to 0.80882, saving model to ../cache/InceptionV3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6215/6215 [03:45<00:00, 27.58it/s]\n",
      "11702it [08:43, 22.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1554/1554 [==============================] - 370s 238ms/step - loss: 1.1204 - f1: 0.0381 - val_loss: 1.1608 - val_f1: 0.0211\n",
      "Epoch 2/2\n",
      "1554/1554 [==============================] - 357s 230ms/step - loss: 1.1044 - f1: 0.0496 - val_loss: 1.1687 - val_f1: 0.0368\n",
      "Epoch 1/10\n",
      "1554/1554 [==============================] - 425s 273ms/step - loss: 1.0517 - f1: 0.1024 - val_loss: 0.9814 - val_f1: 0.1723\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.80882\n",
      "Epoch 2/10\n",
      "1554/1554 [==============================] - 404s 260ms/step - loss: 0.9802 - f1: 0.1700 - val_loss: 0.9262 - val_f1: 0.2357\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.80882\n",
      "Epoch 3/10\n",
      "1554/1554 [==============================] - 402s 259ms/step - loss: 0.9357 - f1: 0.2081 - val_loss: 0.8787 - val_f1: 0.2769\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.80882\n",
      "Epoch 4/10\n",
      "1554/1554 [==============================] - 413s 266ms/step - loss: 0.9092 - f1: 0.2280 - val_loss: 0.8452 - val_f1: 0.3064\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.80882\n",
      "Epoch 5/10\n",
      "1554/1554 [==============================] - 410s 264ms/step - loss: 0.8930 - f1: 0.2385 - val_loss: 0.8250 - val_f1: 0.3098\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.80882\n",
      "Epoch 6/10\n",
      "1554/1554 [==============================] - 410s 264ms/step - loss: 0.8787 - f1: 0.2474 - val_loss: 0.8446 - val_f1: 0.3013\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.80882\n",
      "Epoch 7/10\n",
      "1554/1554 [==============================] - 411s 264ms/step - loss: 0.8687 - f1: 0.2539 - val_loss: 0.8083 - val_f1: 0.3298\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.80882 to 0.80832, saving model to ../cache/InceptionV3.h5\n",
      "Epoch 8/10\n",
      "1554/1554 [==============================] - 410s 264ms/step - loss: 0.8578 - f1: 0.2612 - val_loss: 0.8682 - val_f1: 0.3011\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.80832\n",
      "Epoch 9/10\n",
      "1554/1554 [==============================] - 412s 265ms/step - loss: 0.8485 - f1: 0.2684 - val_loss: 0.8188 - val_f1: 0.3202\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.80832\n",
      "Epoch 10/10\n",
      "1554/1554 [==============================] - 402s 259ms/step - loss: 0.8417 - f1: 0.2726 - val_loss: 0.8047 - val_f1: 0.3348\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.80832 to 0.80470, saving model to ../cache/InceptionV3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6215/6215 [03:52<00:00, 26.70it/s]\n",
      "11702it [07:05, 27.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1554/1554 [==============================] - 364s 235ms/step - loss: 1.1190 - f1: 0.0404 - val_loss: 1.2429 - val_f1: 0.0265\n",
      "Epoch 2/2\n",
      "1554/1554 [==============================] - 352s 227ms/step - loss: 1.1045 - f1: 0.0507 - val_loss: 1.2384 - val_f1: 0.0321\n",
      "Epoch 1/10\n",
      "1554/1554 [==============================] - 422s 271ms/step - loss: 1.0544 - f1: 0.0989 - val_loss: 1.0067 - val_f1: 0.1720\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.80470\n",
      "Epoch 2/10\n",
      "1554/1554 [==============================] - 396s 255ms/step - loss: 0.9806 - f1: 0.1680 - val_loss: 0.9036 - val_f1: 0.2442\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.80470\n",
      "Epoch 3/10\n",
      "1554/1554 [==============================] - 395s 254ms/step - loss: 0.9356 - f1: 0.2062 - val_loss: 0.8960 - val_f1: 0.2617\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.80470\n",
      "Epoch 4/10\n",
      "1554/1554 [==============================] - 395s 254ms/step - loss: 0.9116 - f1: 0.2258 - val_loss: 0.8560 - val_f1: 0.2853\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.80470\n",
      "Epoch 5/10\n",
      "1554/1554 [==============================] - 396s 255ms/step - loss: 0.8909 - f1: 0.2389 - val_loss: 0.8358 - val_f1: 0.3021\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.80470\n",
      "Epoch 6/10\n",
      "1554/1554 [==============================] - 396s 255ms/step - loss: 0.8777 - f1: 0.2478 - val_loss: 0.9163 - val_f1: 0.2655\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.80470\n",
      "Epoch 7/10\n",
      "1554/1554 [==============================] - 429s 276ms/step - loss: 0.8646 - f1: 0.2575 - val_loss: 0.8358 - val_f1: 0.3113\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.80470\n",
      "Epoch 8/10\n",
      "1554/1554 [==============================] - 436s 281ms/step - loss: 0.8557 - f1: 0.2633 - val_loss: 0.7996 - val_f1: 0.3329\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.80470 to 0.79961, saving model to ../cache/InceptionV3.h5\n",
      "Epoch 9/10\n",
      "1554/1554 [==============================] - 443s 285ms/step - loss: 0.8464 - f1: 0.2694 - val_loss: 0.7944 - val_f1: 0.3369\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.79961 to 0.79438, saving model to ../cache/InceptionV3.h5\n",
      "Epoch 10/10\n",
      "1554/1554 [==============================] - 439s 283ms/step - loss: 0.8375 - f1: 0.2752 - val_loss: 0.7936 - val_f1: 0.3357\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.79438 to 0.79359, saving model to ../cache/InceptionV3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6214/6214 [04:10<00:00, 24.82it/s]\n",
      "11702it [07:22, 26.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1554/1554 [==============================] - 438s 282ms/step - loss: 1.1210 - f1: 0.0371 - val_loss: 1.1428 - val_f1: 0.0219\n",
      "Epoch 2/2\n",
      "1554/1554 [==============================] - 353s 227ms/step - loss: 1.1069 - f1: 0.0473 - val_loss: 1.1781 - val_f1: 0.0314\n",
      "Epoch 1/10\n",
      "1554/1554 [==============================] - 434s 279ms/step - loss: 1.0542 - f1: 0.1000 - val_loss: 0.9851 - val_f1: 0.1721\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.79359\n",
      "Epoch 2/10\n",
      "1554/1554 [==============================] - 405s 261ms/step - loss: 0.9828 - f1: 0.1653 - val_loss: 0.9030 - val_f1: 0.2448\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.79359\n",
      "Epoch 3/10\n",
      "1554/1554 [==============================] - 408s 263ms/step - loss: 0.9378 - f1: 0.2046 - val_loss: 0.9002 - val_f1: 0.2667\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.79359\n",
      "Epoch 4/10\n",
      "1554/1554 [==============================] - 444s 286ms/step - loss: 0.9079 - f1: 0.2282 - val_loss: 0.8606 - val_f1: 0.2883\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.79359\n",
      "Epoch 5/10\n",
      "1554/1554 [==============================] - 449s 289ms/step - loss: 0.8904 - f1: 0.2391 - val_loss: 0.8638 - val_f1: 0.2848\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.79359\n",
      "Epoch 6/10\n",
      "1554/1554 [==============================] - 450s 289ms/step - loss: 0.8767 - f1: 0.2485 - val_loss: 0.8628 - val_f1: 0.2956\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.79359\n",
      "Epoch 7/10\n",
      "1554/1554 [==============================] - 447s 288ms/step - loss: 0.8657 - f1: 0.2565 - val_loss: 0.8335 - val_f1: 0.3153\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.79359\n",
      "Epoch 8/10\n",
      "1554/1554 [==============================] - 448s 289ms/step - loss: 0.8545 - f1: 0.2639 - val_loss: 0.7988 - val_f1: 0.3341\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.79359\n",
      "Epoch 9/10\n",
      "1554/1554 [==============================] - 448s 288ms/step - loss: 0.8453 - f1: 0.2700 - val_loss: 0.8065 - val_f1: 0.3282\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.79359\n",
      "Epoch 10/10\n",
      "1554/1554 [==============================] - 434s 280ms/step - loss: 0.8392 - f1: 0.2740 - val_loss: 0.8005 - val_f1: 0.3326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/6214 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00010: val_loss did not improve from 0.79359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6214/6214 [04:23<00:00, 23.61it/s]\n",
      "11702it [08:01, 24.31it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-b27be9d23d79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m     model = create_model(\n\u001b[1;32m     29\u001b[0m         \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mSIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         n_out=28)\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-9efd9b4f0bdd>\u001b[0m in \u001b[0;36mcreate_model\u001b[0;34m(input_shape, n_out)\u001b[0m\n\u001b[1;32m      3\u001b[0m     base_model = InceptionV3(include_top=False,\n\u001b[1;32m      4\u001b[0m                    \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'imagenet'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                    input_shape=input_shape)\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mbn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hpg/lib/python3.6/site-packages/keras/applications/inception_v3.py\u001b[0m in \u001b[0;36mInceptionV3\u001b[0;34m(include_top, weights, input_tensor, input_shape, pooling, classes)\u001b[0m\n\u001b[1;32m    389\u001b[0m                 \u001b[0mcache_subdir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'models'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m                 file_hash='bcbd6486424b2319ff4ef7d526e38f63')\n\u001b[0;32m--> 391\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hpg/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch, reshape)\u001b[0m\n\u001b[1;32m   2665\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2666\u001b[0m                 load_weights_from_hdf5_group(\n\u001b[0;32m-> 2667\u001b[0;31m                     f, self.layers, reshape=reshape)\n\u001b[0m\u001b[1;32m   2668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2669\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_updated_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hpg/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[0;34m(f, layers, reshape)\u001b[0m\n\u001b[1;32m   3391\u001b[0m                              ' elements.')\n\u001b[1;32m   3392\u001b[0m         \u001b[0mweight_value_tuples\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbolic_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3393\u001b[0;31m     \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_value_tuples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hpg/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mbatch_set_value\u001b[0;34m(tuples)\u001b[0m\n\u001b[1;32m   2375\u001b[0m             \u001b[0massign_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2376\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0massign_placeholder\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2377\u001b[0;31m         \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_ops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hpg/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hpg/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hpg/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hpg/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hpg/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hpg/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# split data into train, valid\n",
    "indexes = np.arange(train_dataset_info.shape[0])\n",
    "# np.random.shuffle(indexes)\n",
    "# train_indexes, valid_indexes = train_test_split(indexes, test_size=0.15, random_state=8)\n",
    "n_splits = 5\n",
    "kf = KFold(n_splits=n_splits, random_state=42, shuffle=True)\n",
    "submit = pd.read_csv('../data/sample_submission.csv')\n",
    "\n",
    "# train_generator = data_generator.create_train(\n",
    "#     train_dataset_info[train_indexes], batch_size, (SIZE,SIZE,3), augument=True)\n",
    "# validation_generator = data_generator.create_train(\n",
    "#     train_dataset_info[valid_indexes], 32, (SIZE,SIZE,3), augument=False)\n",
    "\n",
    "oof_class_preds = np.zeros((train_dataset_info.shape[0], 28))\n",
    "sub_class_preds = np.zeros((submit.shape[0], 28))\n",
    "\n",
    "fold_ = 0\n",
    "for train_indexes, valid_indexes in kf.split(indexes):\n",
    "    _preds = []\n",
    "    # create train and valid datagens\n",
    "    train_generator = data_generator.create_train(\n",
    "        train_dataset_info[train_indexes], batch_size, (SIZE,SIZE,3), augument=True)\n",
    "    validation_generator = data_generator.create_train(\n",
    "        train_dataset_info[valid_indexes], 32, (SIZE,SIZE,3), augument=False)\n",
    "\n",
    "    # warm up model\n",
    "    model = create_model(\n",
    "        input_shape=(SIZE,SIZE,3), \n",
    "        n_out=28)\n",
    "\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False\n",
    "    model.layers[-1].trainable = True\n",
    "    model.layers[-2].trainable = True\n",
    "    model.layers[-3].trainable = True\n",
    "    model.layers[-4].trainable = True\n",
    "    model.layers[-5].trainable = True\n",
    "    model.layers[-6].trainable = True\n",
    "    \n",
    "    model.compile(\n",
    "        loss=f1_loss, \n",
    "        optimizer=Adam(1e-03),\n",
    "        metrics=[f1])\n",
    "#     model.summary()\n",
    "\n",
    "    model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=np.ceil(float(len(train_indexes)) / float(batch_size)),\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=np.ceil(float(len(valid_indexes)) / float(batch_size)),\n",
    "        epochs=2, \n",
    "        verbose=1)\n",
    "    \n",
    "    # train all layers\n",
    "    epochs=10\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = True\n",
    "    model.compile(loss=f1_loss,\n",
    "                optimizer=Adam(lr=1e-4),\n",
    "                metrics=[f1])\n",
    "    model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=np.ceil(float(len(train_indexes)) / float(batch_size)),\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=np.ceil(float(len(valid_indexes)) / float(batch_size)),\n",
    "        epochs=epochs, \n",
    "        verbose=1,\n",
    "        callbacks=callbacks_list)\n",
    "    \n",
    "    for idx in tqdm(valid_indexes):\n",
    "        item = train_dataset_info[idx]\n",
    "        path = item['path']\n",
    "        labels = item['labels']\n",
    "        image = data_generator.load_image(path, (SIZE,SIZE,3))/255.\n",
    "        score_predict = model.predict(image[np.newaxis])[0]\n",
    "        oof_class_preds[idx] = score_predict\n",
    "    \n",
    "    for idx, name in tqdm(enumerate(submit['Id'])):\n",
    "        path = os.path.join('../data/test/', name)\n",
    "        image = data_generator.load_image(path, (SIZE,SIZE,3))/255.\n",
    "        score_predict = model.predict(image[np.newaxis])[0]\n",
    "        sub_class_preds[idx] += score_predict\n",
    "    fold_ += 1\n",
    "sub_class_preds /= n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oof_class_preds = np.zeros((train_dataset_info.shape[0], 28))\n",
    "# sub_class_preds = np.zeros((submit.shape[0], 28))\n",
    "# score_predict = model.predict(image[np.newaxis])[0]\n",
    "# oof_class_preds[idx] = score_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.45820379, 0.12732422, 0.3277137 , 0.23298733, 0.3001917 ,\n",
       "       0.24295843, 0.02109067, 0.19385408, 0.00467812, 0.00399152,\n",
       "       0.00271517, 0.06066669, 0.02236799, 0.00866987, 0.03342314,\n",
       "       0.00158739, 0.03309921, 0.00860063, 0.03825995, 0.12749843,\n",
       "       0.01946285, 0.02194879, 0.03339204, 0.14109442, 0.02711315,\n",
       "       0.1113272 , 0.03284218, 0.00121808])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof_class_preds[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "item = train_dataset_info[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([16,  0])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for train_index, test_index in kf.split(indexes):\n",
    "# ...    print(\"TRAIN:\", train_index, \"TEST:\", test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11702, 28)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_class_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11702/11702 [00:00<00:00, 82674.16it/s]\n"
     ]
    }
   ],
   "source": [
    "predicted = []\n",
    "for line in tqdm(sub_class_preds):\n",
    "    label_predict = np.arange(28)[line>=0.2]\n",
    "    str_predict_label = ' '.join(str(l) for l in label_predict)\n",
    "    predicted.append(str_predict_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11702"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0 2',\n",
       " '0 1 3 4 5 6 11 25',\n",
       " '0 2 5 21 25',\n",
       " '0 25',\n",
       " '0 7 21 23 25',\n",
       " '4 12 21 25',\n",
       " '0 4 12 14 21 23 25',\n",
       " '0 23 25',\n",
       " '0',\n",
       " '0 6 21 23 25',\n",
       " '0 5 7 17 18 21 23 25',\n",
       " '3 5',\n",
       " '0 2 21 25',\n",
       " '7 9 18 20 23 25',\n",
       " '0 12 21 23 25',\n",
       " '0 4 5 18 19 21 25',\n",
       " '2 14 16 25',\n",
       " '0 4 5',\n",
       " '11 12 14 16 17 21 25',\n",
       " '0 5',\n",
       " '1 6 25',\n",
       " '0 2 3 5 7 8 20 23 25',\n",
       " '0 2 5 25',\n",
       " '0 16 17 21 23 25',\n",
       " '0 4 21',\n",
       " '0 11 12 21 25',\n",
       " '0 21 25',\n",
       " '0 5 19',\n",
       " '0 25',\n",
       " '0',\n",
       " '0 13 21 25',\n",
       " '0 18 19 21 25',\n",
       " '0 14 16 17 18 21 25',\n",
       " '0 5 25',\n",
       " '0 7 25',\n",
       " '0 13 21 25',\n",
       " '0 23 25 26',\n",
       " '0 3',\n",
       " '0 21 25',\n",
       " '0 1',\n",
       " '0 16 23 25',\n",
       " '6 23 25',\n",
       " '0 21 25',\n",
       " '18 19 25',\n",
       " '0 12 16 21 22 23 25',\n",
       " '6 7 20 21 23 25',\n",
       " '0 2',\n",
       " '0 2 23 25',\n",
       " '0 6 11 14 17 21 23 25',\n",
       " '0',\n",
       " '0 17 25',\n",
       " '0 5',\n",
       " '0 7 11 20 22 23 26',\n",
       " '0 21 23 25',\n",
       " '3 4 25',\n",
       " '0 21 25',\n",
       " '0 21 25',\n",
       " '12 21 23 25',\n",
       " '0 14 16 17 21 25',\n",
       " '0 2 6 16 21 25',\n",
       " '0 2 12 21 22 23',\n",
       " '0 5 16 21 25',\n",
       " '0 4 12 13 14 16 17 21 25',\n",
       " '0 7 21 23 25',\n",
       " '6 23 25',\n",
       " '0 16 17 18 19 21 23 25',\n",
       " '0 1 2 3 6 21 25',\n",
       " '0 21 22 25',\n",
       " '0 1 14 16 25',\n",
       " '0 21 25',\n",
       " '2 3',\n",
       " '0 2 23',\n",
       " '14 16 17 21 25',\n",
       " '4',\n",
       " '0 21 25',\n",
       " '0',\n",
       " '0 2 4',\n",
       " '0 1 5 21',\n",
       " '0 25',\n",
       " '0 25',\n",
       " '0 2 6 14 21 23 25',\n",
       " '0 25',\n",
       " '0 1 2 5 7 21 25',\n",
       " '0 2 21 25',\n",
       " '7 16 17 18 19 25',\n",
       " '0 11 16 23 25',\n",
       " '20 23',\n",
       " '0 21',\n",
       " '6 7 14 16 17 25',\n",
       " '1 6 11 12 14 16 17 21 23 25',\n",
       " '0 2 5 7 18 21 25',\n",
       " '11 21 23 25',\n",
       " '23',\n",
       " '0 12 13 21 22 25',\n",
       " '0 14 16 17 21 23 25',\n",
       " '0 21 25',\n",
       " '7 16 17 18 19 21 23 25',\n",
       " '0 7 16 18 19 25',\n",
       " '5 24',\n",
       " '0 6 23 25',\n",
       " '0 6 23 25',\n",
       " '2 7 23',\n",
       " '0 2 5 21 23 25',\n",
       " '0 23',\n",
       " '6 7 11 25',\n",
       " '0 2 18 19 21 25',\n",
       " '0 11 14 16 17 25',\n",
       " '0 7 11 14 16 18 24 25',\n",
       " '7 8 9 20 21 22 23 26',\n",
       " '0 21 25',\n",
       " '0 2 25',\n",
       " '0 1 25',\n",
       " '0 14 16 17 18 19 25',\n",
       " '0 12 16 21 22 25',\n",
       " '0 3 20 21 23 25 26',\n",
       " '11 21 23 25',\n",
       " '0 2',\n",
       " '4 21 25',\n",
       " '6 11 14 16 17 25',\n",
       " '5 19 20 25 26',\n",
       " '0 18 19 21 25',\n",
       " '0 17 21 25',\n",
       " '0 2 21 25',\n",
       " '0 7 8 20 23',\n",
       " '0 2 4',\n",
       " '0 5',\n",
       " '0 14 16 17 25',\n",
       " '6 21 25',\n",
       " '0 2 3 4 5',\n",
       " '0 18 19',\n",
       " '0 14 16 17 18 23 25',\n",
       " '0 5 21 25',\n",
       " '0',\n",
       " '0 23',\n",
       " '0 11 14 16',\n",
       " '3 5',\n",
       " '0 7 14 16 17 25',\n",
       " '0 25',\n",
       " '0 2 4 5 13 21 25',\n",
       " '6 21 25',\n",
       " '0 18 19 21',\n",
       " '6 14 17 21 23 25',\n",
       " '0 1',\n",
       " '0 5 23 25',\n",
       " '0 2 6 25',\n",
       " '0 4 5 9 16 20 22 25 26',\n",
       " '0 1 14 16 17 21 25',\n",
       " '0 1 6 7 21 23 25',\n",
       " '0',\n",
       " '0 6 25',\n",
       " '0 1 2 3 4 5 7 23',\n",
       " '0 2 7 14 16 17 18 23 25',\n",
       " '0 7',\n",
       " '0 11 16 25',\n",
       " '2 3 6 7 8 20 23 25',\n",
       " '6 23 25',\n",
       " '0 7 23',\n",
       " '0 17 25',\n",
       " '0 1 21 25',\n",
       " '6 17 23 25',\n",
       " '0 16 18 19 25',\n",
       " '0 17 18 21 25',\n",
       " '0 7 11 16 17 18 19 21 24 25',\n",
       " '4 21 25',\n",
       " '0 5',\n",
       " '0 2 21 23',\n",
       " '0 2 3 19 21 25',\n",
       " '0 18 19',\n",
       " '0 2 11 14 17 18 21 25',\n",
       " '0 5 7 18 21 23 25',\n",
       " '0 5 25',\n",
       " '0 1 6 11 21 23 25',\n",
       " '0 2 6 11 14 16 17 25',\n",
       " '2 7 12 21 23 25',\n",
       " '0 2',\n",
       " '0 2 11 12 23 25',\n",
       " '21',\n",
       " '0 7 18 19 21 23 25',\n",
       " '0 12 21 25',\n",
       " '0 2 21 25',\n",
       " '0 4',\n",
       " '0 7 23',\n",
       " '0 2 18 19 25',\n",
       " '0 5 16 19 24',\n",
       " '6 14 16',\n",
       " '0 14 16 17 21 25',\n",
       " '0 16 21 25',\n",
       " '0 2 5 7 21 23 25',\n",
       " '1 6 23',\n",
       " '0 12 13 14 16 17 21 25',\n",
       " '6 14 16 17 21 25',\n",
       " '0 6 25',\n",
       " '0 5 25 26',\n",
       " '6 21 23 25 26',\n",
       " '0 1 3 5 21 25',\n",
       " '0 5 13 21 22 23 25',\n",
       " '0 25',\n",
       " '0 14 16 17 18 19 24 25',\n",
       " '6 23 25',\n",
       " '0 4 6 11 21 25',\n",
       " '2 21',\n",
       " '0 1 2 3 4 5 25',\n",
       " '0 5 25',\n",
       " '0 14 16 17 25',\n",
       " '0 2 3 5 21 25',\n",
       " '21 23',\n",
       " '0 16 17 21 25',\n",
       " '0 4 5 21',\n",
       " '0',\n",
       " '0 21 25',\n",
       " '0 4 12 14 16 21 25',\n",
       " '0 5 22',\n",
       " '7 23 25',\n",
       " '0 2 4 5',\n",
       " '0 18 19 25',\n",
       " '0 5 7 21 25',\n",
       " '3 5 11 20 24 26',\n",
       " '0 5 7 21 22 25 26',\n",
       " '21 22',\n",
       " '0 2 3',\n",
       " '0 2 3 5 13 21 22 25',\n",
       " '0 1 6 14 16 17 21 25',\n",
       " '0 21 25',\n",
       " '0 2 3 4 11 12 21 25',\n",
       " '6 7 8 9 20 23 25',\n",
       " '0 1 2 11 21 23 25',\n",
       " '11 14 21 25',\n",
       " '0 2 6 12 16 21 23 25',\n",
       " '0 18 19',\n",
       " '0 1 2 3 4 5 24',\n",
       " '0 6 11 23 25',\n",
       " '0 11',\n",
       " '0 2 4',\n",
       " '0 23',\n",
       " '0 6 23 25',\n",
       " '11',\n",
       " '7 13 20 21 22 25 26',\n",
       " '0 12 13 21 25',\n",
       " '0 2 7 21 23 25',\n",
       " '0 2 7 16 17 18 19 21 25',\n",
       " '0 12 21',\n",
       " '2 7 23',\n",
       " '0 21 25',\n",
       " '0 6 14 16 21 25',\n",
       " '0 2 11 14 16 17 21 25',\n",
       " '2 4 12 23',\n",
       " '0 7 16 17 18 19 21 25',\n",
       " '4 5',\n",
       " '0 12 13 21 22',\n",
       " '0 1 25',\n",
       " '0 25',\n",
       " '0 21 25',\n",
       " '2 6 21 25',\n",
       " '0 2 23 25',\n",
       " '0 25',\n",
       " '6 11',\n",
       " '21 23',\n",
       " '0 3 5',\n",
       " '0 5 7 18 19 25 26',\n",
       " '12 21 25',\n",
       " '0 6 11 14 16 17 21 25',\n",
       " '0 5 19 25 26',\n",
       " '0 4 5 16 25 26',\n",
       " '0 1 2 5 19 21 25',\n",
       " '0 12 13 21 22 25',\n",
       " '0',\n",
       " '0 12 13 21 22 25',\n",
       " '0 2',\n",
       " '0 7 23 25',\n",
       " '0 6 21 25',\n",
       " '0 18 19',\n",
       " '0 16 17 21 25',\n",
       " '0 12 21 22 25',\n",
       " '0 2 5 21 25',\n",
       " '2 4',\n",
       " '0 7 18 19 25',\n",
       " '0 2 3 5 19',\n",
       " '11 14 25',\n",
       " '0 21 25',\n",
       " '0 12 25',\n",
       " '0 21 25',\n",
       " '0 2 21 23',\n",
       " '0 3 25',\n",
       " '7 8 9 10 18 19 20 22 23 24 25 26',\n",
       " '0 19 21',\n",
       " '0 4 12 21 25',\n",
       " '0 2 3',\n",
       " '7 24',\n",
       " '0 1 2 6 11 25',\n",
       " '7 11 24 25',\n",
       " '0 5 7 11 14 16 18 21 23 25',\n",
       " '0 1 6 7 11 14 16 23 25',\n",
       " '0 7 11 18 21 23 25',\n",
       " '7',\n",
       " '0 4 18 19',\n",
       " '0 21 25',\n",
       " '0 21 23 25',\n",
       " '0 2 3 4 25',\n",
       " '0 2 3 4 5 19',\n",
       " '0 2 4 21 25',\n",
       " '0 19 20 21 22 25 26',\n",
       " '0 2 3 4 5 18 19 25',\n",
       " '0 6 11 14 21 25',\n",
       " '0 2 12 14 16 21 25',\n",
       " '0 6 21 23 25',\n",
       " '0 19',\n",
       " '0 1',\n",
       " '0 6 11 14 16 17 25',\n",
       " '0 21 25',\n",
       " '0 21 25',\n",
       " '0 6 11 21 23 25',\n",
       " '6 11 14 16 17 18 21 25',\n",
       " '0 2 4 7 25',\n",
       " '0 21',\n",
       " '0 25',\n",
       " '0 21 25',\n",
       " '0 14 16 17 18 25',\n",
       " '0 2 3 25',\n",
       " '0 25',\n",
       " '0 17 21 25',\n",
       " '18 19 26',\n",
       " '6 25',\n",
       " '0 17 21 25',\n",
       " '0 2 4',\n",
       " '0 4 5',\n",
       " '0 2 4 7 23 25',\n",
       " '21 22',\n",
       " '0 2 21 25',\n",
       " '0 2 3 4',\n",
       " '0 11 14 16 17 18 25',\n",
       " '5 14',\n",
       " '0 2 3 4 5 7 8 18 19 20 25',\n",
       " '0 17 21 25',\n",
       " '0 1 21 25',\n",
       " '0 11 12 21 25',\n",
       " '7',\n",
       " '0 5 7 9 20 24 25',\n",
       " '0 2 6 11 14 16 17 25',\n",
       " '0 25',\n",
       " '6 25',\n",
       " '0 21 25',\n",
       " '0 7 16 18 25',\n",
       " '0 2 4',\n",
       " '0 14 16 17 25',\n",
       " '0 4 12 21 22 23 25',\n",
       " '0 2 3 5 19 25',\n",
       " '7 18 19 24 25',\n",
       " '0 2 3 7 8 11 25',\n",
       " '0 1 2 6 21 25',\n",
       " '0 25',\n",
       " '0 7 21 23',\n",
       " '8 9 19 20 25 26',\n",
       " '0 6 21 23 25',\n",
       " '0 5 18 19 21',\n",
       " '0 23 25',\n",
       " '3',\n",
       " '0 7 18 24 25',\n",
       " '0 4 5 21',\n",
       " '6 21 25',\n",
       " '0 2 4 23',\n",
       " '0 6 11 18 24 25',\n",
       " '2 6 25',\n",
       " '0 21 25',\n",
       " '0 23 25',\n",
       " '0 6 7 25',\n",
       " '0 11 21 23 25',\n",
       " '11 24 25',\n",
       " '0',\n",
       " '0 1 2 5 18 19 21 25',\n",
       " '0 3 5',\n",
       " '0 14 16 17 18 21 23 25',\n",
       " '0 1 25',\n",
       " '0 21 25',\n",
       " '0 2 21 25',\n",
       " '0 7 13 21 22 23 25',\n",
       " '0 11 12 21 25',\n",
       " '0 3 19 26',\n",
       " '0 3 5 25',\n",
       " '12 21 25',\n",
       " '0 4 13 21 25',\n",
       " '0 21',\n",
       " '2 7',\n",
       " '0 4',\n",
       " '0 2 16 17 21 25',\n",
       " '0 4 5',\n",
       " '0 14 16 17 25',\n",
       " '0 2',\n",
       " '0 2 3 5 21 25',\n",
       " '18 19',\n",
       " '0 21 25',\n",
       " '0 7 14 16 17 18 23 25',\n",
       " '0 23 25',\n",
       " '0 1 14 16 17 25',\n",
       " '0 21 23 25',\n",
       " '0 5 19',\n",
       " '0 3 19 25',\n",
       " '0 12 21 25',\n",
       " '0 11 16 21 25',\n",
       " '0 11 14 16 17 21 23 25',\n",
       " '0 1 12 21 25',\n",
       " '0 6 12 13 21 22 23 25',\n",
       " '0 2 25',\n",
       " '14 17 21 23 25',\n",
       " '0 11 12 14 16 17 21 25',\n",
       " '0 4 14 16 19 21 25',\n",
       " '0 2 6 23 25',\n",
       " '0 12 13 22 23',\n",
       " '0 19 20 23 25 26',\n",
       " '0 21 25',\n",
       " '0 1 11 21 23 25',\n",
       " '6 23 25',\n",
       " '0 4 5 16 21 25',\n",
       " '20 23',\n",
       " '7 21 23 25',\n",
       " '0 21 25',\n",
       " '0',\n",
       " '0 13 21 25',\n",
       " '0 2 16 18 19 21 25',\n",
       " '0 1 2 21 25',\n",
       " '0 7 18 24',\n",
       " '0 4 5 7 21 23 25',\n",
       " '0 1 2 3 4 5',\n",
       " '0 2 7 17 18 21 23 25',\n",
       " '0 2 3 4 25',\n",
       " '0 21 25',\n",
       " '0 7 16 19 25',\n",
       " '0 5 7 17 18 19 21 25',\n",
       " '0 18 19 25',\n",
       " '0 3 5 24',\n",
       " '4 21 25',\n",
       " '0 12 13 21 25',\n",
       " '0 21 23 25',\n",
       " '23',\n",
       " '0 14 16 17 25',\n",
       " '0 7 14 16 17 18 25',\n",
       " '0 7 17 18 19 21 23 25',\n",
       " '0 4',\n",
       " '0 12 21 23 25',\n",
       " '2 4',\n",
       " '7',\n",
       " '0 1 2 6 14 16 17 25',\n",
       " '0 11 12 21 23 25',\n",
       " '0 2 11 14 16 17 18 21 25',\n",
       " '0 2 5 12 13 21 25',\n",
       " '0 25',\n",
       " '0 13 21 22 25 26',\n",
       " '0 16 18 19 25',\n",
       " '0 5 21 25',\n",
       " '0 6 14 16 17 18 25',\n",
       " '0 14 16 17 18 21 25',\n",
       " '11 12 21 25',\n",
       " '0 2 3',\n",
       " '0 4 21 25',\n",
       " '0 2 3 5 19',\n",
       " '0 2 7 21 23 25',\n",
       " '0 5',\n",
       " '0 3 4 5 25',\n",
       " '0 6 21 23 25',\n",
       " '0 6 11 21 23 25',\n",
       " '0 4',\n",
       " '0 1 23 25',\n",
       " '0 2 7 17 18 19 21 25',\n",
       " '0 2 3 21',\n",
       " '0 2 25',\n",
       " '7 20 23',\n",
       " '0 13 21 25',\n",
       " '21 23 25',\n",
       " '0 2 3 5 6 23',\n",
       " '0 2 11',\n",
       " '6 7 11 23 25',\n",
       " '0 2 3',\n",
       " '2 17 18 19 21 23 25',\n",
       " '0 2 3',\n",
       " '0 12 21 25',\n",
       " '0 11 14 16 17 21 25',\n",
       " '0 2 3 4 5',\n",
       " '0 21 25',\n",
       " '0 25',\n",
       " '0 4 6 11 23 25',\n",
       " '4 12',\n",
       " '14 16 25',\n",
       " '0 16 21 22 25',\n",
       " '0 4 11 12',\n",
       " '0 25',\n",
       " '0 21 22',\n",
       " '0 16 21 25',\n",
       " '0 2 6 21 23 25',\n",
       " '0 12 13 21 25',\n",
       " '4',\n",
       " '0 1 21',\n",
       " '0 23 25',\n",
       " '21 23 25',\n",
       " '0 21 25',\n",
       " '2 6 21 25',\n",
       " '0 6 25',\n",
       " '7 23 25',\n",
       " '6 12 21 25',\n",
       " '0 7',\n",
       " '0 23',\n",
       " '0 3 7 8 9 11 18 19 20 23 24 25 26',\n",
       " '0 6 14 17 21 23 25',\n",
       " '0 2 11',\n",
       " '0 25',\n",
       " '0 21 25',\n",
       " '2 21',\n",
       " '0 21 25',\n",
       " '0 4 12 21 25',\n",
       " '2 3 6 7 16 17 18 23 25',\n",
       " '0 7 16 21 23 25',\n",
       " '0 7 18 25',\n",
       " '0 2 21 23 25',\n",
       " '0 4 7 14 16 21 25',\n",
       " '0 12 13 21 25',\n",
       " '0 2 23 25',\n",
       " '0 12 13 21 22 25',\n",
       " '0 21 23 25',\n",
       " '1 7 23',\n",
       " '0 21 23 25',\n",
       " '6 14 16 17 18 19 21 25',\n",
       " '0 3',\n",
       " '0 5 19 21 25 26',\n",
       " '0 3 5 25',\n",
       " '0 1 2 4 19 21 25',\n",
       " '0 2 11 14 16 17 25',\n",
       " '0 2 4 21 23 25',\n",
       " '18 19 21 25',\n",
       " '0 4 5',\n",
       " '0 7 21 23 25',\n",
       " '0 1 14 16 17 25',\n",
       " '21 23',\n",
       " '0 18 19 25',\n",
       " '0 2 21 25',\n",
       " '0 6 14 16 17 18 25',\n",
       " '0 14 16 17 18 21 25',\n",
       " '4 21 25',\n",
       " '0 1 14 16 17 25',\n",
       " '0 2 3 6 7 16 17 18 21 23 25',\n",
       " '18 19',\n",
       " '0 21 25',\n",
       " '18 19',\n",
       " '0 12 21 25',\n",
       " '0 5 21 25',\n",
       " '0 1 2 3 4 5 25 26',\n",
       " '0 21',\n",
       " '0 14 16 25',\n",
       " '7 11',\n",
       " '4',\n",
       " '0 5 21 25',\n",
       " '0 2 7 16 21 23 25',\n",
       " '0 2',\n",
       " '6 23',\n",
       " '14 16 25',\n",
       " '0 2 25',\n",
       " '0 4 11 12 14 16 21 25',\n",
       " '2 7 21 25',\n",
       " '0 21 25',\n",
       " '11 12 21 25',\n",
       " '0 25',\n",
       " '0 1 17 18 19 21 25',\n",
       " '0 25',\n",
       " '0 7 21',\n",
       " '0 25',\n",
       " '12 21 23',\n",
       " '0 2 7 21 23 25',\n",
       " '0 17 18 23 25',\n",
       " '0 21 25',\n",
       " '0 2 12 21 25',\n",
       " '0 5 25',\n",
       " '6 25',\n",
       " '0 23 25',\n",
       " '0 17 18 21 23 25',\n",
       " '0 16 19 25',\n",
       " '6 14 16 17 25',\n",
       " '0 1 5 16 18 19 21 25',\n",
       " '0 6 7 18 19 21 23 25',\n",
       " '0 2 4 5 11 23 24 25',\n",
       " '0 14 16 17 21 25',\n",
       " '7',\n",
       " '0',\n",
       " '0 7 21 25',\n",
       " '0 7 23 25',\n",
       " '0 21 23 25',\n",
       " '6 11 23 25',\n",
       " '5 18 19 21 25',\n",
       " '0 11 12 21 23 25',\n",
       " '0 25',\n",
       " '21',\n",
       " '4 21',\n",
       " '2 6 23',\n",
       " '0 11 21 25',\n",
       " '0 7 16 18 19',\n",
       " '0 5 23',\n",
       " '0 5 7 13 16 20 22 26',\n",
       " '6 25',\n",
       " '0 13 21 22 25',\n",
       " '0 25',\n",
       " '0 5 18 19 21 25',\n",
       " '0 2 3 4',\n",
       " '2 11 12 14 16 21',\n",
       " '1 6 11 14 16 17 25',\n",
       " '0 2 6 12 14 16 17 23 25',\n",
       " '0 1 2',\n",
       " '21 23',\n",
       " '0 25',\n",
       " '0 16 17 21 23 25',\n",
       " '0 1 4 5 21 25',\n",
       " '0 25',\n",
       " '0 18 19 25',\n",
       " '0 4 7 23',\n",
       " '0 12 21 25',\n",
       " '0 21 25',\n",
       " '0 7 17 21 23 25',\n",
       " '0 1 4 11 12 14 16 17 21 25',\n",
       " '12 21 25',\n",
       " '5 19 21',\n",
       " '0 5 21 25',\n",
       " '23',\n",
       " '0 1 6 21 23 25',\n",
       " '0 5 25',\n",
       " '7 18 20 23 25',\n",
       " '0 2 6 21 23 25',\n",
       " '0 3 5',\n",
       " '0 11 21',\n",
       " '11 14 16 17 25',\n",
       " '0 21 23 25',\n",
       " '0 5 21',\n",
       " '0 5 21 22 25',\n",
       " '0 21 22 25',\n",
       " '0 2 21 25',\n",
       " '0 17 23 25',\n",
       " '0 12 21',\n",
       " '0 25',\n",
       " '0 5 7 16 17 18 19 21 25',\n",
       " '0 16 17 21 25',\n",
       " '0 2 3 5 6 21 25',\n",
       " '6 14 16 17 18 25',\n",
       " '0 7 16 17 18 19 21 25',\n",
       " '0 16 18 19',\n",
       " '0 5 25',\n",
       " '0 2 7 21 23 25',\n",
       " '0 5 12 21 22',\n",
       " '0 13 21 25',\n",
       " '0 21 25',\n",
       " '0 17 21 23 25',\n",
       " '0 7',\n",
       " '6 11 12 21 23 25',\n",
       " '0 1 25',\n",
       " '0 7 17 21 23 25',\n",
       " '0 5 7 25',\n",
       " '0 19 20 25 26',\n",
       " '0 1 6 21 25',\n",
       " '0 11 14 16 17 21 25',\n",
       " '0 1 7 19 21 25',\n",
       " '0 2 3 7',\n",
       " '0 2 23',\n",
       " '0 5 12 21',\n",
       " '0 21 23 25',\n",
       " '0 1 4',\n",
       " '0 1 18 19 21 25',\n",
       " '0 6 11 17 23 25',\n",
       " '0 5 7 18 19',\n",
       " '0 2 4 5',\n",
       " '0 7 16 18 19 21 25',\n",
       " '0 16 21 22 25',\n",
       " '0 21 25',\n",
       " '2 4 21 23',\n",
       " '7',\n",
       " '0 5 25',\n",
       " '0 3 5 6 23 25',\n",
       " '21 22',\n",
       " '0 14 16 17 18 25',\n",
       " '0 12 21 22 23 25',\n",
       " '0 2 21 23 25',\n",
       " '0 7',\n",
       " '0 5 14 16 17 25',\n",
       " '18 19',\n",
       " '0 1 21 25',\n",
       " '0 12 21 25',\n",
       " '0 18 19 25 26',\n",
       " '0 7 17 18 19 21 25',\n",
       " '23 25',\n",
       " '0 1 2 21 25',\n",
       " '0 2 4 14 16',\n",
       " '0 13 16 21 22 26',\n",
       " '0 11 21 25',\n",
       " '0 21 25',\n",
       " '0 13 21 22',\n",
       " '0 21',\n",
       " '0 23 25',\n",
       " '0 2 16 17 18 19 21 25',\n",
       " '0 17 21 25',\n",
       " '2 7 23 25',\n",
       " '0 2 5 21 22',\n",
       " '4',\n",
       " '0 12 13 21 25',\n",
       " '0 2 21 25',\n",
       " '11 14 21 25',\n",
       " '0 11 12 21 23 25',\n",
       " '0 1 2 6 11 21 25',\n",
       " '0 1 5 11 12 14 16 17 21 25',\n",
       " '5 11 14 19 24 25',\n",
       " '0 2 7 23 25',\n",
       " '21 23',\n",
       " '11 14 16 17 25',\n",
       " '0 2 3 11 16 25',\n",
       " '0 5 25',\n",
       " '11 24 25',\n",
       " '0 7 23',\n",
       " '0 2 21 25',\n",
       " '3 24 26',\n",
       " '0 5 21 25',\n",
       " '0 25',\n",
       " '21 25',\n",
       " '0 1 2 6 21 25',\n",
       " '0 7 16 17 18 23 25',\n",
       " '0 11 12 21 25',\n",
       " '0 2 11 12 21 22 25',\n",
       " '0 2',\n",
       " '0 2 3 4 5',\n",
       " '0 5 21 25',\n",
       " '0 2 16 17 18 19 25',\n",
       " '21 23',\n",
       " '0 21 23 25',\n",
       " '0 16 17 25',\n",
       " '18 19 26',\n",
       " '0 2',\n",
       " '0 2 21 25',\n",
       " '0 23',\n",
       " '0 1 2 3 4',\n",
       " '0 5 16 19',\n",
       " '0 21 25',\n",
       " '0 4 13 16 21 22 25',\n",
       " '0 4 5 19',\n",
       " '0 21 23 25',\n",
       " '0 2 7',\n",
       " '0 1 2 25',\n",
       " '0 4 7 18 21 23 25',\n",
       " '0 21 25',\n",
       " '0 17 18 19 21 23 25',\n",
       " '6 23',\n",
       " '7 16 18 19 20 23 25 26',\n",
       " '0 3 4 16 21 25',\n",
       " '0 2 21 23 25',\n",
       " '7 21 23 25',\n",
       " '12 19 21 25',\n",
       " '0 2 7 16 17 18 19 21 22 25',\n",
       " '0 13 21 25',\n",
       " '0 21 23 25',\n",
       " '0 2 16 21 23 25',\n",
       " '0 21 25',\n",
       " '0',\n",
       " '0 21 23 25',\n",
       " '0 2 5 11 21 25',\n",
       " '0 2 3',\n",
       " '0 21 25',\n",
       " '0 3 5',\n",
       " '0 6 21 25',\n",
       " '0 1 25',\n",
       " '0 4 5 13 19 21 23 25 26',\n",
       " '6 23 25',\n",
       " '0 6 13 21 25',\n",
       " '0 12 21 23 25',\n",
       " '0 2 5 21 25',\n",
       " '0 6 11 14 16 17 23 25',\n",
       " '3 5 7 24',\n",
       " '6 11 12 14 21 25',\n",
       " '0 4 7 21 22 23 25',\n",
       " '0 18 19 21 22 25',\n",
       " '7 23',\n",
       " '7 11 23',\n",
       " '0 7',\n",
       " '7 9 11 16 18 19 21 22 24 25',\n",
       " '21 23 25',\n",
       " '0 21 25',\n",
       " '0 4 6 14 16 17 21 25',\n",
       " '0 19 21 25',\n",
       " '0 6 11 14 16 17 18 25',\n",
       " '6 23 25',\n",
       " '0 2',\n",
       " '0 6 19 21 25',\n",
       " '0 25',\n",
       " '6 11 14 16 17 18 21 23 25',\n",
       " '0 11 14 16 17 21 25',\n",
       " '0 11 12 14 16 19 21 22 25',\n",
       " '0 11 12 14 16 17 25',\n",
       " '6 11 14 16 17 25',\n",
       " '0 7 16 17 18 19 25',\n",
       " '6 11 21 23 25',\n",
       " '0 3 5',\n",
       " '0 2 7 23',\n",
       " '7 21 23',\n",
       " '0 21',\n",
       " '0 25',\n",
       " '0 19 23 25 26',\n",
       " '0 21 25',\n",
       " '0 2 21 25',\n",
       " '0 21 23 25',\n",
       " '0 1 21 25',\n",
       " '21 22 25',\n",
       " '0 2 3 25',\n",
       " '0 17 18 19 23 25',\n",
       " '0 11 12 14 21 25',\n",
       " '0 21',\n",
       " '0 14 16 17 25',\n",
       " '0 21 25',\n",
       " '0 21 25',\n",
       " '23 25',\n",
       " '4 5 16 17 18 19 21 25',\n",
       " '0 23 25',\n",
       " '0 7 16 18 19 25',\n",
       " '0 1 5 23 25',\n",
       " '11 14 25',\n",
       " '0 2',\n",
       " '0 7 16 17 21 23 25',\n",
       " '0 7 25',\n",
       " '0 5 21 25',\n",
       " '0 6 23 25',\n",
       " '14 16 17 18 21 25',\n",
       " '0 5 11 18 21 25',\n",
       " '0 2 21 23 25',\n",
       " '0 2 21 25',\n",
       " '0 13 14 16 17 25',\n",
       " '0 25',\n",
       " '0 2 21 23 25',\n",
       " '0 1 21 25',\n",
       " '0 2 6 11 21 25',\n",
       " '2 14 17 21 23 25',\n",
       " '0 2 6 21 23 25',\n",
       " '6 11 21 25',\n",
       " '0 21 22 25',\n",
       " '0 21 23 25',\n",
       " '0 11 21 25',\n",
       " '0 25',\n",
       " '0 21 25',\n",
       " '0 25',\n",
       " '0 25',\n",
       " '0 2 3 4 26',\n",
       " '0 19',\n",
       " '0 1 5',\n",
       " '0 2 21 25',\n",
       " '0 17 25',\n",
       " '0 5',\n",
       " '0 1 2 3 18 19 23 25',\n",
       " '0 1 2 3 4 5 14 16',\n",
       " '7',\n",
       " '0 4 20 25 26',\n",
       " '0 16 17 21 25',\n",
       " '0 14 16 17 21 25',\n",
       " '4 12 13 21 25',\n",
       " '0 11 12 21 25',\n",
       " '0 16 17 23 25',\n",
       " '0 2 21 25',\n",
       " '14 16 17 18 19 22 24 25',\n",
       " '0 14 16 17 18 21 25',\n",
       " '0 1 2 17 21 25',\n",
       " '0 19',\n",
       " '6 21 23 25',\n",
       " '0 2 25',\n",
       " '0 12 21 23 25',\n",
       " '0 18 19 25',\n",
       " '0 5 12 21',\n",
       " '0 21 23 25',\n",
       " '0 2 12 21 25',\n",
       " '0 1 14 16 19',\n",
       " '6 19 21 23 25',\n",
       " '0 21 25',\n",
       " '0 5 12 21 25',\n",
       " '0 18 21 25',\n",
       " '0 7 11 14 16 17',\n",
       " '0 4 5 21 25',\n",
       " '11 21 24 25',\n",
       " '0 3 5 24 25',\n",
       " '0 2 3',\n",
       " '0 5 21',\n",
       " '6 11 21 23 25',\n",
       " '0 19 21',\n",
       " '0 22 25',\n",
       " '0 5 21 23',\n",
       " '0 23 25',\n",
       " '6 25',\n",
       " '0 6 23 25',\n",
       " '0 1 2 21 25',\n",
       " '11 21 22 23',\n",
       " '0 2 23 25',\n",
       " '0 11 16 25',\n",
       " '0 1 11 12 13 14 21 25',\n",
       " '0 23',\n",
       " '0 7 21 23 25',\n",
       " '0 19 25',\n",
       " '0 2 21 23 25',\n",
       " '0 2 4 5 7 21 25',\n",
       " '0 5',\n",
       " '23',\n",
       " '0 11 12 21 22 23 25',\n",
       " '0 2 7 16 21 23 25',\n",
       " '0 1 7',\n",
       " '1 6 23 25',\n",
       " '9 13 20 22 25 26',\n",
       " '0 2 21 25',\n",
       " '0 6 21 23 25',\n",
       " '0 7',\n",
       " '0 21 25',\n",
       " '0 2 13 21 22',\n",
       " '23',\n",
       " '0 25',\n",
       " '0 2 14 16 17 21 25',\n",
       " '4',\n",
       " '0 25',\n",
       " '0 4 5 7',\n",
       " '0 5 11 12 16 18 19 21 22 25',\n",
       " '0 2 3 5',\n",
       " '0 7 16 17 18 19 23 25',\n",
       " '0 2 21 23 25',\n",
       " '0 2 21 25',\n",
       " '19 22 25 26',\n",
       " '0 7',\n",
       " '0 14 16 17 25',\n",
       " '6 21 25',\n",
       " '7 25',\n",
       " '0 2 6 21 25',\n",
       " '0 7',\n",
       " '2 6 17 23 25',\n",
       " '0',\n",
       " '7 18 23 25',\n",
       " '0 21 23 25',\n",
       " '0 3 5',\n",
       " '0 2 21 25',\n",
       " '0 17 21 23 25',\n",
       " '0 2 6 7 16 17 25',\n",
       " '0 21 25',\n",
       " '0 1 6 21 25',\n",
       " '11 17 18 19 24 25',\n",
       " '0 2 3 4',\n",
       " '0 4',\n",
       " '14 16 17 18 19 21 23 25',\n",
       " '6 14 16 17 25',\n",
       " '0 21 25',\n",
       " '0 1 2 21 22 25',\n",
       " '18 19',\n",
       " '0 11 14 21 23 25',\n",
       " '0 2 7 14 16 17 18 19 21 25',\n",
       " '0 1 21 25',\n",
       " '0 12 21',\n",
       " '0 6 21 22 25',\n",
       " '0 1 6 21 25',\n",
       " '1 6 14 16 17 18 21 25',\n",
       " '0 2 3 4',\n",
       " '7 23',\n",
       " '0 1 25',\n",
       " '0 2 16 17 21 23 25',\n",
       " '0 2 4 21 23',\n",
       " '0 21 25',\n",
       " '0 1 6 11 14 16 17 25',\n",
       " '0 1 2 3 7',\n",
       " '0 14 16 17 18 21 25',\n",
       " '0 4 12 14 16 21 25',\n",
       " '0 1 12 21 25',\n",
       " '0 25',\n",
       " '0 7 19 23 25',\n",
       " '0 2 3',\n",
       " '0 16 18 19 25',\n",
       " '0 6 11 23 25',\n",
       " '0 16 17 23 25',\n",
       " '0 7 14 16 18 19 25',\n",
       " '0 12 25',\n",
       " '7 18 20 23 24 25',\n",
       " '0 21 23 25',\n",
       " '0 7 25',\n",
       " '0 7 25',\n",
       " '0 7',\n",
       " '6 21 25',\n",
       " '0 11 12 14 16 17 21 25',\n",
       " '0 4 11 12 16 22 25 26',\n",
       " '0 4 19',\n",
       " '0 5 21 22',\n",
       " '0 21 25',\n",
       " '0 1 2 25',\n",
       " '0 14 16 17 18 25',\n",
       " '0 25',\n",
       " '0 2 21 25',\n",
       " '11 12 14 16 17 21 25',\n",
       " '0 1 7 11 14 16 17 21 25',\n",
       " '0 21 23 25',\n",
       " '0 3',\n",
       " '0 1 4 6 21 23 25',\n",
       " '0 2 3 5 23 25',\n",
       " '0 2 3 25',\n",
       " '0 5 7 18 19 21 25',\n",
       " '0 2 23 25',\n",
       " '3 5',\n",
       " '0 2 5 25',\n",
       " '0 1 2',\n",
       " '0 1 19',\n",
       " '0 2',\n",
       " '0 2',\n",
       " '0 5 7 25',\n",
       " '0 1 5 25',\n",
       " '0 2 16 17 18 21 25',\n",
       " '0 2 21 25',\n",
       " '0 23 25',\n",
       " ...]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit['Predicted'] = predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submit\n",
    "# submit = pd.read_csv('../data/sample_submission.csv')\n",
    "# predicted = []\n",
    "# draw_predict = []\n",
    "# # model.load_weights('../cache/InceptionV3.h5')\n",
    "# for name in tqdm(submit['Id']):\n",
    "#     path = os.path.join('../data/test/', name)\n",
    "#     image = data_generator.load_image(path, (SIZE,SIZE,3))/255.\n",
    "#     score_predict = model.predict(image[np.newaxis])[0]\n",
    "#     draw_predict.append(score_predict)\n",
    "#     label_predict = np.arange(28)[score_predict>=0.2]\n",
    "#     str_predict_label = ' '.join(str(l) for l in label_predict)\n",
    "#     predicted.append(str_predict_label)\n",
    "\n",
    "# submit['Predicted'] = predicted\n",
    "# np.save('../cache/draw_predict_InceptionV3-8.npy', score_predict)\n",
    "# submit.to_csv('../submissions/submit_InceptionV3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv('../submissions/sub10.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/1855095/how-to-create-a-zip-archive-of-a-directory\n",
    "def backup_project_as_zip(project_dir, zip_file):\n",
    "    assert(os.path.isdir(project_dir))\n",
    "    assert(os.path.isdir(os.path.dirname(zip_file)))\n",
    "    shutil.make_archive(zip_file.replace('.zip',''), 'zip', project_dir)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-10-22 22:46:14.145230\n"
     ]
    }
   ],
   "source": [
    "import datetime, shutil\n",
    "now = datetime.datetime.now()\n",
    "print(now)\n",
    "PROJECT_PATH = '/home/watts/lal/Kaggle/kagglehp/scripts_nbs'\n",
    "backup_project_as_zip(PROJECT_PATH, '../cache/code.scripts_nbs.%s.zip'%now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.4.7.1 / client 1.3.8)\n",
      "Successfully submitted to Human Protein Atlas Image ClassificationCPU times: user 343 ms, sys: 185 ms, total: 528 ms\n",
      "Wall time: 16.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!kaggle competitions submit -c human-protein-atlas-image-classification -f ../submissions/sub10.csv -m \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.4.7.1 / client 1.3.8)\r\n",
      "fileName   date                 description  status    publicScore  privateScore  \r\n",
      "---------  -------------------  -----------  --------  -----------  ------------  \r\n",
      "sub10.csv  2018-10-22 17:16:40               complete  0.336        None          \r\n",
      "sub9.csv   2018-10-21 20:04:09               complete  0.098        None          \r\n",
      "sub9.csv   2018-10-21 19:44:17               complete  0.073        None          \r\n",
      "sub9.csv   2018-10-21 19:37:30               complete  0.043        None          \r\n",
      "sub9.csv   2018-10-21 19:27:51               complete  0.000        None          \r\n",
      "sub8.csv   2018-10-20 20:08:45               complete  0.422        None          \r\n",
      "sub7.csv   2018-10-20 17:06:09               complete  0.389        None          \r\n",
      "sub5.csv   2018-10-19 18:27:33               complete  0.387        None          \r\n",
      "sub4.csv   2018-10-19 14:45:15               complete  0.411        None          \r\n",
      "sub3.csv   2018-10-19 10:19:26               complete  0.377        None          \r\n",
      "sub2.csv   2018-10-19 08:07:30               complete  0.135        None          \r\n",
      "sub1.csv   2018-10-19 06:28:57               complete  0.374        None          \r\n"
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "sleep(10)\n",
    "!kaggle competitions submissions -c human-protein-atlas-image-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hpg",
   "language": "python",
   "name": "hpg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
