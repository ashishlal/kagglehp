{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/mathormad/inceptionv3-baseline-lb-0-379/code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.io\n",
    "from skimage.transform import resize\n",
    "from imgaug import augmenters as iaa\n",
    "from tqdm import tqdm\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from sklearn.utils import class_weight, shuffle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "SIZE = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/rejpalcz/best-loss-function-for-f1-score-metric/notebook\n",
    "import tensorflow as tf\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    y_pred = K.round(y_pred)\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n",
    "\n",
    "def f1_loss(y_true, y_pred):\n",
    "    \n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(K.binary_crossentropy(y_true, y_pred), axis=-1) + (1 - K.mean(f1))\n",
    "\n",
    "# POS_WEIGHT = 1.0  # multiplier for positive targets, needs to be tuned\n",
    "\n",
    "# def weighted_binary_crossentropy(target, output):\n",
    "#     \"\"\"\n",
    "#     Weighted binary crossentropy between an output tensor \n",
    "#     and a target tensor. POS_WEIGHT is used as a multiplier \n",
    "#     for the positive targets.\n",
    "\n",
    "#     Combination of the following functions:\n",
    "#     * keras.losses.binary_crossentropy\n",
    "#     * keras.backend.tensorflow_backend.binary_crossentropy\n",
    "#     * tf.nn.weighted_cross_entropy_with_logits\n",
    "#     \"\"\"\n",
    "#     # transform back to logits\n",
    "# #     _epsilon = tfb._to_tensor(tfb.epsilon(), output.dtype.base_dtype)\n",
    "#     _epsilon = K.epsilon()\n",
    "#     output = tf.clip_by_value(output, _epsilon, 1 - _epsilon)\n",
    "#     output = tf.log(output / (1 - output))\n",
    "#     # compute weighted loss\n",
    "#     loss = tf.nn.weighted_cross_entropy_with_logits(targets=target,\n",
    "#                                                     logits=output,\n",
    "#                                                     pos_weight=POS_WEIGHT)\n",
    "#     return tf.reduce_mean(loss, axis=-1)\n",
    "\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.python.framework import ops\n",
    "# from functools import reduce\n",
    "\n",
    "# def binaryRound(x):\n",
    "#     \"\"\"\n",
    "#     Rounds a tensor whose values are in [0,1] to a tensor with values in {0, 1},\n",
    "#     using the straight through estimator for the gradient.\n",
    "#     \"\"\"\n",
    "#     g = tf.get_default_graph()\n",
    "\n",
    "#     with ops.name_scope(\"BinaryRound\") as name:\n",
    "#         with g.gradient_override_map({\"Round\": \"Identity\"}):\n",
    "#             return tf.round(x, name=name)\n",
    "\n",
    "#         # For Tensorflow v0.11 and below use:\n",
    "#         #with g.gradient_override_map({\"Floor\": \"Identity\"}):\n",
    "#         #    return tf.round(x, name=name)\n",
    "        \n",
    "# def f1_loss2(y_true, y_pred):\n",
    "#     y_pred = binaryRound(y_pred)\n",
    "#     tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "#     tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "#     fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "#     fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "#     p = tp / (tp + fp + K.epsilon())\n",
    "#     r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "#     f1 = 2*p*r / (p+r+K.epsilon())\n",
    "#     f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "#     return K.mean(K.binary_crossentropy(y_true, y_pred), axis=-1) + (1-K.mean(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load dataset info\n",
    "path_to_train = '../data/train/'\n",
    "data = pd.read_csv('../data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00070df0-bbc3-11e8-b2bc-ac1f6b6435d0</td>\n",
       "      <td>16 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000a6c98-bb9b-11e8-b2b9-ac1f6b6435d0</td>\n",
       "      <td>7 1 2 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000a9596-bbc4-11e8-b2bc-ac1f6b6435d0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000c99ba-bba4-11e8-b2b9-ac1f6b6435d0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001838f8-bbca-11e8-b2bc-ac1f6b6435d0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Id   Target\n",
       "0  00070df0-bbc3-11e8-b2bc-ac1f6b6435d0     16 0\n",
       "1  000a6c98-bb9b-11e8-b2b9-ac1f6b6435d0  7 1 2 0\n",
       "2  000a9596-bbc4-11e8-b2bc-ac1f6b6435d0        5\n",
       "3  000c99ba-bba4-11e8-b2b9-ac1f6b6435d0        1\n",
       "4  001838f8-bbca-11e8-b2bc-ac1f6b6435d0       18"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dataset_info = []\n",
    "for name, labels in zip(data['Id'], data['Target'].str.split(' ')):\n",
    "    train_dataset_info.append({\n",
    "        'path':os.path.join(path_to_train, name),\n",
    "        'labels':np.array([int(label) for label in labels])})\n",
    "train_dataset_info = np.array(train_dataset_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([{'path': '../data/train/00070df0-bbc3-11e8-b2bc-ac1f6b6435d0', 'labels': array([16,  0])},\n",
       "       {'path': '../data/train/000a6c98-bb9b-11e8-b2b9-ac1f6b6435d0', 'labels': array([7, 1, 2, 0])},\n",
       "       {'path': '../data/train/000a9596-bbc4-11e8-b2bc-ac1f6b6435d0', 'labels': array([5])},\n",
       "       ...,\n",
       "       {'path': '../data/train/fff189d8-bbab-11e8-b2ba-ac1f6b6435d0', 'labels': array([7])},\n",
       "       {'path': '../data/train/fffdf7e0-bbc4-11e8-b2bc-ac1f6b6435d0', 'labels': array([25,  2, 21])},\n",
       "       {'path': '../data/train/fffe0ffe-bbc0-11e8-b2bb-ac1f6b6435d0', 'labels': array([2, 0])}],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11702/11702 [00:00<00:00, 70625.08it/s]\n"
     ]
    }
   ],
   "source": [
    "submit = pd.read_csv('../data/sample_submission.csv')\n",
    "path_to_test = '../data/test/'\n",
    "test_dataset_info = []\n",
    "for name in tqdm(submit['Id']):\n",
    "    test_dataset_info.append({\n",
    "        'path':os.path.join(path_to_test, name)})\n",
    "test_dataset_info = np.array(test_dataset_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# rgb_arr = np.memmap('../cache/tmp_rgb_arr', dtype='uint8', mode='r+', \n",
    "#                    shape=(len(train_dataset_info),299,299,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class data_generator:\n",
    "    \n",
    "    def create_train(dataset_info, batch_size, shape, augument=True):\n",
    "        assert shape[2] == 3\n",
    "        while True:\n",
    "            dataset_info = shuffle(dataset_info)\n",
    "            for start in range(0, len(dataset_info), batch_size):\n",
    "                end = min(start + batch_size, len(dataset_info))\n",
    "                batch_images = []\n",
    "                X_train_batch = dataset_info[start:end]\n",
    "                batch_labels = np.zeros((len(X_train_batch), 28))\n",
    "                for i in range(len(X_train_batch)):\n",
    "                    image = data_generator.load_image(\n",
    "                        X_train_batch[i]['path'], shape) \n",
    "#                     image = data_generator.load_image(\n",
    "#                         i, shape) \n",
    "                    if augument:\n",
    "                        image = data_generator.augment(image)\n",
    "                    batch_images.append(image/255.)\n",
    "                    batch_labels[i][X_train_batch[i]['labels']] = 1\n",
    "                yield np.array(batch_images, np.float32), batch_labels\n",
    "    def create_train2(dataset_info, batch_size, shape, augument=False):\n",
    "        assert shape[2] == 3\n",
    "        while True:\n",
    "            dataset_info = shuffle(dataset_info)\n",
    "            for start in range(0, len(dataset_info), batch_size):\n",
    "                end = min(start + batch_size, len(dataset_info))\n",
    "                batch_images = []\n",
    "                X_train_batch = dataset_info[start:end]\n",
    "                batch_labels = np.zeros((len(X_train_batch), 28))\n",
    "                for i in range(len(X_train_batch)):\n",
    "                    image = data_generator.load_image(\n",
    "                        X_train_batch[i]['path'], shape) \n",
    "#                     image = data_generator.load_image(\n",
    "#                         i, shape) \n",
    "                    \n",
    "                    batch_images.append(image/255.)\n",
    "                    \n",
    "                yield np.array(batch_images, np.float32), None\n",
    "    def create_test(dataset_info, batch_size, shape, augument=False):\n",
    "        assert shape[2] == 3\n",
    "        while True:\n",
    "            dataset_info = shuffle(dataset_info)\n",
    "            for start in range(0, len(dataset_info), batch_size):\n",
    "                end = min(start + batch_size, len(dataset_info))\n",
    "                batch_images = []\n",
    "                X_test_batch = dataset_info[start:end]\n",
    "                batch_labels = np.zeros((len(X_test_batch), 28))\n",
    "                for i in range(len(X_test_batch)):\n",
    "                    image = data_generator.load_image(\n",
    "                        X_test_batch[i]['path'], shape) \n",
    "#                     image = data_generator.load_image(\n",
    "#                         i, shape) \n",
    "                    \n",
    "                    batch_images.append(image/255.)\n",
    "                    \n",
    "                yield np.array(batch_images, np.float32), None\n",
    "    def load_image(path, shape):\n",
    "        img1 = cv2.imread(path+'_red.png', cv2.IMREAD_GRAYSCALE)\n",
    "        img2 = cv2.imread(path+'_green.png', cv2.IMREAD_GRAYSCALE)\n",
    "        img3 = cv2.imread(path+'_blue.png', cv2.IMREAD_GRAYSCALE)\n",
    "        image = np.stack((img1,img2,img3), -1)\n",
    "        image = cv2.resize(image, (shape[0], shape[1]))\n",
    "        return image\n",
    "    def load_image3(idx, shape):\n",
    "#         print(idx)\n",
    "        name = '../cache/RGB/img-{}.png'.format(idx)\n",
    "        image = cv2.imread(name)\n",
    "        image = cv2.resize(image, (shape[0], shape[1]))\n",
    "        return image\n",
    "    def load_image2(path, shape):\n",
    "        image_red_ch = Image.open(path+'_red.png')\n",
    "        image_yellow_ch = Image.open(path+'_yellow.png')\n",
    "        image_green_ch = Image.open(path+'_green.png')\n",
    "        image_blue_ch = Image.open(path+'_blue.png')\n",
    "        image = np.stack((\n",
    "            np.array(image_red_ch),\n",
    "            np.array(image_green_ch), \n",
    "            np.array(image_blue_ch)), -1)\n",
    "        w, h = 512, 512\n",
    "#         zero_data = np.zeros((h, w), dtype=np.uint8)\n",
    "#         image2 = np.stack((\n",
    "#             np.array(image_yellow_ch),\n",
    "#             zero_data, zero_data), -1)\n",
    "#         print(image1.shape, image2.shape)\n",
    "#         image = np.vstack((image1, image2))\n",
    "        image = cv2.resize(image, (shape[0], shape[1]))\n",
    "        return image\n",
    "    \n",
    "    def augment2(image):\n",
    "        augment_img = iaa.Sequential([\n",
    "            iaa.OneOf([\n",
    "                iaa.Affine(rotate=0),\n",
    "                iaa.Affine(rotate=90),\n",
    "                iaa.Affine(rotate=180),\n",
    "                iaa.Affine(rotate=270),\n",
    "                iaa.Fliplr(0.5),\n",
    "                iaa.Flipud(0.5),\n",
    "            ])], random_order=True)\n",
    "\n",
    "        image_aug = augment_img.augment_image(image)\n",
    "        return image_aug\n",
    "    def augment(image):\n",
    "        augment_img = iaa.Sequential([\n",
    "            iaa.OneOf([\n",
    "                    iaa.Fliplr(0.5), # horizontal flips\n",
    "                    iaa.Affine(rotate=0),\n",
    "                    iaa.Affine(rotate=90),\n",
    "                    iaa.Affine(rotate=180),\n",
    "                    iaa.Affine(rotate=270),\n",
    "                    iaa.Flipud(0.5),\n",
    "                    iaa.Crop(percent=(0, 0.1)), # random crops\n",
    "                    # Small gaussian blur with random sigma between 0 and 0.5.\n",
    "                    # But we only blur about 50% of all images.\n",
    "                    iaa.Sometimes(0.5,\n",
    "                        iaa.GaussianBlur(sigma=(0, 0.5))\n",
    "                    ),\n",
    "                    # Strengthen or weaken the contrast in each image.\n",
    "                    iaa.ContrastNormalization((0.75, 1.5)),\n",
    "                    # Add gaussian noise.\n",
    "                    # For 50% of all images, we sample the noise once per pixel.\n",
    "                    # For the other 50% of all images, we sample the noise per pixel AND\n",
    "                    # channel. This can change the color (not only brightness) of the\n",
    "                    # pixels.\n",
    "                    iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.05*255), per_channel=0.5),\n",
    "                    # Make some images brighter and some darker.\n",
    "                    # In 20% of all cases, we sample the multiplier once per channel,\n",
    "                    # which can end up changing the color of the images.\n",
    "                    iaa.Multiply((0.8, 1.2), per_channel=0.2),\n",
    "                    # Apply affine transformations to each image.\n",
    "                    # Scale/zoom them, translate/move them, rotate them and shear them.\n",
    "                    iaa.Affine(\n",
    "                        scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)},\n",
    "                        translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},\n",
    "                        rotate=(-180, 180),\n",
    "                        shear=(-8, 8)\n",
    "                    )\n",
    "                ])], random_order=True)\n",
    "\n",
    "        image_aug = augment_img.augment_image(image)\n",
    "        return image_aug\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.4\n"
     ]
    }
   ],
   "source": [
    "import keras as k\n",
    "print(k.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# !pip install -U keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, GlobalMaxPooling2D, BatchNormalization, Input, Conv2D\n",
    "from keras.layers import UpSampling2D, Lambda, Reshape, Conv2DTranspose\n",
    "from keras.layers import  MaxPooling2D, concatenate, merge, ReLU, LeakyReLU, GlobalAveragePooling2D\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import metrics\n",
    "from keras.optimizers import Adam \n",
    "from keras import backend as K\n",
    "import keras\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape1, input_shape2, input_shape3, input_shape4, n_out):\n",
    "    input_tensor1 = Input(shape=input_shape1)\n",
    "    \n",
    "    input_tensor2 = Input(shape=input_shape2)\n",
    "    \n",
    "    input_tensor3 = Input(shape=input_shape3)\n",
    "    \n",
    "    input_tensor4 = Input(shape=input_shape4)\n",
    "    \n",
    "    x1 = Conv2D(64, kernel_size=(5,5), activation='relu', padding='same', name='conv1a')(input_tensor1)\n",
    "    x1 = MaxPooling2D(pool_size=(2, 2), padding='same')(x1)\n",
    "    \n",
    "    x1 = Conv2D(128, kernel_size=(3,3), activation='relu', padding='same', name='conv2a')(x1)\n",
    "    x1 = MaxPooling2D(pool_size=(2, 2), padding='same')(x1)\n",
    "    \n",
    "    x1 = Conv2D(256, kernel_size=(3,3), activation='relu', padding='same', name='conv3a')(x1)\n",
    "    x1 = MaxPooling2D(pool_size=(2, 2), padding='same')(x1)\n",
    "    \n",
    "    x2 = Conv2D(64, kernel_size=(5,5), activation='relu', padding='same', name='conv1b')(input_tensor2)\n",
    "    x2 = MaxPooling2D(pool_size=(2, 2), padding='same')(x2)\n",
    "    \n",
    "    x2 = Conv2D(128, kernel_size=(3,3), activation='relu', padding='same', name='conv2b')(x2)\n",
    "    x2 = MaxPooling2D(pool_size=(2, 2), padding='same')(x2)\n",
    "    \n",
    "    x2 = Conv2D(256, kernel_size=(3,3), activation='relu', padding='same', name='conv3b')(x2)\n",
    "    x2 = MaxPooling2D(pool_size=(2, 2), padding='same')(x2)\n",
    "    \n",
    "    x3 = Conv2D(64, kernel_size=(5,5), activation='relu', padding='same', name='conv1c')(input_tensor3)\n",
    "    x3 = MaxPooling2D(pool_size=(2, 2), padding='same')(x3)\n",
    "    \n",
    "    x3 = Conv2D(128, kernel_size=(3,3), activation='relu', padding='same', name='conv2c')(x3)\n",
    "    x3 = MaxPooling2D(pool_size=(2, 2), padding='same')(x3)\n",
    "    \n",
    "    x3 = Conv2D(256, kernel_size=(3,3), activation='relu', padding='same', name='conv3c')(x3)\n",
    "    x3 = MaxPooling2D(pool_size=(2, 2), padding='same')(x3)\n",
    "    \n",
    "    x4 = Conv2D(64, kernel_size=(5,5), activation='relu', padding='same', name='conv1d')(input_tensor4)\n",
    "    x4 = MaxPooling2D(pool_size=(2, 2), padding='same')(x4)\n",
    "    \n",
    "    x4 = Conv2D(128, kernel_size=(3,3), activation='relu', padding='same', name='conv2d')(x4)\n",
    "    x4 = MaxPooling2D(pool_size=(2, 2), padding='same')(x4)\n",
    "    \n",
    "    x4 = Conv2D(256, kernel_size=(3,3), activation='relu', padding='same', name='conv3d')(x4)\n",
    "    x4 = MaxPooling2D(pool_size=(2, 2), padding='same')(x4)\n",
    "    \n",
    "    x = concatenate([x1, x2, x3, x4], axis=3)\n",
    "\n",
    "    x = Conv2D(256, kernel_size=(3,3), activation='relu', padding='same', name='conv4')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), padding='same', data_format=None)(x)\n",
    "    \n",
    "    output = Conv2D(n_out, kernel_size=(3,3), activation='sigmoid', padding='same', name='confidence_map')(x)\n",
    "    \n",
    "    model = Model([input_tensor1, input_tensor2, input_tensor3, input_tensor4], output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_193 (InputLayer)       (None, 512, 512, 1)       0         \n",
      "_________________________________________________________________\n",
      "conv1a (Conv2D)              (None, 512, 512, 64)      1664      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_535 (MaxPoolin (None, 256, 256, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2a (Conv2D)              (None, 256, 256, 128)     73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_536 (MaxPoolin (None, 128, 128, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv3a (Conv2D)              (None, 128, 128, 256)     295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_537 (MaxPoolin (None, 64, 64, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv4 (Conv2D)               (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_547 (MaxPoolin (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "confidence_map (Conv2D)      (None, 30, 30, 28)        64540     \n",
      "=================================================================\n",
      "Total params: 1,025,308\n",
      "Trainable params: 1,025,308\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model(\n",
    "    input_shape1=(SIZE,SIZE, 1), input_shape2=(SIZE,SIZE,1), input_shape3=(SIZE,SIZE,1), \n",
    "    input_shape4=(SIZE,SIZE,1),\n",
    "    n_out=28)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 16\n",
    "kernel_size = 3\n",
    "layer_filters = [32, 64, 128, 256, 512]\n",
    "from keras.regularizers import l2\n",
    "def create_model(input_shape, n_out):\n",
    "    input_tensor = Input(shape=input_shape)\n",
    "    base_model = InceptionV3(include_top=False,\n",
    "                   weights='imagenet',\n",
    "                   input_shape=input_shape)\n",
    "    bn = BatchNormalization()(input_tensor)\n",
    "    x = base_model(bn)\n",
    "#     w = K.get_session().run(base_model.trainable_weights)\n",
    "#     print(w.shape)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    W_x = Dense(x.shape[1], kernel_initializer='glorot_uniform', use_bias=True, kernel_regularizer=l2(0.))\n",
    "    print(W_x.shape)\n",
    "    x = K.dot(x, W_x)\n",
    "    print(x.shape)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    \n",
    "    output = Dense(n_out, activation='sigmoid', name='output')(x)\n",
    "    model = Model(input_tensor, output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1568.0"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "401408/(16*16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "307328.0"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(401408*14*14)/(16*16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Dense' object has no attribute 'get_shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-67c9ddf896d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m model = create_model(\n\u001b[0;32m----> 2\u001b[0;31m     input_shape=(SIZE,SIZE,3), n_out=28)\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-68-5349f58bbaed>\u001b[0m in \u001b[0;36mcreate_model\u001b[0;34m(input_shape, n_out)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGlobalAveragePooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mW_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'glorot_uniform'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_bias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_regularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ml2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hpg/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mdot\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1059\u001b[0m     \u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1060\u001b[0m     \"\"\"\n\u001b[0;32m-> 1061\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1062\u001b[0m         \u001b[0mx_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1063\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hpg/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mndim\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    617\u001b[0m     \u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m     \"\"\"\n\u001b[0;32m--> 619\u001b[0;31m     \u001b[0mdims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dims\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    620\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdims\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Dense' object has no attribute 'get_shape'"
     ]
    }
   ],
   "source": [
    "model = create_model(\n",
    "    input_shape1=(SIZE,SIZE,3), n_out=28)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create callbacks list\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "epochs = 10; batch_size = 16\n",
    "checkpoint = ModelCheckpoint('../cache/iv3-40.h5', monitor='val_loss', verbose=1, \n",
    "                             save_best_only=True, mode='min', save_weights_only = True)\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, \n",
    "                                   verbose=1, mode='auto', epsilon=0.0001)\n",
    "early = EarlyStopping(monitor=\"val_loss\", \n",
    "                      mode=\"min\", \n",
    "                      patience=6)\n",
    "callbacks_list = [checkpoint, early, reduceLROnPlat]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# split data into train, valid\n",
    "indexes = np.arange(train_dataset_info.shape[0])\n",
    "np.random.shuffle(indexes)\n",
    "train_indexes, valid_indexes = train_test_split(indexes, test_size=0.15, random_state=8)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_17 (InputLayer)        (None, 512, 512, 3)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_855 (Bat (None, 512, 512, 3)       12        \n",
      "_________________________________________________________________\n",
      "inception_v3 (Model)         (None, 14, 14, 2048)      21802784  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_6 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 28)                28700     \n",
      "=================================================================\n",
      "Total params: 23,929,672\n",
      "Trainable params: 23,895,234\n",
      "Non-trainable params: 34,438\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# warm up model\n",
    "# model = create_model(\n",
    "#     input_shape=(SIZE,SIZE,3), \n",
    "#     n_out=28)\n",
    "model.summary()\n",
    "\n",
    "for layer in model.layers:\n",
    "    layer.trainable = True\n",
    "model.layers[0].trainable = False\n",
    "model.layers[1].trainable = False\n",
    "model.layers[2].trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=[f1_loss], \n",
    "    optimizer=Adam(1e-03),\n",
    "    metrics=[f1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26411 4661\n"
     ]
    }
   ],
   "source": [
    "print(len(train_indexes), len(valid_indexes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "  62/1651 [>.............................] - ETA: 23:42 - loss: 1.1870 - f1: 0.0339"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-40ff253b20e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_indexes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     verbose=1)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/hpg/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hpg/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hpg/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m                 \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hpg/lib/python3.6/site-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    683\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hpg/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hpg/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hpg/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hpg/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size=16\n",
    "\n",
    "# create train and valid datagens\n",
    "train_generator = data_generator.create_train(\n",
    "    train_dataset_info[train_indexes], batch_size, (SIZE,SIZE,3), augument=True)\n",
    "validation_generator = data_generator.create_train(\n",
    "    train_dataset_info[valid_indexes], 32, (SIZE,SIZE,3), augument=False)\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=np.ceil(float(len(train_indexes)) / float(batch_size)),\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=np.ceil(float(len(valid_indexes)) / float(batch_size)),\n",
    "    epochs=2, \n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs=120\n",
    "\n",
    "# batch_size=8\n",
    "for layer in model.layers:\n",
    "    layer.trainable = True\n",
    "model.compile(loss=[f1_loss, 'mse'],\n",
    "              optimizer=Adam(lr=1e-4),\n",
    "              loss_weights = {\"output\": 1.0, \"img_out\": 10.0 }, \n",
    "              metrics=[f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "6603/6603 [==============================] - 2147s 325ms/step - loss: 1.3233 - output_loss: 1.0986 - img_out_loss: 0.0225 - output_f1: 0.0505 - img_out_f1: 0.0000e+00 - val_loss: 1.2780 - val_output_loss: 1.0541 - val_img_out_loss: 0.0224 - val_output_f1: 0.1139 - val_img_out_f1: 0.0000e+00\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.27798, saving model to ../cache/iv3-40.h5\n",
      "Epoch 2/120\n",
      "6603/6603 [==============================] - 2071s 314ms/step - loss: 1.2767 - output_loss: 1.0522 - img_out_loss: 0.0225 - output_f1: 0.0803 - img_out_f1: 0.0000e+00 - val_loss: 1.2467 - val_output_loss: 1.0228 - val_img_out_loss: 0.0224 - val_output_f1: 0.1378 - val_img_out_f1: 0.0000e+00\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.27798 to 1.24667, saving model to ../cache/iv3-40.h5\n",
      "Epoch 3/120\n",
      "6603/6603 [==============================] - 2029s 307ms/step - loss: 1.2553 - output_loss: 1.0307 - img_out_loss: 0.0225 - output_f1: 0.0934 - img_out_f1: 0.0000e+00 - val_loss: 1.2240 - val_output_loss: 1.0002 - val_img_out_loss: 0.0224 - val_output_f1: 0.1522 - val_img_out_f1: 0.0000e+00\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.24667 to 1.22401, saving model to ../cache/iv3-40.h5\n",
      "Epoch 4/120\n",
      "6603/6603 [==============================] - 1983s 300ms/step - loss: 1.2420 - output_loss: 1.0177 - img_out_loss: 0.0224 - output_f1: 0.1011 - img_out_f1: 0.0000e+00 - val_loss: 1.1955 - val_output_loss: 0.9717 - val_img_out_loss: 0.0224 - val_output_f1: 0.1612 - val_img_out_f1: 0.0000e+00\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.22401 to 1.19553, saving model to ../cache/iv3-40.h5\n",
      "Epoch 5/120\n",
      "6603/6603 [==============================] - 1988s 301ms/step - loss: 1.2341 - output_loss: 1.0098 - img_out_loss: 0.0224 - output_f1: 0.1051 - img_out_f1: 0.0000e+00 - val_loss: 1.1829 - val_output_loss: 0.9590 - val_img_out_loss: 0.0224 - val_output_f1: 0.1636 - val_img_out_f1: 0.0000e+00\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.19553 to 1.18289, saving model to ../cache/iv3-40.h5\n",
      "Epoch 6/120\n",
      "6603/6603 [==============================] - 1996s 302ms/step - loss: 1.2286 - output_loss: 1.0043 - img_out_loss: 0.0224 - output_f1: 0.1081 - img_out_f1: 0.0000e+00 - val_loss: 1.1935 - val_output_loss: 0.9696 - val_img_out_loss: 0.0224 - val_output_f1: 0.1655 - val_img_out_f1: 0.0000e+00\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.18289\n",
      "Epoch 7/120\n",
      "6603/6603 [==============================] - 1989s 301ms/step - loss: 1.2182 - output_loss: 0.9989 - img_out_loss: 0.0219 - output_f1: 0.1108 - img_out_f1: 0.0000e+00 - val_loss: 1.1851 - val_output_loss: 0.9819 - val_img_out_loss: 0.0203 - val_output_f1: 0.1621 - val_img_out_f1: 0.0000e+00\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.18289\n",
      "Epoch 8/120\n",
      "6603/6603 [==============================] - 1995s 302ms/step - loss: 1.1975 - output_loss: 0.9942 - img_out_loss: 0.0203 - output_f1: 0.1131 - img_out_f1: 0.0000e+00 - val_loss: 1.1464 - val_output_loss: 0.9433 - val_img_out_loss: 0.0203 - val_output_f1: 0.1755 - val_img_out_f1: 0.0000e+00\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.18289 to 1.14639, saving model to ../cache/iv3-40.h5\n",
      "Epoch 9/120\n",
      "6603/6603 [==============================] - 1991s 301ms/step - loss: 1.1934 - output_loss: 0.9903 - img_out_loss: 0.0203 - output_f1: 0.1155 - img_out_f1: 0.0000e+00 - val_loss: 1.1488 - val_output_loss: 0.9456 - val_img_out_loss: 0.0203 - val_output_f1: 0.1780 - val_img_out_f1: 0.0000e+00\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.14639\n",
      "Epoch 10/120\n",
      "6603/6603 [==============================] - 1983s 300ms/step - loss: 1.1898 - output_loss: 0.9867 - img_out_loss: 0.0203 - output_f1: 0.1173 - img_out_f1: 0.0000e+00 - val_loss: 1.1449 - val_output_loss: 0.9418 - val_img_out_loss: 0.0203 - val_output_f1: 0.1748 - val_img_out_f1: 0.0000e+00\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.14639 to 1.14492, saving model to ../cache/iv3-40.h5\n",
      "Epoch 11/120\n",
      "6603/6603 [==============================] - 1979s 300ms/step - loss: 1.1864 - output_loss: 0.9834 - img_out_loss: 0.0203 - output_f1: 0.1186 - img_out_f1: 0.0000e+00 - val_loss: 1.1498 - val_output_loss: 0.9467 - val_img_out_loss: 0.0203 - val_output_f1: 0.1738 - val_img_out_f1: 0.0000e+00\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.14492\n",
      "Epoch 12/120\n",
      "6603/6603 [==============================] - 1987s 301ms/step - loss: 1.1853 - output_loss: 0.9819 - img_out_loss: 0.0203 - output_f1: 0.1196 - img_out_f1: 0.0000e+00 - val_loss: 1.1662 - val_output_loss: 0.9631 - val_img_out_loss: 0.0203 - val_output_f1: 0.1756 - val_img_out_f1: 0.0000e+00\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.14492\n",
      "Epoch 13/120\n",
      "6603/6603 [==============================] - 1982s 300ms/step - loss: 1.1812 - output_loss: 0.9779 - img_out_loss: 0.0203 - output_f1: 0.1212 - img_out_f1: 0.0000e+00 - val_loss: 1.1467 - val_output_loss: 0.9436 - val_img_out_loss: 0.0203 - val_output_f1: 0.1841 - val_img_out_f1: 0.0000e+00\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.14492\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "Epoch 14/120\n",
      "6603/6603 [==============================] - 1984s 300ms/step - loss: 1.1675 - output_loss: 0.9642 - img_out_loss: 0.0203 - output_f1: 0.1279 - img_out_f1: 0.0000e+00 - val_loss: 1.1279 - val_output_loss: 0.9248 - val_img_out_loss: 0.0203 - val_output_f1: 0.1889 - val_img_out_f1: 0.0000e+00\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.14492 to 1.12788, saving model to ../cache/iv3-40.h5\n",
      "Epoch 15/120\n",
      "6603/6603 [==============================] - 1974s 299ms/step - loss: 1.1631 - output_loss: 0.9599 - img_out_loss: 0.0203 - output_f1: 0.1289 - img_out_f1: 0.0000e+00 - val_loss: 1.1269 - val_output_loss: 0.9237 - val_img_out_loss: 0.0203 - val_output_f1: 0.1857 - val_img_out_f1: 0.0000e+00\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.12788 to 1.12685, saving model to ../cache/iv3-40.h5\n",
      "Epoch 16/120\n",
      "6603/6603 [==============================] - 1979s 300ms/step - loss: 1.1616 - output_loss: 0.9583 - img_out_loss: 0.0203 - output_f1: 0.1293 - img_out_f1: 0.0000e+00 - val_loss: 1.1231 - val_output_loss: 0.9199 - val_img_out_loss: 0.0203 - val_output_f1: 0.1909 - val_img_out_f1: 0.0000e+00\n",
      "\n",
      "Epoch 00016: val_loss improved from 1.12685 to 1.12306, saving model to ../cache/iv3-40.h5\n",
      "Epoch 17/120\n",
      "6603/6603 [==============================] - 1986s 301ms/step - loss: 1.1597 - output_loss: 0.9564 - img_out_loss: 0.0203 - output_f1: 0.1299 - img_out_f1: 0.0000e+00 - val_loss: 1.1274 - val_output_loss: 0.9243 - val_img_out_loss: 0.0203 - val_output_f1: 0.1897 - val_img_out_f1: 0.0000e+00\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.12306\n",
      "Epoch 18/120\n",
      "6603/6603 [==============================] - 1985s 301ms/step - loss: 1.1593 - output_loss: 0.9560 - img_out_loss: 0.0203 - output_f1: 0.1302 - img_out_f1: 0.0000e+00 - val_loss: 1.1258 - val_output_loss: 0.9227 - val_img_out_loss: 0.0203 - val_output_f1: 0.1887 - val_img_out_f1: 0.0000e+00\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.12306\n",
      "Epoch 19/120\n",
      "6603/6603 [==============================] - 1985s 301ms/step - loss: 1.1564 - output_loss: 0.9535 - img_out_loss: 0.0203 - output_f1: 0.1317 - img_out_f1: 0.0000e+00 - val_loss: 1.1262 - val_output_loss: 0.9231 - val_img_out_loss: 0.0203 - val_output_f1: 0.1907 - val_img_out_f1: 0.0000e+00\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.12306\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "Epoch 20/120\n",
      "6603/6603 [==============================] - 1984s 301ms/step - loss: 1.1551 - output_loss: 0.9518 - img_out_loss: 0.0203 - output_f1: 0.1324 - img_out_f1: 0.0000e+00 - val_loss: 1.1217 - val_output_loss: 0.9185 - val_img_out_loss: 0.0203 - val_output_f1: 0.1902 - val_img_out_f1: 0.0000e+00\n",
      "\n",
      "Epoch 00020: val_loss improved from 1.12306 to 1.12165, saving model to ../cache/iv3-40.h5\n",
      "Epoch 21/120\n",
      "6603/6603 [==============================] - 1983s 300ms/step - loss: 1.1562 - output_loss: 0.9529 - img_out_loss: 0.0203 - output_f1: 0.1317 - img_out_f1: 0.0000e+00 - val_loss: 1.1229 - val_output_loss: 0.9198 - val_img_out_loss: 0.0203 - val_output_f1: 0.1912 - val_img_out_f1: 0.0000e+00\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.12165\n",
      "Epoch 22/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6603/6603 [==============================] - 1985s 301ms/step - loss: 1.1547 - output_loss: 0.9514 - img_out_loss: 0.0203 - output_f1: 0.1323 - img_out_f1: 0.0000e+00 - val_loss: 1.1204 - val_output_loss: 0.9172 - val_img_out_loss: 0.0203 - val_output_f1: 0.1910 - val_img_out_f1: 0.0000e+00\n",
      "\n",
      "Epoch 00022: val_loss improved from 1.12165 to 1.12037, saving model to ../cache/iv3-40.h5\n",
      "Epoch 23/120\n",
      "6603/6603 [==============================] - 1978s 300ms/step - loss: 1.1545 - output_loss: 0.9512 - img_out_loss: 0.0203 - output_f1: 0.1324 - img_out_f1: 0.0000e+00 - val_loss: 1.1223 - val_output_loss: 0.9191 - val_img_out_loss: 0.0203 - val_output_f1: 0.1912 - val_img_out_f1: 0.0000e+00\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.12037\n",
      "Epoch 24/120\n",
      "6603/6603 [==============================] - 1984s 301ms/step - loss: 1.1545 - output_loss: 0.9511 - img_out_loss: 0.0203 - output_f1: 0.1321 - img_out_f1: 0.0000e+00 - val_loss: 1.1221 - val_output_loss: 0.9190 - val_img_out_loss: 0.0203 - val_output_f1: 0.1907 - val_img_out_f1: 0.0000e+00\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.12037\n",
      "Epoch 25/120\n",
      "6603/6603 [==============================] - 1982s 300ms/step - loss: 1.1539 - output_loss: 0.9506 - img_out_loss: 0.0203 - output_f1: 0.1328 - img_out_f1: 0.0000e+00 - val_loss: 1.1208 - val_output_loss: 0.9177 - val_img_out_loss: 0.0203 - val_output_f1: 0.1919 - val_img_out_f1: 0.0000e+00\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.12037\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
      "Epoch 26/120\n",
      "6603/6603 [==============================] - 1974s 299ms/step - loss: 1.1537 - output_loss: 0.9505 - img_out_loss: 0.0203 - output_f1: 0.1328 - img_out_f1: 0.0000e+00 - val_loss: 1.1221 - val_output_loss: 0.9189 - val_img_out_loss: 0.0203 - val_output_f1: 0.1914 - val_img_out_f1: 0.0000e+00\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1.12037\n",
      "Epoch 27/120\n",
      "6603/6603 [==============================] - 1982s 300ms/step - loss: 1.1540 - output_loss: 0.9511 - img_out_loss: 0.0203 - output_f1: 0.1330 - img_out_f1: 0.0000e+00 - val_loss: 1.1208 - val_output_loss: 0.9177 - val_img_out_loss: 0.0203 - val_output_f1: 0.1924 - val_img_out_f1: 0.0000e+00\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1.12037\n",
      "Epoch 28/120\n",
      "6603/6603 [==============================] - 1980s 300ms/step - loss: 1.1539 - output_loss: 0.9509 - img_out_loss: 0.0203 - output_f1: 0.1322 - img_out_f1: 0.0000e+00 - val_loss: 1.1222 - val_output_loss: 0.9191 - val_img_out_loss: 0.0203 - val_output_f1: 0.1910 - val_img_out_f1: 0.0000e+00\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1.12037\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 1.0000000116860975e-08.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f18cac6feb8>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train all layers\n",
    "batch_size=4\n",
    "\n",
    "train_generator = data_generator.create_train(\n",
    "    train_dataset_info[train_indexes], batch_size, (SIZE,SIZE,3), augument=True)\n",
    "validation_generator = data_generator.create_train(\n",
    "    train_dataset_info[valid_indexes], 8, (SIZE,SIZE,3), augument=False)\n",
    "# model.load_weights('../cache/iv3-38.h5')\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=np.ceil(float(len(train_indexes)) / float(batch_size)),\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=np.ceil(float(len(valid_indexes)) / float(batch_size)),\n",
    "    epochs=epochs, \n",
    "    verbose=1,\n",
    "    callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for ii in tqdm(np.arange(len(train_dataset_info))):\n",
    "#     img1 = cv2.imread(train_dataset_info[ii]['path']+'_red.png', cv2.IMREAD_GRAYSCALE)\n",
    "#     img2 = cv2.imread(train_dataset_info[ii]['path']+'_green.png', cv2.IMREAD_GRAYSCALE)\n",
    "#     img3 = cv2.imread(train_dataset_info[ii]['path']+'_blue.png', cv2.IMREAD_GRAYSCALE)\n",
    "#     img1 = np.stack((img1, img2, img3), -1)\n",
    "#     name = '../cache/RGB/img-{}.png'.format(ii)\n",
    "#     cv2.imwrite(name,img1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# submit = pd.read_csv('../data/sample_submission.csv')\n",
    "# for name in tqdm(submit['Id']):\n",
    "#     path = os.path.join('../data/test/', name)\n",
    "#     img1 = cv2.imread(path+'_red.png', cv2.IMREAD_GRAYSCALE)\n",
    "#     img2 = cv2.imread(path+'_green.png', cv2.IMREAD_GRAYSCALE)\n",
    "#     img3 = cv2.imread(path+'_blue.png', cv2.IMREAD_GRAYSCALE)\n",
    "#     img1 = np.stack((img1, img2, img3), -1)\n",
    "#     name1 = '../cache/RGB/test/img-{}.png'.format(name)\n",
    "#     cv2.imwrite(name1,img1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11702/11702 [12:08<00:00, 16.06it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create submit\n",
    "submit = pd.read_csv('../data/sample_submission.csv')\n",
    "predicted = []\n",
    "draw_predict = []\n",
    "# model = create_model(\n",
    "#     input_shape=(SIZE,SIZE,3), \n",
    "#     n_out=28)\n",
    "# for layer in model.layers:\n",
    "#     layer.trainable = True\n",
    "# model.compile(loss=f1_loss,\n",
    "#             optimizer=Adam(lr=1e-4),\n",
    "#             metrics=[f1])\n",
    "model.load_weights('../cache/iv3-40.h5')\n",
    "for name in tqdm(submit['Id']):\n",
    "    path = os.path.join('../data/test/', name)\n",
    "    image = data_generator.load_image(path, (SIZE,SIZE,3))/255.\n",
    "    score_predict = model.predict(image[np.newaxis])[0]\n",
    "    draw_predict.append(score_predict)\n",
    "    label_predict = np.arange(28)[score_predict[0]>=0.2]\n",
    "    str_predict_label = ' '.join(str(l) for l in label_predict)\n",
    "    predicted.append(str_predict_label)\n",
    "\n",
    "submit['Predicted'] = predicted\n",
    "# np.save('../cache/draw_predict_InceptionV3-8.npy', score_predict)\n",
    "# submit.to_csv('../submissions/submit_InceptionV3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submit.to_csv('../submissions/sub40-a.csv', index=False)\n",
    "\n",
    "# sub40-a.csv      2018-11-29 14:06:01               complete  0.419        None          \n",
    "# sub38-a.csv      2018-11-29 02:08:54               complete  0.356        None          \n",
    "# sub39-c.csv      2018-11-29 02:08:16               complete  0.475        None          \n",
    "# sub39-d.csv      2018-11-28 18:32:15               complete  0.473        None          \n",
    "# sub39-f.csv      2018-11-28 18:31:26               complete  0.471        None          \n",
    "# sub39-a.csv      2018-11-28 18:25:37               complete  0.467        None          \n",
    "# sub37-max-a.csv  2018-11-28 11:16:37               complete  0.135        None          \n",
    "# sub37-max.csv    2018-11-28 11:04:09               complete  0.135        None          \n",
    "# sub35-max-d.csv  2018-11-27 09:55:56               complete  0.472        None          \n",
    "# sub35-max-c.csv  2018-11-27 09:47:12               complete  0.458        None          \n",
    "# sub35-max-b.csv  2018-11-27 09:45:48               complete  0.456        None          \n",
    "# sub35-max-a.csv  2018-11-27 09:45:10               complete  0.456        None          \n",
    "# sub36-max.csv    2018-11-27 06:40:12               complete  0.469        None          \n",
    "# sub37-c.csv      2018-11-26 21:04:50               complete  0.437        None          \n",
    "# sub37-b.csv      2018-11-26 21:04:21               complete  0.457        None          \n",
    "# sub37-a.csv      2018-11-26 21:03:26               complete  0.464        None          \n",
    "# sub35-max.csv    2018-11-26 00:58:38               complete  0.473        None          \n",
    "# sub34b-max.csv   2018-11-24 19:03:59               complete  0.459        None          \n",
    "# sub34a-max.csv   2018-11-24 18:50:22               complete  0.469        None          \n",
    "# sub34-max.csv    2018-11-24 17:27:36               complete  0.473        None          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11702/11702 [00:00<00:00, 48046.21it/s]\n"
     ]
    }
   ],
   "source": [
    "predicted = []\n",
    "for score_predict in tqdm(draw_predict):\n",
    "    \n",
    "    label_predict = np.arange(28)[score_predict[0]>=0.25]\n",
    "    str_predict_label = ' '.join(str(l) for l in label_predict)\n",
    "    predicted.append(str_predict_label)\n",
    "submit['Predicted'] = predicted\n",
    "submit.to_csv('../submissions/sub38-b.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11702/11702 [00:00<00:00, 50626.20it/s]\n"
     ]
    }
   ],
   "source": [
    "predicted = []\n",
    "for score_predict in tqdm(draw_predict):\n",
    "    \n",
    "    label_predict = np.arange(28)[score_predict[0]>=0.5]\n",
    "    str_predict_label = ' '.join(str(l) for l in label_predict)\n",
    "    predicted.append(str_predict_label)\n",
    "submit['Predicted'] = predicted\n",
    "submit.to_csv('../submissions/sub38-c.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11702/11702 [00:00<00:00, 49779.15it/s]\n"
     ]
    }
   ],
   "source": [
    "predicted = []\n",
    "for score_predict in tqdm(draw_predict):\n",
    "    \n",
    "    label_predict = np.arange(28)[score_predict[0]>=0.45]\n",
    "    str_predict_label = ' '.join(str(l) for l in label_predict)\n",
    "    predicted.append(str_predict_label)\n",
    "submit['Predicted'] = predicted\n",
    "submit.to_csv('../submissions/sub38-d.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11702/11702 [00:00<00:00, 43551.10it/s]\n"
     ]
    }
   ],
   "source": [
    "predicted = []\n",
    "for score_predict in tqdm(draw_predict):\n",
    "    \n",
    "    label_predict = np.arange(28)[score_predict[0]>=0.4]\n",
    "    str_predict_label = ' '.join(str(l) for l in label_predict)\n",
    "    predicted.append(str_predict_label)\n",
    "submit['Predicted'] = predicted\n",
    "submit.to_csv('../submissions/sub38-e.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11702/11702 [00:00<00:00, 48735.09it/s]\n"
     ]
    }
   ],
   "source": [
    "predicted = []\n",
    "for score_predict in tqdm(draw_predict):\n",
    "    \n",
    "    label_predict = np.arange(28)[score_predict[0]>=0.35]\n",
    "    str_predict_label = ' '.join(str(l) for l in label_predict)\n",
    "    predicted.append(str_predict_label)\n",
    "submit['Predicted'] = predicted\n",
    "submit.to_csv('../submissions/sub38-f.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/1855095/how-to-create-a-zip-archive-of-a-directory\n",
    "def backup_project_as_zip(project_dir, zip_file):\n",
    "    assert(os.path.isdir(project_dir))\n",
    "    assert(os.path.isdir(os.path.dirname(zip_file)))\n",
    "    shutil.make_archive(zip_file.replace('.zip',''), 'zip', project_dir)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-11-19 12:33:39.384598\n"
     ]
    }
   ],
   "source": [
    "import datetime, shutil\n",
    "now = datetime.datetime.now()\n",
    "print(now)\n",
    "PROJECT_PATH = '/home/watts/lal/Kaggle/kagglehp/scripts_nbs'\n",
    "backup_project_as_zip(PROJECT_PATH, '../cache/code.scripts_nbs.%s.zip'%now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 480k/480k [00:08<00:00, 51.3kB/s]\n",
      "Successfully submitted to Human Protein Atlas Image ClassificationCPU times: user 332 ms, sys: 134 ms, total: 467 ms\n",
      "Wall time: 15.6 s\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# !kaggle competitions submit -c human-protein-atlas-image-classification -f ../submissions/sub8i1.csv -m \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileName      date                 description  status    publicScore  privateScore  \r\n",
      "------------  -------------------  -----------  --------  -----------  ------------  \r\n",
      "sub8i.csv     2018-11-14 04:28:35               complete  0.443        None          \r\n",
      "sub8h.csv     2018-11-13 23:48:00               complete  0.434        None          \r\n",
      "sub8g.csv     2018-11-13 07:17:59               complete  0.389        None          \r\n",
      "sub8c.csv     2018-11-11 14:31:02               complete  0.429        None          \r\n",
      "sub30.csv     2018-11-09 07:02:56               complete  0.033        None          \r\n",
      "sub29.csv     2018-11-08 22:07:11               complete  0.389        None          \r\n",
      "sub28-c.csv   2018-11-08 15:47:08               complete  0.457        None          \r\n",
      "sub28-bb.csv  2018-11-08 15:46:13               complete  0.458        None          \r\n",
      "sub28-b.csv   2018-11-08 15:45:28               complete  0.454        None          \r\n",
      "sub28-a.csv   2018-11-08 15:44:27               complete  0.454        None          \r\n",
      "sub25.csv     2018-11-07 10:45:12               complete  0.421        None          \r\n",
      "sub25.csv     2018-11-07 10:26:20               complete  0.421        None          \r\n",
      "sub8a.csv     2018-11-07 05:53:08               complete  0.425        None          \r\n",
      "sub24.csv     2018-11-07 05:09:26               complete  0.410        None          \r\n",
      "sub23-d.csv   2018-11-07 00:21:06               complete  0.469        None          \r\n",
      "sub23-c.csv   2018-11-06 14:34:37               complete  0.472        None          \r\n",
      "sub23-bb.csv  2018-11-06 14:33:35               complete  0.466        None          \r\n",
      "sub23-b.csv   2018-11-06 14:32:47               complete  0.463        None          \r\n",
      "sub23-a.csv   2018-11-06 14:31:57               complete  0.461        None          \r\n",
      "sub22-a.csv   2018-11-06 14:30:53               complete  0.467        None          \r\n"
     ]
    }
   ],
   "source": [
    "# from time import sleep\n",
    "# sleep(60)\n",
    "# !kaggle competitions submissions -c human-protein-atlas-image-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.4.7.1 / client 1.3.8)\r\n",
      "fileName  date                 description  status    publicScore  privateScore  \r\n",
      "--------  -------------------  -----------  --------  -----------  ------------  \r\n",
      "sub8.csv  2018-10-20 20:08:45               complete  0.422        None          \r\n",
      "sub7.csv  2018-10-20 17:06:09               complete  0.389        None          \r\n",
      "sub5.csv  2018-10-19 18:27:33               complete  0.387        None          \r\n",
      "sub4.csv  2018-10-19 14:45:15               complete  0.411        None          \r\n",
      "sub3.csv  2018-10-19 10:19:26               complete  0.377        None          \r\n",
      "sub2.csv  2018-10-19 08:07:30               complete  0.135        None          \r\n",
      "sub1.csv  2018-10-19 06:28:57               complete  0.374        None          \r\n"
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "sleep(60)\n",
    "!kaggle competitions submissions -c human-protein-atlas-image-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hpg",
   "language": "python",
   "name": "hpg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
