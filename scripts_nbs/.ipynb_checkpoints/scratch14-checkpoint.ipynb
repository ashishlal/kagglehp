{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/mathormad/inceptionv3-baseline-lb-0-379/code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install iterative-stratification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.io\n",
    "from skimage.transform import resize\n",
    "from imgaug import augmenters as iaa\n",
    "from tqdm import tqdm\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from sklearn.utils import class_weight, shuffle\n",
    "from sklearn.model_selection import KFold\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold, MultilabelStratifiedShuffleSplit\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "SIZE = 299"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/rejpalcz/best-loss-function-for-f1-score-metric/notebook\n",
    "import tensorflow as tf\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    y_pred = K.round(y_pred)\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n",
    "\n",
    "def f1_loss(y_true, y_pred):\n",
    "    \n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(K.binary_crossentropy(y_true, y_pred), axis=-1) + (1 - K.mean(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset info\n",
    "path_to_train = '../data/train/'\n",
    "data = pd.read_csv('../data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00070df0-bbc3-11e8-b2bc-ac1f6b6435d0</td>\n",
       "      <td>16 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000a6c98-bb9b-11e8-b2b9-ac1f6b6435d0</td>\n",
       "      <td>7 1 2 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000a9596-bbc4-11e8-b2bc-ac1f6b6435d0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000c99ba-bba4-11e8-b2b9-ac1f6b6435d0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001838f8-bbca-11e8-b2bc-ac1f6b6435d0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Id   Target\n",
       "0  00070df0-bbc3-11e8-b2bc-ac1f6b6435d0     16 0\n",
       "1  000a6c98-bb9b-11e8-b2b9-ac1f6b6435d0  7 1 2 0\n",
       "2  000a9596-bbc4-11e8-b2bc-ac1f6b6435d0        5\n",
       "3  000c99ba-bba4-11e8-b2b9-ac1f6b6435d0        1\n",
       "4  001838f8-bbca-11e8-b2bc-ac1f6b6435d0       18"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_info = []\n",
    "for name, labels in zip(data['Id'], data['Target'].str.split(' ')):\n",
    "    train_dataset_info.append({\n",
    "        'path':os.path.join(path_to_train, name),\n",
    "        'labels':np.array([int(label) for label in labels])})\n",
    "train_dataset_info = np.array(train_dataset_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([{'path': '../data/train/00070df0-bbc3-11e8-b2bc-ac1f6b6435d0', 'labels': array([16,  0])},\n",
       "       {'path': '../data/train/000a6c98-bb9b-11e8-b2b9-ac1f6b6435d0', 'labels': array([7, 1, 2, 0])},\n",
       "       {'path': '../data/train/000a9596-bbc4-11e8-b2bc-ac1f6b6435d0', 'labels': array([5])},\n",
       "       ...,\n",
       "       {'path': '../data/train/fff189d8-bbab-11e8-b2ba-ac1f6b6435d0', 'labels': array([7])},\n",
       "       {'path': '../data/train/fffdf7e0-bbc4-11e8-b2bc-ac1f6b6435d0', 'labels': array([25,  2, 21])},\n",
       "       {'path': '../data/train/fffe0ffe-bbc0-11e8-b2bb-ac1f6b6435d0', 'labels': array([2, 0])}],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class data_generator:\n",
    "    \n",
    "    def create_train(dataset_info, batch_size, shape, augument=True):\n",
    "        assert shape[2] == 3\n",
    "        while True:\n",
    "            dataset_info = shuffle(dataset_info)\n",
    "            for start in range(0, len(dataset_info), batch_size):\n",
    "                end = min(start + batch_size, len(dataset_info))\n",
    "                batch_images = []\n",
    "                X_train_batch = dataset_info[start:end]\n",
    "                batch_labels = np.zeros((len(X_train_batch), 28))\n",
    "                for i in range(len(X_train_batch)):\n",
    "                    image = data_generator.load_image(\n",
    "                        X_train_batch[i]['path'], shape)   \n",
    "                    if augument:\n",
    "                        image = data_generator.augment(image)\n",
    "                    batch_images.append(image/255.)\n",
    "                    batch_labels[i][X_train_batch[i]['labels']] = 1\n",
    "                yield np.array(batch_images, np.float32), batch_labels\n",
    "\n",
    "    def load_image(path, shape):\n",
    "        image_red_ch = Image.open(path+'_red.png')\n",
    "        image_yellow_ch = Image.open(path+'_yellow.png')\n",
    "        image_green_ch = Image.open(path+'_green.png')\n",
    "        image_blue_ch = Image.open(path+'_blue.png')\n",
    "        image = np.stack((\n",
    "            np.array(image_red_ch),\n",
    "            np.array(image_green_ch), \n",
    "            np.array(image_blue_ch)), -1)\n",
    "        w, h = 512, 512\n",
    "        zero_data = np.zeros((h, w), dtype=np.uint8)\n",
    "#         image2 = np.stack((\n",
    "#             np.array(image_yellow_ch),\n",
    "#             zero_data, zero_data), -1)\n",
    "#         print(image1.shape, image2.shape)\n",
    "#         image = np.vstack((image1, image2))\n",
    "        image = cv2.resize(image, (shape[0], shape[1]))\n",
    "        return image\n",
    "\n",
    "    def augment(image):\n",
    "        augment_img = iaa.Sequential([\n",
    "            iaa.OneOf([\n",
    "                iaa.Affine(rotate=0),\n",
    "                iaa.Affine(rotate=90),\n",
    "                iaa.Affine(rotate=180),\n",
    "                iaa.Affine(rotate=270),\n",
    "                iaa.Fliplr(0.5),\n",
    "                iaa.Flipud(0.5),\n",
    "            ])], random_order=True)\n",
    "\n",
    "        image_aug = augment_img.augment_image(image)\n",
    "        return image_aug\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, GlobalMaxPooling2D, BatchNormalization, Input, Conv2D\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import metrics\n",
    "from keras.optimizers import Adam \n",
    "from keras import backend as K\n",
    "import keras\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape, n_out):\n",
    "    input_tensor = Input(shape=input_shape)\n",
    "    base_model = InceptionV3(include_top=False,\n",
    "                   weights='imagenet',\n",
    "                   input_shape=input_shape)\n",
    "    bn = BatchNormalization()(input_tensor)\n",
    "    x = base_model(bn)\n",
    "    x = Conv2D(32, kernel_size=(1,1), activation='relu')(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(n_out, activation='sigmoid')(x)\n",
    "    model = Model(input_tensor, output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.ops import array_ops\n",
    "\n",
    "# https://github.com/ailias/Focal-Loss-implement-on-Tensorflow/blob/master/focal_loss.py\n",
    "def focal_loss_org(prediction_tensor, target_tensor, weights=None, alpha=0.25, gamma=2):\n",
    "    r\"\"\"Compute focal loss for predictions.\n",
    "        Multi-labels Focal loss formula:\n",
    "            FL = -alpha * (z-p)^gamma * log(p) -(1-alpha) * p^gamma * log(1-p)\n",
    "                 ,which alpha = 0.25, gamma = 2, p = sigmoid(x), z = target_tensor.\n",
    "    Args:\n",
    "     prediction_tensor: A float tensor of shape [batch_size, num_anchors,\n",
    "        num_classes] representing the predicted logits for each class\n",
    "     target_tensor: A float tensor of shape [batch_size, num_anchors,\n",
    "        num_classes] representing one-hot encoded classification targets\n",
    "     weights: A float tensor of shape [batch_size, num_anchors]\n",
    "     alpha: A scalar tensor for focal loss alpha hyper-parameter\n",
    "     gamma: A scalar tensor for focal loss gamma hyper-parameter\n",
    "    Returns:\n",
    "        loss: A (scalar) tensor representing the value of the loss function\n",
    "    \"\"\"\n",
    "    sigmoid_p = tf.nn.sigmoid(prediction_tensor)\n",
    "    zeros = array_ops.zeros_like(sigmoid_p, dtype=sigmoid_p.dtype)\n",
    "    \n",
    "    # For poitive prediction, only need consider front part loss, back part is 0;\n",
    "    # target_tensor > zeros <=> z=1, so poitive coefficient = z - p.\n",
    "    pos_p_sub = array_ops.where(target_tensor > zeros, target_tensor - sigmoid_p, zeros)\n",
    "    \n",
    "    # For negative prediction, only need consider back part loss, front part is 0;\n",
    "    # target_tensor > zeros <=> z=1, so negative coefficient = 0.\n",
    "    neg_p_sub = array_ops.where(target_tensor > zeros, zeros, sigmoid_p)\n",
    "    per_entry_cross_ent = - alpha * (pos_p_sub ** gamma) * tf.log(tf.clip_by_value(sigmoid_p, 1e-8, 1.0)) \\\n",
    "                          - (1 - alpha) * (neg_p_sub ** gamma) * tf.log(tf.clip_by_value(1.0 - sigmoid_p, 1e-8, 1.0))\n",
    "    return tf.reduce_sum(per_entry_cross_ent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def focal_loss(weights=None, alpha=0.25, gamma=2):\n",
    "    def focal_loss_my(target_tensor, prediction_tensor, ):\n",
    "        r\"\"\"Compute focal loss for predictions.\n",
    "            Multi-labels Focal loss formula:\n",
    "                FL = -alpha * (z-p)^gamma * log(p) -(1-alpha) * p^gamma * log(1-p)\n",
    "                     ,which alpha = 0.25, gamma = 2, p = sigmoid(x), z = target_tensor.\n",
    "        Args:\n",
    "         prediction_tensor: A float tensor of shape [batch_size, num_anchors,\n",
    "            num_classes] representing the predicted logits for each class\n",
    "         target_tensor: A float tensor of shape [batch_size, num_anchors,\n",
    "            num_classes] representing one-hot encoded classification targets\n",
    "         weights: A float tensor of shape [batch_size, num_anchors]\n",
    "         alpha: A scalar tensor for focal loss alpha hyper-parameter\n",
    "         gamma: A scalar tensor for focal loss gamma hyper-parameter\n",
    "        Returns:\n",
    "            loss: A (scalar) tensor representing the value of the loss function\n",
    "        \"\"\"\n",
    "        sigmoid_p = tf.nn.sigmoid(prediction_tensor)\n",
    "        zeros = array_ops.zeros_like(sigmoid_p, dtype=sigmoid_p.dtype)\n",
    "\n",
    "        # For poitive prediction, only need consider front part loss, back part is 0;\n",
    "        # target_tensor > zeros <=> z=1, so poitive coefficient = z - p.\n",
    "        pos_p_sub = array_ops.where(target_tensor > zeros, target_tensor - sigmoid_p, zeros)\n",
    "\n",
    "        # For negative prediction, only need consider back part loss, front part is 0;\n",
    "        # target_tensor > zeros <=> z=1, so negative coefficient = 0.\n",
    "        neg_p_sub = array_ops.where(target_tensor > zeros, zeros, sigmoid_p)\n",
    "        per_entry_cross_ent = - alpha * (pos_p_sub ** gamma) * tf.log(tf.clip_by_value(sigmoid_p, 1e-8, 1.0)) \\\n",
    "                              - (1 - alpha) * (neg_p_sub ** gamma) * tf.log(tf.clip_by_value(1.0 - sigmoid_p, 1e-8, 1.0))\n",
    "        return tf.reduce_sum(per_entry_cross_ent)\n",
    "#         return K.mean(K.binary_crossentropy(target_tensor, prediction_tensor), axis=-1) + tf.reduce_sum(per_entry_cross_ent)\n",
    "    return focal_loss_my"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def focal_loss_fixed(y_true, y_pred):\n",
    "    gamma = 2.\n",
    "    alpha = 0.25\n",
    "    print(y_pred)\n",
    "    print(y_true)\n",
    "    pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
    "    pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
    "\n",
    "#     pt_1 = K.clip(pt_1, 1e-3, .999)\n",
    "#     pt_0 = K.clip(pt_0, 1e-3, .999)\n",
    "\n",
    "    return -K.sum(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1))-K.sum((1-alpha) * K.pow( pt_0, gamma) * K.log(1. - pt_0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def focal_loss(gamma=2., alpha=.25):\n",
    "#     def focal_loss_fixed(y_true, y_pred):\n",
    "#         pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
    "#         pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
    "\n",
    "#         pt_1 = K.clip(pt_1, 1e-3, .999)\n",
    "#         pt_0 = K.clip(pt_0, 1e-3, .999)\n",
    "\n",
    "#         return -K.sum(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1))-K.sum((1-alpha) * K.pow( pt_0, gamma) * K.log(1. - pt_0))\n",
    "#     return focal_loss_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create callbacks list\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31072,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_info.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31072/31072 [00:00<00:00, 625442.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31072, 28)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_classes = 28\n",
    "y_train = np.zeros((train_dataset_info.shape[0], n_classes))\n",
    "print(y_train.shape)\n",
    "\n",
    "idx = 0\n",
    "for labels in tqdm(data['Target'].str.split(' ')):\n",
    "#     print(labels)\n",
    "    for label in labels:\n",
    "        y_train[idx][int(label)] = 1\n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27958 3114\n",
      "27973 3099\n",
      "27969 3103\n",
      "27995 3077\n",
      "27928 3144\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# split data into train, valid\n",
    "indexes = np.arange(train_dataset_info.shape[0])\n",
    "# np.random.shuffle(indexes)\n",
    "# train_indexes, valid_indexes = train_test_split(indexes, test_size=0.15, random_state=8)\n",
    "n_splits = 5\n",
    "# kf = KFold(n_splits=n_splits, random_state=42, shuffle=True)\n",
    "kf = MultilabelStratifiedShuffleSplit(n_splits=5, random_state=42)\n",
    "submit = pd.read_csv('../data/sample_submission.csv')\n",
    "\n",
    "# train_generator = data_generator.create_train(\n",
    "#     train_dataset_info[train_indexes], batch_size, (SIZE,SIZE,3), augument=True)\n",
    "# validation_generator = data_generator.create_train(\n",
    "#     train_dataset_info[valid_indexes], 32, (SIZE,SIZE,3), augument=False)\n",
    "\n",
    "oof_class_preds = np.zeros((train_dataset_info.shape[0], 28))\n",
    "sub_class_preds = np.zeros((submit.shape[0], 28))\n",
    "\n",
    "oof_class_preds = np.load('../cache/oof_class_preds-14.npy')\n",
    "sub_class_preds = np.load('../cache/sub_class_preds-14.npy')\n",
    "                          \n",
    "fold_ = 0\n",
    "epochs = 10; batch_size = 16\n",
    "my_fold = 0\n",
    "for train_indexes, valid_indexes in kf.split(indexes, y_train):\n",
    "    print(len(train_indexes), len(valid_indexes))\n",
    "    if my_fold < 2:\n",
    "        my_fold += 1\n",
    "        continue\n",
    "    checkpoint = ModelCheckpoint('../cache/InceptionV3.h5', monitor='val_loss', verbose=1, \n",
    "                                 save_best_only=True, mode='min', save_weights_only = True)\n",
    "    reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, \n",
    "                                       verbose=1, mode='auto', epsilon=0.0001)\n",
    "    early = EarlyStopping(monitor=\"val_loss\", \n",
    "                          mode=\"min\", \n",
    "                          patience=6)\n",
    "    callbacks_list = [checkpoint, early, reduceLROnPlat]\n",
    "\n",
    "\n",
    "    _preds = []\n",
    "    # create train and valid datagens\n",
    "    train_generator = data_generator.create_train(\n",
    "        train_dataset_info[train_indexes], batch_size, (SIZE,SIZE,3), augument=True)\n",
    "    validation_generator = data_generator.create_train(\n",
    "        train_dataset_info[valid_indexes], 32, (SIZE,SIZE,3), augument=False)\n",
    "\n",
    "    # warm up model\n",
    "    model = create_model(\n",
    "        input_shape=(SIZE,SIZE,3), \n",
    "        n_out=28)\n",
    "\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False\n",
    "    model.layers[-1].trainable = True\n",
    "    model.layers[-2].trainable = True\n",
    "    model.layers[-3].trainable = True\n",
    "    model.layers[-4].trainable = True\n",
    "    model.layers[-5].trainable = True\n",
    "    model.layers[-6].trainable = True\n",
    "    \n",
    "    model.compile(\n",
    "        loss=f1_loss, \n",
    "        optimizer=Adam(1e-03),\n",
    "        metrics=[f1])\n",
    "#     model.summary()\n",
    "\n",
    "    model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=np.ceil(float(len(train_indexes)) / float(batch_size)),\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=np.ceil(float(len(valid_indexes)) / float(batch_size)),\n",
    "        epochs=2, \n",
    "        verbose=1)\n",
    "    \n",
    "    # train all layers\n",
    "    epochs=120\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = True\n",
    "    model.compile(loss=f1_loss,\n",
    "                optimizer=Adam(lr=1e-4),\n",
    "                metrics=[f1])\n",
    "    model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=np.ceil(float(len(train_indexes)) / float(batch_size)),\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=np.ceil(float(len(valid_indexes)) / float(batch_size)),\n",
    "        epochs=epochs, \n",
    "        verbose=1,\n",
    "        callbacks=callbacks_list)\n",
    "    \n",
    "    for idx in tqdm(valid_indexes):\n",
    "        item = train_dataset_info[idx]\n",
    "        path = item['path']\n",
    "        labels = item['labels']\n",
    "        image = data_generator.load_image(path, (SIZE,SIZE,3))/255.\n",
    "        score_predict = model.predict(image[np.newaxis])[0]\n",
    "        oof_class_preds[idx] = score_predict\n",
    "        np.save('../cache/oof_class_preds-14.npy', oof_class_preds)\n",
    "        \n",
    "    for idx, name in tqdm(enumerate(submit['Id'])):\n",
    "        path = os.path.join('../data/test/', name)\n",
    "        image = data_generator.load_image(path, (SIZE,SIZE,3))/255.\n",
    "        score_predict = model.predict(image[np.newaxis])[0]\n",
    "        sub_class_preds[idx] += score_predict\n",
    "        np.save('../cache/sub_class_preds-14.npy', sub_class_preds)\n",
    "    fold_ += 1\n",
    "sub_class_preds /= n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 27958 3114\n",
    "# Epoch 1/2\n",
    "# 1748/1748 [==============================] - 1797s 1s/step - loss: 1.1195 - f1: 0.0376 - val_loss: 1.1698 - val_f1: 0.0320\n",
    "# Epoch 2/2\n",
    "# 1748/1748 [==============================] - 325s 186ms/step - loss: 1.1067 - f1: 0.0476 - val_loss: 1.1549 - val_f1: 0.0308\n",
    "# Epoch 1/120\n",
    "# 1748/1748 [==============================] - 413s 236ms/step - loss: 1.0568 - f1: 0.0977 - val_loss: 0.9852 - val_f1: 0.1725\n",
    "\n",
    "# Epoch 00001: val_loss improved from inf to 0.98515, saving model to ../cache/InceptionV3.h5\n",
    "# Epoch 2/120\n",
    "# 1748/1748 [==============================] - 396s 227ms/step - loss: 0.9804 - f1: 0.1686 - val_loss: 0.9657 - val_f1: 0.2039\n",
    "\n",
    "# Epoch 00002: val_loss improved from 0.98515 to 0.96568, saving model to ../cache/InceptionV3.h5\n",
    "# Epoch 3/120\n",
    "# 1748/1748 [==============================] - 401s 229ms/step - loss: 0.9326 - f1: 0.2086 - val_loss: 0.8926 - val_f1: 0.2645\n",
    "\n",
    "# Epoch 00003: val_loss improved from 0.96568 to 0.89257, saving model to ../cache/InceptionV3.h5\n",
    "# Epoch 4/120\n",
    "# 1748/1748 [==============================] - 403s 230ms/step - loss: 0.9055 - f1: 0.2302 - val_loss: 0.8653 - val_f1: 0.2878\n",
    "\n",
    "# Epoch 00004: val_loss improved from 0.89257 to 0.86533, saving model to ../cache/InceptionV3.h5\n",
    "# Epoch 5/120\n",
    "# 1748/1748 [==============================] - 406s 232ms/step - loss: 0.8883 - f1: 0.2408 - val_loss: 0.8512 - val_f1: 0.3025\n",
    "\n",
    "# Epoch 00005: val_loss improved from 0.86533 to 0.85124, saving model to ../cache/InceptionV3.h5\n",
    "# Epoch 6/120\n",
    "# 1748/1748 [==============================] - 407s 233ms/step - loss: 0.8755 - f1: 0.2495 - val_loss: 0.8227 - val_f1: 0.3191\n",
    "\n",
    "# Epoch 00006: val_loss improved from 0.85124 to 0.82271, saving model to ../cache/InceptionV3.h5\n",
    "# Epoch 7/120\n",
    "# 1748/1748 [==============================] - 404s 231ms/step - loss: 0.8642 - f1: 0.2577 - val_loss: 0.8060 - val_f1: 0.3284\n",
    "\n",
    "# Epoch 00007: val_loss improved from 0.82271 to 0.80597, saving model to ../cache/InceptionV3.h5\n",
    "# Epoch 8/120\n",
    "# 1748/1748 [==============================] - 404s 231ms/step - loss: 0.8521 - f1: 0.2657 - val_loss: 0.8056 - val_f1: 0.3273\n",
    "\n",
    "# Epoch 00008: val_loss improved from 0.80597 to 0.80562, saving model to ../cache/InceptionV3.h5\n",
    "# Epoch 9/120\n",
    "# 1748/1748 [==============================] - 402s 230ms/step - loss: 0.8428 - f1: 0.2711 - val_loss: 0.7919 - val_f1: 0.3408\n",
    "\n",
    "# Epoch 00009: val_loss improved from 0.80562 to 0.79187, saving model to ../cache/InceptionV3.h5\n",
    "# Epoch 10/120\n",
    "# 1748/1748 [==============================] - 399s 228ms/step - loss: 0.8353 - f1: 0.2757 - val_loss: 0.8004 - val_f1: 0.3347\n",
    "\n",
    "# Epoch 00010: val_loss did not improve from 0.79187\n",
    "# Epoch 11/120\n",
    "# 1748/1748 [==============================] - 400s 229ms/step - loss: 0.8286 - f1: 0.2815 - val_loss: 0.7983 - val_f1: 0.3329\n",
    "\n",
    "# Epoch 00011: val_loss did not improve from 0.79187\n",
    "# Epoch 12/120\n",
    "# 1748/1748 [==============================] - 396s 226ms/step - loss: 0.8188 - f1: 0.2875 - val_loss: 0.7782 - val_f1: 0.3509\n",
    "\n",
    "# Epoch 00012: val_loss improved from 0.79187 to 0.77825, saving model to ../cache/InceptionV3.h5\n",
    "# Epoch 13/120\n",
    "# 1748/1748 [==============================] - 396s 226ms/step - loss: 0.8137 - f1: 0.2905 - val_loss: 0.7710 - val_f1: 0.3602\n",
    "\n",
    "# Epoch 00013: val_loss improved from 0.77825 to 0.77102, saving model to ../cache/InceptionV3.h5\n",
    "# Epoch 14/120\n",
    "# 1748/1748 [==============================] - 396s 227ms/step - loss: 0.8078 - f1: 0.2949 - val_loss: 0.7753 - val_f1: 0.3552\n",
    "\n",
    "# Epoch 00014: val_loss did not improve from 0.77102\n",
    "# Epoch 15/120\n",
    "# 1748/1748 [==============================] - 396s 226ms/step - loss: 0.8001 - f1: 0.2995 - val_loss: 0.7773 - val_f1: 0.3505\n",
    "\n",
    "# Epoch 00015: val_loss did not improve from 0.77102\n",
    "# Epoch 16/120\n",
    "# 1748/1748 [==============================] - 395s 226ms/step - loss: 0.7972 - f1: 0.3004 - val_loss: 0.8064 - val_f1: 0.3335\n",
    "\n",
    "# Epoch 00016: val_loss did not improve from 0.77102\n",
    "\n",
    "# Epoch 00016: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
    "# Epoch 17/120\n",
    "# 1748/1748 [==============================] - 396s 226ms/step - loss: 0.7710 - f1: 0.3174 - val_loss: 0.7301 - val_f1: 0.3866\n",
    "\n",
    "# Epoch 00017: val_loss improved from 0.77102 to 0.73014, saving model to ../cache/InceptionV3.h5\n",
    "# Epoch 18/120\n",
    "# 1748/1748 [==============================] - 395s 226ms/step - loss: 0.7606 - f1: 0.3238 - val_loss: 0.7375 - val_f1: 0.3798\n",
    "\n",
    "# Epoch 00018: val_loss did not improve from 0.73014\n",
    "# Epoch 19/120\n",
    "# 1748/1748 [==============================] - 396s 226ms/step - loss: 0.7575 - f1: 0.3253 - val_loss: 0.7297 - val_f1: 0.3862\n",
    "\n",
    "# Epoch 00019: val_loss improved from 0.73014 to 0.72971, saving model to ../cache/InceptionV3.h5\n",
    "# Epoch 20/120\n",
    "# 1748/1748 [==============================] - 394s 225ms/step - loss: 0.7554 - f1: 0.3257 - val_loss: 0.7304 - val_f1: 0.3831\n",
    "\n",
    "# Epoch 00020: val_loss did not improve from 0.72971\n",
    "# Epoch 21/120\n",
    "# 1748/1748 [==============================] - 395s 226ms/step - loss: 0.7496 - f1: 0.3294 - val_loss: 0.7343 - val_f1: 0.3803\n",
    "\n",
    "# Epoch 00021: val_loss did not improve from 0.72971\n",
    "# Epoch 22/120\n",
    "# 1748/1748 [==============================] - 393s 225ms/step - loss: 0.7482 - f1: 0.3302 - val_loss: 0.7265 - val_f1: 0.3887\n",
    "\n",
    "# Epoch 00022: val_loss improved from 0.72971 to 0.72649, saving model to ../cache/InceptionV3.h5\n",
    "# Epoch 23/120\n",
    "# 1748/1748 [==============================] - 394s 226ms/step - loss: 0.7444 - f1: 0.3328 - val_loss: 0.7339 - val_f1: 0.3818\n",
    "\n",
    "# Epoch 00023: val_loss did not improve from 0.72649\n",
    "# Epoch 24/120\n",
    "# 1748/1748 [==============================] - 394s 225ms/step - loss: 0.7426 - f1: 0.3338 - val_loss: 0.7304 - val_f1: 0.3866\n",
    "\n",
    "# Epoch 00024: val_loss did not improve from 0.72649\n",
    "# Epoch 25/120\n",
    "# 1748/1748 [==============================] - 394s 226ms/step - loss: 0.7398 - f1: 0.3354 - val_loss: 0.7324 - val_f1: 0.3816\n",
    "\n",
    "# Epoch 00025: val_loss did not improve from 0.72649\n",
    "\n",
    "# Epoch 00025: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
    "# Epoch 26/120\n",
    "# 1748/1748 [==============================] - 395s 226ms/step - loss: 0.7369 - f1: 0.3367 - val_loss: 0.7284 - val_f1: 0.3866\n",
    "\n",
    "# Epoch 00026: val_loss did not improve from 0.72649\n",
    "# Epoch 27/120\n",
    "# 1748/1748 [==============================] - 394s 225ms/step - loss: 0.7358 - f1: 0.3378 - val_loss: 0.7321 - val_f1: 0.3835\n",
    "\n",
    "# Epoch 00027: val_loss did not improve from 0.72649\n",
    "# Epoch 28/120\n",
    "# 1748/1748 [==============================] - 393s 225ms/step - loss: 0.7357 - f1: 0.3381 - val_loss: 0.7290 - val_f1: 0.3877\n",
    "#   0%|          | 0/3114 [00:00<?, ?it/s]\n",
    "\n",
    "# Epoch 00028: val_loss did not improve from 0.72649\n",
    "\n",
    "# Epoch 00028: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
    "# 100%|██████████| 3114/3114 [02:42<00:00, 19.14it/s]\n",
    "# 11702it [21:06,  9.24it/s]\n",
    "# 27973 3099\n",
    "# Epoch 1/2\n",
    "# 1749/1749 [==============================] - 331s 190ms/step - loss: 1.1197 - f1: 0.0378 - val_loss: 1.1816 - val_f1: 0.0357\n",
    "# Epoch 2/2\n",
    "# 1749/1749 [==============================] - 319s 182ms/step - loss: 1.1067 - f1: 0.0478 - val_loss: 1.2044 - val_f1: 0.0347\n",
    "# Epoch 1/120\n",
    "# 1749/1749 [==============================] - 405s 232ms/step - loss: 1.0601 - f1: 0.0933 - val_loss: 0.9947 - val_f1: 0.1676\n",
    "\n",
    "# Epoch 00001: val_loss improved from inf to 0.99467, saving model to ../cache/InceptionV3.h5\n",
    "# Epoch 2/120\n",
    "# 1749/1749 [==============================] - 384s 220ms/step - loss: 0.9880 - f1: 0.1613 - val_loss: 0.9376 - val_f1: 0.2233\n",
    "\n",
    "# Epoch 00002: val_loss improved from 0.99467 to 0.93759, saving model to ../cache/InceptionV3.h5\n",
    "# Epoch 3/120\n",
    "# 1749/1749 [==============================] - 385s 220ms/step - loss: 0.9386 - f1: 0.2050 - val_loss: 0.8781 - val_f1: 0.2778\n",
    "\n",
    "# Epoch 00003: val_loss improved from 0.93759 to 0.87811, saving model to ../cache/InceptionV3.h5\n",
    "# Epoch 4/120\n",
    "# 1749/1749 [==============================] - 385s 220ms/step - loss: 0.9109 - f1: 0.2256 - val_loss: 0.8430 - val_f1: 0.2990\n",
    "\n",
    "# Epoch 00004: val_loss improved from 0.87811 to 0.84296, saving model to ../cache/InceptionV3.h5\n",
    "# Epoch 5/120\n",
    "# 1749/1749 [==============================] - 384s 220ms/step - loss: 0.8937 - f1: 0.2383 - val_loss: 0.8510 - val_f1: 0.2958\n",
    "\n",
    "# Epoch 00005: val_loss did not improve from 0.84296\n",
    "# Epoch 6/120\n",
    "# 1749/1749 [==============================] - 384s 219ms/step - loss: 0.8799 - f1: 0.2472 - val_loss: 0.8430 - val_f1: 0.3046\n",
    "\n",
    "# Epoch 00006: val_loss did not improve from 0.84296\n",
    "# Epoch 7/120\n",
    "# 1749/1749 [==============================] - 384s 219ms/step - loss: 0.8679 - f1: 0.2548 - val_loss: 0.8243 - val_f1: 0.3158\n",
    "\n",
    "# Epoch 00007: val_loss improved from 0.84296 to 0.82426, saving model to ../cache/InceptionV3.h5\n",
    "# Epoch 8/120\n",
    "# 1749/1749 [==============================] - 383s 219ms/step - loss: 0.8553 - f1: 0.2641 - val_loss: 0.8559 - val_f1: 0.2988\n",
    "\n",
    "# Epoch 00008: val_loss did not improve from 0.82426\n",
    "# Epoch 9/120\n",
    "# 1749/1749 [==============================] - 384s 219ms/step - loss: 0.8510 - f1: 0.2662 - val_loss: 0.8497 - val_f1: 0.3030\n",
    "\n",
    "# Epoch 00009: val_loss did not improve from 0.82426\n",
    "# Epoch 10/120\n",
    "# 1749/1749 [==============================] - 382s 218ms/step - loss: 0.8410 - f1: 0.2731 - val_loss: 0.8813 - val_f1: 0.2890\n",
    "\n",
    "# Epoch 00010: val_loss did not improve from 0.82426\n",
    "\n",
    "# Epoch 00010: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
    "# Epoch 11/120\n",
    "# 1749/1749 [==============================] - 382s 219ms/step - loss: 0.8165 - f1: 0.2874 - val_loss: 0.7563 - val_f1: 0.3650\n",
    "\n",
    "# Epoch 00011: val_loss improved from 0.82426 to 0.75628, saving model to ../cache/InceptionV3.h5\n",
    "# Epoch 12/120\n",
    "# 1749/1749 [==============================] - 382s 218ms/step - loss: 0.8073 - f1: 0.2933 - val_loss: 0.7564 - val_f1: 0.3663\n",
    "\n",
    "# Epoch 00012: val_loss did not improve from 0.75628\n",
    "# Epoch 13/120\n",
    "# 1749/1749 [==============================] - 383s 219ms/step - loss: 0.8035 - f1: 0.2963 - val_loss: 0.7528 - val_f1: 0.3692\n",
    "\n",
    "# Epoch 00013: val_loss improved from 0.75628 to 0.75284, saving model to ../cache/InceptionV3.h5\n",
    "# Epoch 14/120\n",
    "# 1749/1749 [==============================] - 383s 219ms/step - loss: 0.7986 - f1: 0.2995 - val_loss: 0.7515 - val_f1: 0.3681\n",
    "\n",
    "# Epoch 00014: val_loss improved from 0.75284 to 0.75147, saving model to ../cache/InceptionV3.h5\n",
    "# Epoch 15/120\n",
    "# 1749/1749 [==============================] - 382s 219ms/step - loss: 0.7943 - f1: 0.3026 - val_loss: 0.7538 - val_f1: 0.3696\n",
    "\n",
    "# Epoch 00015: val_loss did not improve from 0.75147\n",
    "# Epoch 16/120\n",
    "# 1749/1749 [==============================] - 382s 219ms/step - loss: 0.7955 - f1: 0.3003 - val_loss: 0.7536 - val_f1: 0.3683\n",
    "\n",
    "# Epoch 00016: val_loss did not improve from 0.75147\n",
    "# Epoch 17/120\n",
    "# 1749/1749 [==============================] - 384s 219ms/step - loss: 0.7889 - f1: 0.3054 - val_loss: 0.7508 - val_f1: 0.3676\n",
    "\n",
    "# Epoch 00017: val_loss improved from 0.75147 to 0.75082, saving model to ../cache/InceptionV3.h5\n",
    "# Epoch 18/120\n",
    "# 1749/1749 [==============================] - 383s 219ms/step - loss: 0.7860 - f1: 0.3074 - val_loss: 0.7566 - val_f1: 0.3672\n",
    "\n",
    "# Epoch 00018: val_loss did not improve from 0.75082\n",
    "# Epoch 19/120\n",
    "# 1749/1749 [==============================] - 383s 219ms/step - loss: 0.7832 - f1: 0.3099 - val_loss: 0.7517 - val_f1: 0.3718\n",
    "\n",
    "# Epoch 00019: val_loss did not improve from 0.75082\n",
    "# Epoch 20/120\n",
    "# 1749/1749 [==============================] - 382s 219ms/step - loss: 0.7794 - f1: 0.3112 - val_loss: 0.7510 - val_f1: 0.3683\n",
    "\n",
    "# Epoch 00020: val_loss did not improve from 0.75082\n",
    "\n",
    "# Epoch 00020: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
    "# Epoch 21/120\n",
    "# 1749/1749 [==============================] - 383s 219ms/step - loss: 0.7766 - f1: 0.3129 - val_loss: 0.7479 - val_f1: 0.3757\n",
    "\n",
    "# Epoch 00021: val_loss improved from 0.75082 to 0.74793, saving model to ../cache/InceptionV3.h5\n",
    "# Epoch 22/120\n",
    "# 1749/1749 [==============================] - 383s 219ms/step - loss: 0.7778 - f1: 0.3123 - val_loss: 0.7495 - val_f1: 0.3689\n",
    "\n",
    "# Epoch 00022: val_loss did not improve from 0.74793\n",
    "# Epoch 23/120\n",
    "# 1749/1749 [==============================] - 383s 219ms/step - loss: 0.7773 - f1: 0.3124 - val_loss: 0.7480 - val_f1: 0.3725\n",
    "\n",
    "# Epoch 00023: val_loss did not improve from 0.74793\n",
    "# Epoch 24/120\n",
    "# 1749/1749 [==============================] - 382s 219ms/step - loss: 0.7740 - f1: 0.3146 - val_loss: 0.7491 - val_f1: 0.3715\n",
    "\n",
    "# Epoch 00024: val_loss did not improve from 0.74793\n",
    "\n",
    "# Epoch 00024: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
    "# Epoch 25/120\n",
    "# 1749/1749 [==============================] - 382s 219ms/step - loss: 0.7737 - f1: 0.3153 - val_loss: 0.7473 - val_f1: 0.3761\n",
    "\n",
    "# Epoch 00025: val_loss improved from 0.74793 to 0.74733, saving model to ../cache/InceptionV3.h5\n",
    "# Epoch 26/120\n",
    "# 1749/1749 [==============================] - 383s 219ms/step - loss: 0.7742 - f1: 0.3146 - val_loss: 0.7437 - val_f1: 0.3774\n",
    "\n",
    "# Epoch 00026: val_loss improved from 0.74733 to 0.74374, saving model to ../cache/InceptionV3.h5\n",
    "# Epoch 27/120\n",
    "# 1749/1749 [==============================] - 383s 219ms/step - loss: 0.7743 - f1: 0.3141 - val_loss: 0.7483 - val_f1: 0.3721\n",
    "\n",
    "# Epoch 00027: val_loss did not improve from 0.74374\n",
    "# Epoch 28/120\n",
    "# 1749/1749 [==============================] - 384s 219ms/step - loss: 0.7740 - f1: 0.3141 - val_loss: 0.7494 - val_f1: 0.3722\n",
    "\n",
    "# Epoch 00028: val_loss did not improve from 0.74374\n",
    "# Epoch 29/120\n",
    "# 1749/1749 [==============================] - 383s 219ms/step - loss: 0.7741 - f1: 0.3147 - val_loss: 0.7469 - val_f1: 0.3752\n",
    "\n",
    "# Epoch 00029: val_loss did not improve from 0.74374\n",
    "\n",
    "# Epoch 00029: ReduceLROnPlateau reducing learning rate to 1.0000000116860975e-08.\n",
    "# Epoch 30/120\n",
    "# 1749/1749 [==============================] - 383s 219ms/step - loss: 0.7732 - f1: 0.3159 - val_loss: 0.7468 - val_f1: 0.3734\n",
    "\n",
    "# Epoch 00030: val_loss did not improve from 0.74374\n",
    "# Epoch 31/120\n",
    "# 1749/1749 [==============================] - 384s 220ms/step - loss: 0.7745 - f1: 0.3138 - val_loss: 0.7500 - val_f1: 0.3702\n",
    "\n",
    "# Epoch 00031: val_loss did not improve from 0.74374\n",
    "# Epoch 32/120\n",
    "# 1749/1749 [==============================] - 386s 221ms/step - loss: 0.7765 - f1: 0.3127 - val_loss: 0.7468 - val_f1: 0.3748\n",
    "#   0%|          | 0/3099 [00:00<?, ?it/s]\n",
    "\n",
    "# Epoch 00032: val_loss did not improve from 0.74374\n",
    "\n",
    "# Epoch 00032: ReduceLROnPlateau reducing learning rate to 9.999999939225292e-10.\n",
    "# 100%|██████████| 3099/3099 [02:47<00:00, 18.52it/s]\n",
    "# 11702it [08:03, 24.19it/s]\n",
    "# 27969 3103\n",
    "# Epoch 1/2\n",
    "# 1749/1749 [==============================] - 331s 189ms/step - loss: 1.1194 - f1: 0.0381 - val_loss: 1.1530 - val_f1: 0.0276\n",
    "# Epoch 2/2\n",
    "# 1749/1749 [==============================] - 328s 187ms/step - loss: 1.1066 - f1: 0.0477 - val_loss: 1.2052 - val_f1: 0.0364\n",
    "# Epoch 1/120\n",
    "# 1749/1749 [==============================] - 401s 229ms/step - loss: 1.0629 - f1: 0.0893 - val_loss: 1.0045 - val_f1: 0.1535\n",
    "\n",
    "# Epoch 00001: val_loss improved from inf to 1.00452, saving model to ../cache/InceptionV3.h5\n",
    "# Epoch 2/120\n",
    "# 1749/1749 [==============================] - 380s 218ms/step - loss: 0.9884 - f1: 0.1612 - val_loss: 0.9702 - val_f1: 0.1899\n",
    "\n",
    "# Epoch 00002: val_loss improved from 1.00452 to 0.97018, saving model to ../cache/InceptionV3.h5\n",
    "# Epoch 3/120\n",
    "# 1749/1749 [==============================] - 378s 216ms/step - loss: 0.9427 - f1: 0.2013 - val_loss: 0.8851 - val_f1: 0.2652\n",
    "\n",
    "# Epoch 00003: val_loss improved from 0.97018 to 0.88508, saving model to ../cache/InceptionV3.h5\n",
    "# Epoch 4/120\n",
    "# 1749/1749 [==============================] - 379s 217ms/step - loss: 0.9145 - f1: 0.2240 - val_loss: 0.8796 - val_f1: 0.2782\n",
    "\n",
    "# Epoch 00004: val_loss improved from 0.88508 to 0.87963, saving model to ../cache/InceptionV3.h5\n",
    "# Epoch 5/120\n",
    "#  978/1749 [===============>..............] - ETA: 2:24 - loss: 0.8989 - f1: 0.2330"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../cache/oof_class_preds-14.npy', oof_class_preds)\n",
    "np.save('../cache/sub_class_preds-14.npy', sub_class_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oof_class_preds = np.zeros((train_dataset_info.shape[0], 28))\n",
    "# sub_class_preds = np.zeros((submit.shape[0], 28))\n",
    "# score_predict = model.predict(image[np.newaxis])[0]\n",
    "# oof_class_preds[idx] = score_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for train_index, test_index in kf.split(indexes):\n",
    "# ...    print(\"TRAIN:\", train_index, \"TEST:\", test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11702, 28)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_class_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11702/11702 [00:00<00:00, 82600.97it/s]\n"
     ]
    }
   ],
   "source": [
    "predicted = []\n",
    "for line in tqdm(sub_class_preds):\n",
    "    label_predict = np.arange(28)[line>=0.2]\n",
    "    str_predict_label = ' '.join(str(l) for l in label_predict)\n",
    "    predicted.append(str_predict_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11702"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2',\n",
       " '5 25',\n",
       " '0 5 25',\n",
       " '0 25',\n",
       " '0 7 25',\n",
       " '4',\n",
       " '0 4 23 25',\n",
       " '0 23 25',\n",
       " '0',\n",
       " '0 25',\n",
       " '18 25',\n",
       " '3 5',\n",
       " '0 25',\n",
       " '7 9 20',\n",
       " '23',\n",
       " '4 18 25',\n",
       " '2 14',\n",
       " '0 5',\n",
       " '14 21',\n",
       " '0 5',\n",
       " '6',\n",
       " '3 5 24',\n",
       " '0 11 16 17 25',\n",
       " '0 21',\n",
       " '0 25',\n",
       " '0 11 12 25 26',\n",
       " '0',\n",
       " '0 5',\n",
       " '0 2 25',\n",
       " '0',\n",
       " '21',\n",
       " '0 7 25',\n",
       " '14 16 17 18 21 25',\n",
       " '0 5 25',\n",
       " '0 7 25',\n",
       " '13',\n",
       " '0 25',\n",
       " '0 3',\n",
       " '0 5 21 25',\n",
       " '1',\n",
       " '0 16 17 25',\n",
       " '6 25',\n",
       " '0 21',\n",
       " '18 19 25',\n",
       " '0 14 16 25',\n",
       " '6',\n",
       " '0',\n",
       " '0',\n",
       " '6 11 23 25',\n",
       " '0',\n",
       " '0 25',\n",
       " '0 5',\n",
       " '20 23',\n",
       " '0 25',\n",
       " '3',\n",
       " '0 25',\n",
       " '0 25',\n",
       " '11 23',\n",
       " '0 25',\n",
       " '11 21 25',\n",
       " '2 21 22 23',\n",
       " '0 5 21 25',\n",
       " '14 16',\n",
       " '7 21 25',\n",
       " '23',\n",
       " '0 13 18 19 25',\n",
       " '3 6 21 25',\n",
       " '0 21 22 25',\n",
       " '0 16',\n",
       " '21 25',\n",
       " '2 3',\n",
       " '0 2',\n",
       " '14',\n",
       " '4',\n",
       " '21',\n",
       " '0',\n",
       " '2 4',\n",
       " '0 1',\n",
       " '0 25',\n",
       " '0 25',\n",
       " '6 25',\n",
       " '0 25',\n",
       " '0 21',\n",
       " '0 21 25',\n",
       " '18 19',\n",
       " '0 23 24 25',\n",
       " '20 23',\n",
       " '0 21',\n",
       " '14 25',\n",
       " '12 14',\n",
       " '0 25',\n",
       " '11 21',\n",
       " '23',\n",
       " '12 13',\n",
       " '0 16 17 23 25',\n",
       " '0 25',\n",
       " '7 17 18 25',\n",
       " '0 19 25',\n",
       " '24',\n",
       " '0 23 25',\n",
       " '0 25',\n",
       " '23',\n",
       " '21 23',\n",
       " '0 23',\n",
       " '7 11 25',\n",
       " '2 21 25',\n",
       " '0 14 16',\n",
       " '0 11 16 24 25',\n",
       " '20 26',\n",
       " '0 25',\n",
       " '0 2',\n",
       " '1',\n",
       " '16 17 18 25',\n",
       " '0 22 25',\n",
       " '25',\n",
       " '21 23',\n",
       " '0 2 25',\n",
       " '4 25',\n",
       " '14 16 17 25',\n",
       " '26',\n",
       " '0 18 19 25',\n",
       " '21 25',\n",
       " '2 21 25',\n",
       " '8 9 10 20 23',\n",
       " '0 4',\n",
       " '0',\n",
       " '0 25',\n",
       " '25',\n",
       " '0 3 4',\n",
       " '19',\n",
       " '25',\n",
       " '0 21',\n",
       " '0',\n",
       " '0',\n",
       " '0 11',\n",
       " '5',\n",
       " '0 14 16 25',\n",
       " '0 25',\n",
       " '21',\n",
       " '6 25',\n",
       " '0 19 21 25',\n",
       " '21 25',\n",
       " '0 1',\n",
       " '0 5',\n",
       " '0 25',\n",
       " '4 26',\n",
       " '0 21 23 25',\n",
       " '0 6 23 25',\n",
       " '0',\n",
       " '0 6 25',\n",
       " '0 3',\n",
       " '7 16 17 18',\n",
       " '0 7',\n",
       " '0 11 25',\n",
       " '6 7 25',\n",
       " '6',\n",
       " '0 7',\n",
       " '0 16 25',\n",
       " '1 2 25',\n",
       " '6 25',\n",
       " '0 18 19 25',\n",
       " '0 17 18 21 25',\n",
       " '0 3 11 25',\n",
       " '4 25',\n",
       " '5',\n",
       " '21 23',\n",
       " '0 19 25',\n",
       " '19',\n",
       " '17 21 25',\n",
       " '7 16 17 25',\n",
       " '5 25',\n",
       " '0 6 21 25',\n",
       " '0 14 16 25',\n",
       " '21 23',\n",
       " '0 2',\n",
       " '0 11 23',\n",
       " '21',\n",
       " '0 7 25',\n",
       " '0 12 21',\n",
       " '0 2 25',\n",
       " '0',\n",
       " '23',\n",
       " '0 19',\n",
       " '0 24',\n",
       " '14',\n",
       " '0 14 16 17 25',\n",
       " '0 25',\n",
       " '0 5 25',\n",
       " '23',\n",
       " '14 16 17 21 25',\n",
       " '14 17 25',\n",
       " '0 25',\n",
       " '5 25 26',\n",
       " '25 26',\n",
       " '0 5 25',\n",
       " '0 13 22',\n",
       " '0 25',\n",
       " '16',\n",
       " '23 25',\n",
       " '0 4 25',\n",
       " '2 21',\n",
       " '0 2 3',\n",
       " '0 2 25',\n",
       " '0 25',\n",
       " '0 3 19 25',\n",
       " '21',\n",
       " '0 21 25',\n",
       " '0 5',\n",
       " '0',\n",
       " '21',\n",
       " '0 14 16',\n",
       " '0 5',\n",
       " '7',\n",
       " '0 5',\n",
       " '18 19 25',\n",
       " '0 21',\n",
       " '24 26',\n",
       " '7 25',\n",
       " '21 22',\n",
       " '2 3',\n",
       " '0 3 22',\n",
       " '14 17 21 25',\n",
       " '13 21 26',\n",
       " '2 3 12',\n",
       " '6 8 20 23',\n",
       " '0 23',\n",
       " '21 25',\n",
       " '12 25',\n",
       " '0 19',\n",
       " '0 1 5',\n",
       " '2 25',\n",
       " '0 11',\n",
       " '0 2',\n",
       " '23',\n",
       " '0 23 25',\n",
       " '11',\n",
       " '13 20 26',\n",
       " '0 12',\n",
       " '0 18 21 23 25',\n",
       " '16 17 18 25',\n",
       " '21',\n",
       " '2 7',\n",
       " '21 25',\n",
       " '0 21 25',\n",
       " '2 4 11 14 16 17 21',\n",
       " '12 23',\n",
       " '25',\n",
       " '4',\n",
       " '13 22',\n",
       " '0 1',\n",
       " '0 25',\n",
       " '0 25',\n",
       " '2 3 6 25',\n",
       " '0 2 25',\n",
       " '0 25',\n",
       " '11',\n",
       " '23',\n",
       " '3 5',\n",
       " '25',\n",
       " '12 21 25',\n",
       " '14 16 17 25',\n",
       " '19 26',\n",
       " '0 4 26',\n",
       " '0 5',\n",
       " '13 21 22',\n",
       " '0',\n",
       " '12',\n",
       " '0 2',\n",
       " '23 25',\n",
       " '0 25',\n",
       " '0 19',\n",
       " '21 25',\n",
       " '0 12',\n",
       " '0 2 25',\n",
       " '2',\n",
       " '0 18 19 25',\n",
       " '0 2',\n",
       " '11',\n",
       " '0 25',\n",
       " '0 18',\n",
       " '0 21 25',\n",
       " '2',\n",
       " '0 3',\n",
       " '8 9 10 20 26',\n",
       " '0 18 19',\n",
       " '0 12 21',\n",
       " '0 2',\n",
       " '7',\n",
       " '1 2 6',\n",
       " '7 11 24',\n",
       " '0 5 16',\n",
       " '0 14 16',\n",
       " '0 18 21 25',\n",
       " '7',\n",
       " '0 19',\n",
       " '0 21 25',\n",
       " '23 25',\n",
       " '0 2 25',\n",
       " '0 5 19',\n",
       " '0 2 21 25',\n",
       " '0 26',\n",
       " '0 3 5 19',\n",
       " '0 11 25',\n",
       " '0 14',\n",
       " '23 25',\n",
       " '0 16 19',\n",
       " '0 1',\n",
       " '14 16 17 25',\n",
       " '0 21',\n",
       " '0',\n",
       " '11 25',\n",
       " '6 11',\n",
       " '0 4 7 25',\n",
       " '0',\n",
       " '0',\n",
       " '21 25',\n",
       " '14 16 17 18 25',\n",
       " '0 25',\n",
       " '0 25',\n",
       " '0 2 17 25',\n",
       " '19',\n",
       " '6',\n",
       " '0 21 25',\n",
       " '0 2',\n",
       " '0',\n",
       " '0 2 7 18 25',\n",
       " '21 22',\n",
       " '0 2',\n",
       " '0 2 3',\n",
       " '0 14',\n",
       " '5',\n",
       " '3 9 19 25',\n",
       " '25',\n",
       " '0 1 21',\n",
       " '11 21 25',\n",
       " '7',\n",
       " '24',\n",
       " '14 16 17 25',\n",
       " '0 25',\n",
       " '6',\n",
       " '21 25',\n",
       " '0 7',\n",
       " '0 2 4',\n",
       " '14 16',\n",
       " '4 12 21 25',\n",
       " '0 2 3 19 25',\n",
       " '18 19',\n",
       " '3 7',\n",
       " '0 2 21 25',\n",
       " '0 25',\n",
       " '0 7',\n",
       " '8 9 20 26',\n",
       " '25',\n",
       " '5 19',\n",
       " '0 2 16 25',\n",
       " '3',\n",
       " '0 7 24',\n",
       " '0 5 21',\n",
       " '25',\n",
       " '2 4',\n",
       " '11 24 25',\n",
       " '2 6 25',\n",
       " '0 25',\n",
       " '0 25',\n",
       " '7',\n",
       " '11',\n",
       " '11',\n",
       " '0',\n",
       " '0 5 19 25',\n",
       " '0 5',\n",
       " '16 17 18 21 25',\n",
       " '0 1 25',\n",
       " '0 21 25',\n",
       " '17 21 25',\n",
       " '0 23',\n",
       " '0 21',\n",
       " '0 3',\n",
       " '0 3 25',\n",
       " '12 21',\n",
       " '4 13 21 25',\n",
       " '0 2 21',\n",
       " '2 7',\n",
       " '0',\n",
       " '2 14 21 25',\n",
       " '4 5',\n",
       " '14 25',\n",
       " '0 25',\n",
       " '3',\n",
       " '18 19',\n",
       " '0 25',\n",
       " '16 17 18 25',\n",
       " '25',\n",
       " '0 14',\n",
       " '21 25',\n",
       " '0 5',\n",
       " '0 25',\n",
       " '0 21',\n",
       " '0 11 25',\n",
       " '14 17 21',\n",
       " '0',\n",
       " '0 12 21 23',\n",
       " '0',\n",
       " '21 23',\n",
       " '0 14 21',\n",
       " '0 21 22 25',\n",
       " '0 2 23',\n",
       " '0 20 23',\n",
       " '20 26',\n",
       " '0 5 21 25',\n",
       " '1',\n",
       " '6 25',\n",
       " '0 3 21 25',\n",
       " '20 23',\n",
       " '7',\n",
       " '0 25',\n",
       " '0',\n",
       " '0 21 25',\n",
       " '6 25',\n",
       " '0 2 21 25',\n",
       " '0 7 24',\n",
       " '0 7 25',\n",
       " '0 2 5',\n",
       " '5 16 17 18 21',\n",
       " '0 3 4 25',\n",
       " '0 21 25',\n",
       " '0 7 25',\n",
       " '0 18 25',\n",
       " '0 18 19',\n",
       " '0 3 5 24',\n",
       " '4 21 25',\n",
       " '0 12 21 25',\n",
       " '0 23 25',\n",
       " '23',\n",
       " '0 14 16',\n",
       " '0 18 25',\n",
       " '0 23 25',\n",
       " '0 4',\n",
       " '0 12 21 23',\n",
       " '2',\n",
       " '7',\n",
       " '1',\n",
       " '21 25',\n",
       " '11 25',\n",
       " '0 2 3',\n",
       " '0 25',\n",
       " '0 22 25',\n",
       " '0',\n",
       " '18 19 21 25',\n",
       " '14 16 17 25',\n",
       " '16 17 18 21',\n",
       " '12 21',\n",
       " '0 2',\n",
       " '0 4 21 25',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0 3 5 25',\n",
       " '25',\n",
       " '6 11',\n",
       " '4',\n",
       " '0 25',\n",
       " '2 21 25',\n",
       " '0 2',\n",
       " '0 2 25',\n",
       " '7 9 20',\n",
       " '21',\n",
       " '23',\n",
       " '0 23',\n",
       " '0 2 11',\n",
       " '7 11',\n",
       " '3',\n",
       " '23',\n",
       " '0 2',\n",
       " '0 25',\n",
       " '14 16 17 25',\n",
       " '3 4',\n",
       " '0 25',\n",
       " '0 25',\n",
       " '5 6 25',\n",
       " '4',\n",
       " '14',\n",
       " '0 21 22 25',\n",
       " '4',\n",
       " '0',\n",
       " '0 21 22',\n",
       " '0 21 25',\n",
       " '2 25',\n",
       " '0 13',\n",
       " '4',\n",
       " '0 1',\n",
       " '0 25',\n",
       " '21 25',\n",
       " '0 25',\n",
       " '2 25',\n",
       " '0 25',\n",
       " '7 20',\n",
       " '21 25',\n",
       " '0 7',\n",
       " '0 23',\n",
       " '19 23 25',\n",
       " '16 17 21 25',\n",
       " '2',\n",
       " '0',\n",
       " '21 25',\n",
       " '21 23',\n",
       " '0',\n",
       " '0 21',\n",
       " '2 7 25',\n",
       " '0 25',\n",
       " '0 7',\n",
       " '0 21 25',\n",
       " '0 7 21 25',\n",
       " '12 13',\n",
       " '0 2 3 25',\n",
       " '0 13 21 22 25',\n",
       " '21 25',\n",
       " '7',\n",
       " '0',\n",
       " '16 25',\n",
       " '3',\n",
       " '0 19',\n",
       " '0 3 25',\n",
       " '0 1 25',\n",
       " '0 11 25',\n",
       " '21',\n",
       " '25',\n",
       " '0 4 18',\n",
       " '7',\n",
       " '0 1 25',\n",
       " '21 23',\n",
       " '18 19',\n",
       " '0 5 21',\n",
       " '0 16 17 18 25',\n",
       " '0 14 16 17 18 21',\n",
       " '4 25',\n",
       " '0 14',\n",
       " '2 25',\n",
       " '19',\n",
       " '0 25',\n",
       " '18 19',\n",
       " '12',\n",
       " '0 5 21',\n",
       " '5 26',\n",
       " '0',\n",
       " '0',\n",
       " '7',\n",
       " '4',\n",
       " '0',\n",
       " '2 7 21',\n",
       " '2',\n",
       " '6 23',\n",
       " '14',\n",
       " '0 2 25',\n",
       " '0 11 12 16 25',\n",
       " '2 7 21 25',\n",
       " '21',\n",
       " '12 21 25',\n",
       " '0 25',\n",
       " '0 17 18 21 25',\n",
       " '0 25',\n",
       " '7',\n",
       " '0',\n",
       " '21 23',\n",
       " '2 7 21',\n",
       " '18 25',\n",
       " '0 25',\n",
       " '2 25',\n",
       " '0 19 25',\n",
       " '25',\n",
       " '0 23 25',\n",
       " '18',\n",
       " '0 25',\n",
       " '14 16 25',\n",
       " '0 18',\n",
       " '7 21 25',\n",
       " '24',\n",
       " '0 16 17 25',\n",
       " '7 16',\n",
       " '0',\n",
       " '25',\n",
       " '0 18 25',\n",
       " '5 20 21 26',\n",
       " '6 25',\n",
       " '5 19 21 25',\n",
       " '21',\n",
       " '0',\n",
       " '21',\n",
       " '4 26',\n",
       " '23',\n",
       " '21',\n",
       " '0 7 19',\n",
       " '5 23',\n",
       " '0 5 13 20 22',\n",
       " '6 25',\n",
       " '21 22 25',\n",
       " '0 25',\n",
       " '0 5 19 25',\n",
       " '2 3',\n",
       " '2 14',\n",
       " '6',\n",
       " '0 2 23 25',\n",
       " '1 2',\n",
       " '23',\n",
       " '0 25',\n",
       " '25',\n",
       " '0 5 21',\n",
       " '0',\n",
       " '19',\n",
       " '0 4 7',\n",
       " '0 12 21',\n",
       " '0 25',\n",
       " '7 25',\n",
       " '14',\n",
       " '12 14 21',\n",
       " '5 19',\n",
       " '21',\n",
       " '23',\n",
       " '1 25',\n",
       " '0 25',\n",
       " '7',\n",
       " '0 21 23 25',\n",
       " '3 5',\n",
       " '0 12',\n",
       " '14',\n",
       " '23 25',\n",
       " '0 21',\n",
       " '5 21 22',\n",
       " '21 22',\n",
       " '0 25',\n",
       " '25',\n",
       " '0 12 21',\n",
       " '0 25',\n",
       " '0 7 21 23',\n",
       " '0 25',\n",
       " '3 5 25',\n",
       " '14 16 17',\n",
       " '0 7 18',\n",
       " '0 19',\n",
       " '5',\n",
       " '7',\n",
       " '21 22',\n",
       " '13',\n",
       " '0',\n",
       " '23 25',\n",
       " '0 7',\n",
       " '11 21 25',\n",
       " '0 25',\n",
       " '7 23 25',\n",
       " '0 5 25',\n",
       " '20 25 26',\n",
       " '21 25',\n",
       " '11 14 21 25',\n",
       " '0 21 25',\n",
       " '0 2 3 7',\n",
       " '2',\n",
       " '5 21',\n",
       " '0 23 25',\n",
       " '1 4',\n",
       " '0 1 18 19 21 25',\n",
       " '0 25',\n",
       " '0 18 19',\n",
       " '0 5',\n",
       " '0 19 26',\n",
       " '0 16 17 25',\n",
       " '0 25',\n",
       " '4 26',\n",
       " '7',\n",
       " '5 25',\n",
       " '0 5 25',\n",
       " '21 22',\n",
       " '14 16 17 25',\n",
       " '0 21 22',\n",
       " '0 21 25',\n",
       " '7',\n",
       " '5 25',\n",
       " '18 19',\n",
       " '0 1 25',\n",
       " '0 21',\n",
       " '19 26',\n",
       " '18 19 25',\n",
       " '23 25',\n",
       " '1 2 25',\n",
       " '0 4 14 16',\n",
       " '22',\n",
       " '0 21 25',\n",
       " '0 25',\n",
       " '0 22',\n",
       " '0 21',\n",
       " '0 25',\n",
       " '0 16 17 25',\n",
       " '0 25',\n",
       " '23',\n",
       " '0 2 5 21',\n",
       " '4',\n",
       " '13',\n",
       " '0 25',\n",
       " '21 25',\n",
       " '0 12 23 25',\n",
       " '1 21 25',\n",
       " '0 5 14',\n",
       " '5',\n",
       " '0 4 23',\n",
       " '7 21 23',\n",
       " '14',\n",
       " '0 2 3 11 25',\n",
       " '5 25',\n",
       " '11',\n",
       " '0 7',\n",
       " '0 21 22',\n",
       " '3',\n",
       " '0 21',\n",
       " '0 25',\n",
       " '21 25',\n",
       " '1 21 25',\n",
       " '25',\n",
       " '0 21 25',\n",
       " '0 11 12 21 22 24',\n",
       " '0 2',\n",
       " '5',\n",
       " '0 21',\n",
       " '0 2 18 19',\n",
       " '21',\n",
       " '25',\n",
       " '0 25',\n",
       " '19',\n",
       " '0',\n",
       " '0 2 25',\n",
       " '0 23',\n",
       " '0 1 2 5',\n",
       " '0 19',\n",
       " '0 25',\n",
       " '0 13 22 25',\n",
       " '0 5',\n",
       " '0 17 18 21',\n",
       " '0 2 7',\n",
       " '0 1 2',\n",
       " '0 7 21',\n",
       " '0 21 25',\n",
       " '0 18 25',\n",
       " '23',\n",
       " '7 13 25',\n",
       " '0 3 19 21 25',\n",
       " '21 23 25',\n",
       " '23 25',\n",
       " '21',\n",
       " '7 18 21 24',\n",
       " '0 13',\n",
       " '21 25',\n",
       " '25',\n",
       " '0 21 25',\n",
       " '0',\n",
       " '23',\n",
       " '0 2 11 21',\n",
       " '0 2',\n",
       " '0 25',\n",
       " '0 5',\n",
       " '21 25',\n",
       " '0 25',\n",
       " '0 25 26',\n",
       " '23',\n",
       " '13 25',\n",
       " '0 25',\n",
       " '0 2 21 25',\n",
       " '14 16 17 25',\n",
       " '5 7',\n",
       " '12 14 16 21 25',\n",
       " '0 7 21 25',\n",
       " '18 19 21 25',\n",
       " '7',\n",
       " '7 11',\n",
       " '0 7',\n",
       " '18',\n",
       " '23',\n",
       " '0 21 25',\n",
       " '0 25',\n",
       " '0',\n",
       " '0 14 16 17 25',\n",
       " '25',\n",
       " '0 2 16',\n",
       " '21 25',\n",
       " '0 25',\n",
       " '11',\n",
       " '14 16 17',\n",
       " '0 16 21',\n",
       " '14 16 17 25',\n",
       " '14 25',\n",
       " '0 18 19 25',\n",
       " '6 11 23',\n",
       " '5',\n",
       " '2 7',\n",
       " '7 23',\n",
       " '0',\n",
       " '0',\n",
       " '0 26',\n",
       " '0 25',\n",
       " '25',\n",
       " '25',\n",
       " '0 25',\n",
       " '21 25 26',\n",
       " '0 2 3 25',\n",
       " '0 18 19 25',\n",
       " '12 25',\n",
       " '0',\n",
       " '0 25',\n",
       " '0 4 21',\n",
       " '0 21',\n",
       " '23',\n",
       " '4 18 19 25',\n",
       " '0 25',\n",
       " '0 16 19',\n",
       " '23',\n",
       " '11',\n",
       " '2 3',\n",
       " '0 23 25',\n",
       " '0 7',\n",
       " '5',\n",
       " '0 25',\n",
       " '14 16 17 18',\n",
       " '0 3 5 21 25',\n",
       " '0 11 23 25',\n",
       " '21 25',\n",
       " '0 13 14 16',\n",
       " '0 25',\n",
       " '25',\n",
       " '0 1 21 25',\n",
       " '6 11 21 25',\n",
       " '23 25',\n",
       " '25',\n",
       " '25',\n",
       " '0 21',\n",
       " '21 25',\n",
       " '21 25',\n",
       " '0 25',\n",
       " '0 25',\n",
       " '0 1 25',\n",
       " '0 25',\n",
       " '3',\n",
       " '0 19',\n",
       " '0 5',\n",
       " '0 2 21 25',\n",
       " '0 25',\n",
       " '0 5',\n",
       " '0',\n",
       " '0 1 3 5 19',\n",
       " '7 9 10',\n",
       " '26',\n",
       " '0 25',\n",
       " '0 16 21 25',\n",
       " '13 18 19 21 25',\n",
       " '0 21',\n",
       " '0 23 25',\n",
       " '0 25',\n",
       " '14 16 17',\n",
       " '14 17 21 25',\n",
       " '0 21 25',\n",
       " '0 19',\n",
       " '6 25',\n",
       " '0 2',\n",
       " '21',\n",
       " '0 18 19',\n",
       " '21',\n",
       " '0 21 23 25',\n",
       " '0 18',\n",
       " '0 1',\n",
       " '18 19 25',\n",
       " '0',\n",
       " '0 5 12 21',\n",
       " '0 17 18 25',\n",
       " '0 11 14 16 17',\n",
       " '0 5 21',\n",
       " '11 21',\n",
       " '3 5 25',\n",
       " '0 2 3 5',\n",
       " '0 5',\n",
       " '6 11',\n",
       " '0',\n",
       " '0',\n",
       " '23',\n",
       " '23 25',\n",
       " '6',\n",
       " '0 23 25',\n",
       " '0 2 5 25',\n",
       " '11 14 21 22',\n",
       " '0 25',\n",
       " '0 25 26',\n",
       " '12 21',\n",
       " '0 23',\n",
       " '0 23 25',\n",
       " '0 3 25',\n",
       " '6 25',\n",
       " '0 2 4 21',\n",
       " '5',\n",
       " '23',\n",
       " '12 21 25',\n",
       " '2 7 25',\n",
       " '0 1 7',\n",
       " '1 6',\n",
       " '20 26',\n",
       " '0 21 25',\n",
       " '0 25',\n",
       " '0 7',\n",
       " '0 21 25',\n",
       " '0 2 13 22',\n",
       " '23',\n",
       " '0 25',\n",
       " '0 14 16 17 25',\n",
       " '4',\n",
       " '0 25',\n",
       " '0 5',\n",
       " '19 21',\n",
       " '0 3',\n",
       " '19 25',\n",
       " '0 3 21',\n",
       " '0 5',\n",
       " '26',\n",
       " '0 7',\n",
       " '14',\n",
       " '21 25',\n",
       " '7',\n",
       " '0 2 25',\n",
       " '7 16',\n",
       " '25',\n",
       " '0',\n",
       " '7 23 25',\n",
       " '0 21 25',\n",
       " '0 3 5',\n",
       " '0 21 25',\n",
       " '0 21 25',\n",
       " '0 2 7 25',\n",
       " '0 25',\n",
       " '0 6 25',\n",
       " '11 18 19 25',\n",
       " '0 2 4',\n",
       " '4',\n",
       " '17 18 21 25',\n",
       " '14 16 17',\n",
       " '0 4 5 21',\n",
       " '0 3 21 22 25',\n",
       " '19',\n",
       " '21',\n",
       " '2 6 25',\n",
       " '0 21 25',\n",
       " '0 21 22',\n",
       " '0 21',\n",
       " '1 21 25',\n",
       " '25',\n",
       " '0 2 4 16',\n",
       " '7',\n",
       " '0 1 25',\n",
       " '21 25',\n",
       " '26',\n",
       " '0 25',\n",
       " '14 16 17 25',\n",
       " '0 2 3',\n",
       " '18 21 25',\n",
       " '4 21 25',\n",
       " '4 21',\n",
       " '0 25',\n",
       " '0 18 19',\n",
       " '0',\n",
       " '0 18 19',\n",
       " '0 11 25',\n",
       " '21 25',\n",
       " '7 16 18',\n",
       " '5 12',\n",
       " '7 18',\n",
       " '0 23',\n",
       " '0 25',\n",
       " '0 7',\n",
       " '7',\n",
       " '21 25',\n",
       " '0 12 14 21 25',\n",
       " '0 4 25',\n",
       " '0 4',\n",
       " '0 5 21 22',\n",
       " '0 25',\n",
       " '0 1 4',\n",
       " '0 16 17 18 25',\n",
       " '0 25',\n",
       " '0 21 25',\n",
       " '11',\n",
       " '0 1 7 14 16',\n",
       " '6 21 25',\n",
       " '3',\n",
       " '21 25',\n",
       " '0 2 3 5 23',\n",
       " '3',\n",
       " '5 18 25',\n",
       " '23 25',\n",
       " '5',\n",
       " '0 25',\n",
       " '0 2',\n",
       " '0 1 19',\n",
       " '0 2',\n",
       " '0 2',\n",
       " '5 7 25',\n",
       " '0 26',\n",
       " '0 18 21 25',\n",
       " '0 25',\n",
       " '23 25',\n",
       " ...]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit['Predicted'] = predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submit\n",
    "# submit = pd.read_csv('../data/sample_submission.csv')\n",
    "# predicted = []\n",
    "# draw_predict = []\n",
    "# # model.load_weights('../cache/InceptionV3.h5')\n",
    "# for name in tqdm(submit['Id']):\n",
    "#     path = os.path.join('../data/test/', name)\n",
    "#     image = data_generator.load_image(path, (SIZE,SIZE,3))/255.\n",
    "#     score_predict = model.predict(image[np.newaxis])[0]\n",
    "#     draw_predict.append(score_predict)\n",
    "#     label_predict = np.arange(28)[score_predict>=0.2]\n",
    "#     str_predict_label = ' '.join(str(l) for l in label_predict)\n",
    "#     predicted.append(str_predict_label)\n",
    "\n",
    "# submit['Predicted'] = predicted\n",
    "# np.save('../cache/draw_predict_InceptionV3-8.npy', score_predict)\n",
    "# submit.to_csv('../submissions/submit_InceptionV3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv('../submissions/sub12-a.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/1855095/how-to-create-a-zip-archive-of-a-directory\n",
    "def backup_project_as_zip(project_dir, zip_file):\n",
    "    assert(os.path.isdir(project_dir))\n",
    "    assert(os.path.isdir(os.path.dirname(zip_file)))\n",
    "    shutil.make_archive(zip_file.replace('.zip',''), 'zip', project_dir)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-10-25 06:10:33.481598\n"
     ]
    }
   ],
   "source": [
    "import datetime, shutil\n",
    "now = datetime.datetime.now()\n",
    "print(now)\n",
    "PROJECT_PATH = '/home/watts/lal/Kaggle/kagglehp/scripts_nbs'\n",
    "backup_project_as_zip(PROJECT_PATH, '../cache/code.scripts_nbs.%s.zip'%now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.4.7.1 / client 1.3.8)\n",
      "Successfully submitted to Human Protein Atlas Image ClassificationCPU times: user 306 ms, sys: 172 ms, total: 478 ms\n",
      "Wall time: 13.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!kaggle competitions submit -c human-protein-atlas-image-classification -f ../submissions/sub12-a.csv -m \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.4.7.1 / client 1.3.8)\n",
      "fileName     date                 description  status    publicScore  privateScore  \n",
      "-----------  -------------------  -----------  --------  -----------  ------------  \n",
      "sub12-a.csv  2018-10-25 00:40:56               complete  0.449        None          \n",
      "sub11-k.csv  2018-10-24 00:35:39               complete  0.346        None          \n",
      "sub11-j.csv  2018-10-24 00:34:46               complete  0.366        None          \n",
      "sub11-j.csv  2018-10-24 00:33:17               complete  0.000        None          \n",
      "sub11-i.csv  2018-10-24 00:24:24               complete  0.389        None          \n",
      "sub11-h.csv  2018-10-24 00:21:18               complete  0.371        None          \n",
      "sub11-g.csv  2018-10-23 09:13:19               complete  0.347        None          \n",
      "sub11-f.csv  2018-10-23 09:11:15               complete  0.358        None          \n",
      "sub11-b.csv  2018-10-23 05:25:32               complete  0.437        None          \n",
      "sub12.csv    2018-10-23 05:18:36               complete  0.436        None          \n",
      "sub11.csv    2018-10-23 01:07:18               complete  0.431        None          \n",
      "sub10.csv    2018-10-22 17:16:40               complete  0.336        None          \n",
      "sub9.csv     2018-10-21 20:04:09               complete  0.098        None          \n",
      "sub9.csv     2018-10-21 19:44:17               complete  0.073        None          \n",
      "sub9.csv     2018-10-21 19:37:30               complete  0.043        None          \n",
      "sub9.csv     2018-10-21 19:27:51               complete  0.000        None          \n",
      "sub8.csv     2018-10-20 20:08:45               complete  0.422        None          \n",
      "sub7.csv     2018-10-20 17:06:09               complete  0.389        None          \n",
      "sub5.csv     2018-10-19 18:27:33               complete  0.387        None          \n",
      "sub4.csv     2018-10-19 14:45:15               complete  0.411        None          \n"
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "sleep(10)\n",
    "!kaggle competitions submissions -c human-protein-atlas-image-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11702/11702 [00:00<00:00, 81492.96it/s]\n"
     ]
    }
   ],
   "source": [
    "predicted = []\n",
    "for line in tqdm(sub_class_preds):\n",
    "    label_predict = np.arange(28)[line>=0.25]\n",
    "    str_predict_label = ' '.join(str(l) for l in label_predict)\n",
    "    predicted.append(str_predict_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit['Predicted'] = predicted\n",
    "submit.to_csv('../submissions/sub12-b.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-10-25 06:11:26.291663\n"
     ]
    }
   ],
   "source": [
    "import datetime, shutil\n",
    "now = datetime.datetime.now()\n",
    "print(now)\n",
    "PROJECT_PATH = '/home/watts/lal/Kaggle/kagglehp/scripts_nbs'\n",
    "backup_project_as_zip(PROJECT_PATH, '../cache/code.scripts_nbs.%s.zip'%now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.4.7.1 / client 1.3.8)\n",
      "Successfully submitted to Human Protein Atlas Image ClassificationCPU times: user 267 ms, sys: 217 ms, total: 484 ms\n",
      "Wall time: 13.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!kaggle competitions submit -c human-protein-atlas-image-classification -f ../submissions/sub12-b.csv -m \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.4.7.1 / client 1.3.8)\r\n",
      "fileName     date                 description  status    publicScore  privateScore  \r\n",
      "-----------  -------------------  -----------  --------  -----------  ------------  \r\n",
      "sub12-b.csv  2018-10-25 00:41:50               complete  0.457        None          \r\n",
      "sub12-a.csv  2018-10-25 00:40:56               complete  0.449        None          \r\n",
      "sub11-k.csv  2018-10-24 00:35:39               complete  0.346        None          \r\n",
      "sub11-j.csv  2018-10-24 00:34:46               complete  0.366        None          \r\n",
      "sub11-j.csv  2018-10-24 00:33:17               complete  0.000        None          \r\n",
      "sub11-i.csv  2018-10-24 00:24:24               complete  0.389        None          \r\n",
      "sub11-h.csv  2018-10-24 00:21:18               complete  0.371        None          \r\n",
      "sub11-g.csv  2018-10-23 09:13:19               complete  0.347        None          \r\n",
      "sub11-f.csv  2018-10-23 09:11:15               complete  0.358        None          \r\n",
      "sub11-b.csv  2018-10-23 05:25:32               complete  0.437        None          \r\n",
      "sub12.csv    2018-10-23 05:18:36               complete  0.436        None          \r\n",
      "sub11.csv    2018-10-23 01:07:18               complete  0.431        None          \r\n",
      "sub10.csv    2018-10-22 17:16:40               complete  0.336        None          \r\n",
      "sub9.csv     2018-10-21 20:04:09               complete  0.098        None          \r\n",
      "sub9.csv     2018-10-21 19:44:17               complete  0.073        None          \r\n",
      "sub9.csv     2018-10-21 19:37:30               complete  0.043        None          \r\n",
      "sub9.csv     2018-10-21 19:27:51               complete  0.000        None          \r\n",
      "sub8.csv     2018-10-20 20:08:45               complete  0.422        None          \r\n",
      "sub7.csv     2018-10-20 17:06:09               complete  0.389        None          \r\n",
      "sub5.csv     2018-10-19 18:27:33               complete  0.387        None          \r\n"
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "sleep(10)\n",
    "!kaggle competitions submissions -c human-protein-atlas-image-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {0.3:'bb', 0.35:'c', 0.4:'d', 0.45:'e', 0.5:'f'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11702/11702 [00:00<00:00, 87915.69it/s]\n",
      "100%|██████████| 11702/11702 [00:00<00:00, 93076.31it/s]\n",
      "  0%|          | 0/11702 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../submissions/sub12-bb.csv\n",
      "../submissions/sub12-c.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11702/11702 [00:00<00:00, 98104.04it/s]\n",
      "100%|██████████| 11702/11702 [00:00<00:00, 96662.13it/s]\n",
      "  0%|          | 0/11702 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../submissions/sub12-d.csv\n",
      "../submissions/sub12-e.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11702/11702 [00:00<00:00, 98385.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../submissions/sub12-f.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for alpha in [0.3, 0.35, 0.4, 0.45, 0.5]:\n",
    "    predicted = []\n",
    "    for line in tqdm(sub_class_preds):\n",
    "        label_predict = np.arange(28)[line>=alpha]\n",
    "        str_predict_label = ' '.join(str(l) for l in label_predict)\n",
    "        predicted.append(str_predict_label)\n",
    "    submit['Predicted'] = predicted\n",
    "    name = '../submissions/sub12-' + d[alpha] + '.csv'\n",
    "    print(name)\n",
    "    submit.to_csv(name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.4.7.1 / client 1.3.8)\n",
      "Successfully submitted to Human Protein Atlas Image ClassificationCPU times: user 290 ms, sys: 216 ms, total: 506 ms\n",
      "Wall time: 13.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!kaggle competitions submit -c human-protein-atlas-image-classification -f ../submissions/sub12-bb.csv -m \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.4.7.1 / client 1.3.8)\r\n",
      "fileName      date                 description  status    publicScore  privateScore  \r\n",
      "------------  -------------------  -----------  --------  -----------  ------------  \r\n",
      "sub12-bb.csv  2018-10-25 00:43:34               complete  0.466        None          \r\n",
      "sub12-b.csv   2018-10-25 00:41:50               complete  0.457        None          \r\n",
      "sub12-a.csv   2018-10-25 00:40:56               complete  0.449        None          \r\n",
      "sub11-k.csv   2018-10-24 00:35:39               complete  0.346        None          \r\n",
      "sub11-j.csv   2018-10-24 00:34:46               complete  0.366        None          \r\n",
      "sub11-j.csv   2018-10-24 00:33:17               complete  0.000        None          \r\n",
      "sub11-i.csv   2018-10-24 00:24:24               complete  0.389        None          \r\n",
      "sub11-h.csv   2018-10-24 00:21:18               complete  0.371        None          \r\n",
      "sub11-g.csv   2018-10-23 09:13:19               complete  0.347        None          \r\n",
      "sub11-f.csv   2018-10-23 09:11:15               complete  0.358        None          \r\n",
      "sub11-b.csv   2018-10-23 05:25:32               complete  0.437        None          \r\n",
      "sub12.csv     2018-10-23 05:18:36               complete  0.436        None          \r\n",
      "sub11.csv     2018-10-23 01:07:18               complete  0.431        None          \r\n",
      "sub10.csv     2018-10-22 17:16:40               complete  0.336        None          \r\n",
      "sub9.csv      2018-10-21 20:04:09               complete  0.098        None          \r\n",
      "sub9.csv      2018-10-21 19:44:17               complete  0.073        None          \r\n",
      "sub9.csv      2018-10-21 19:37:30               complete  0.043        None          \r\n",
      "sub9.csv      2018-10-21 19:27:51               complete  0.000        None          \r\n",
      "sub8.csv      2018-10-20 20:08:45               complete  0.422        None          \r\n",
      "sub7.csv      2018-10-20 17:06:09               complete  0.389        None          \r\n"
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "sleep(10)\n",
    "!kaggle competitions submissions -c human-protein-atlas-image-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.4.7.1 / client 1.3.8)\n",
      "Successfully submitted to Human Protein Atlas Image ClassificationWarning: Looks like you're using an outdated API Version, please consider updating (server 1.4.7.1 / client 1.3.8)\n",
      "fileName      date                 description  status    publicScore  privateScore  \n",
      "------------  -------------------  -----------  --------  -----------  ------------  \n",
      "sub12-c.csv   2018-10-25 00:45:32               complete  0.469        None          \n",
      "sub12-bb.csv  2018-10-25 00:43:34               complete  0.466        None          \n",
      "sub12-b.csv   2018-10-25 00:41:50               complete  0.457        None          \n",
      "sub12-a.csv   2018-10-25 00:40:56               complete  0.449        None          \n",
      "sub11-k.csv   2018-10-24 00:35:39               complete  0.346        None          \n",
      "sub11-j.csv   2018-10-24 00:34:46               complete  0.366        None          \n",
      "sub11-j.csv   2018-10-24 00:33:17               complete  0.000        None          \n",
      "sub11-i.csv   2018-10-24 00:24:24               complete  0.389        None          \n",
      "sub11-h.csv   2018-10-24 00:21:18               complete  0.371        None          \n",
      "sub11-g.csv   2018-10-23 09:13:19               complete  0.347        None          \n",
      "sub11-f.csv   2018-10-23 09:11:15               complete  0.358        None          \n",
      "sub11-b.csv   2018-10-23 05:25:32               complete  0.437        None          \n",
      "sub12.csv     2018-10-23 05:18:36               complete  0.436        None          \n",
      "sub11.csv     2018-10-23 01:07:18               complete  0.431        None          \n",
      "sub10.csv     2018-10-22 17:16:40               complete  0.336        None          \n",
      "sub9.csv      2018-10-21 20:04:09               complete  0.098        None          \n",
      "sub9.csv      2018-10-21 19:44:17               complete  0.073        None          \n",
      "sub9.csv      2018-10-21 19:37:30               complete  0.043        None          \n",
      "sub9.csv      2018-10-21 19:27:51               complete  0.000        None          \n",
      "sub8.csv      2018-10-20 20:08:45               complete  0.422        None          \n",
      "CPU times: user 344 ms, sys: 330 ms, total: 675 ms\n",
      "Wall time: 26.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!kaggle competitions submit -c human-protein-atlas-image-classification -f ../submissions/sub12-c.csv -m \"\"\n",
    "from time import sleep\n",
    "sleep(10)\n",
    "!kaggle competitions submissions -c human-protein-atlas-image-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31072, 28)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof_class_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00070df0-bbc3-11e8-b2bc-ac1f6b6435d0</td>\n",
       "      <td>16 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000a6c98-bb9b-11e8-b2b9-ac1f6b6435d0</td>\n",
       "      <td>7 1 2 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000a9596-bbc4-11e8-b2bc-ac1f6b6435d0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000c99ba-bba4-11e8-b2b9-ac1f6b6435d0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001838f8-bbca-11e8-b2bc-ac1f6b6435d0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Id   Target\n",
       "0  00070df0-bbc3-11e8-b2bc-ac1f6b6435d0     16 0\n",
       "1  000a6c98-bb9b-11e8-b2b9-ac1f6b6435d0  7 1 2 0\n",
       "2  000a9596-bbc4-11e8-b2bc-ac1f6b6435d0        5\n",
       "3  000c99ba-bba4-11e8-b2b9-ac1f6b6435d0        1\n",
       "4  001838f8-bbca-11e8-b2bc-ac1f6b6435d0       18"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31072, 2)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31072, 28)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_classes = 28\n",
    "y_train = np.zeros(oof_class_preds.shape)\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31072/31072 [00:00<00:00, 741901.66it/s]\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "for labels in tqdm(data['Target'].str.split(' ')):\n",
    "#     print(labels)\n",
    "    for label in labels:\n",
    "        y_train[idx][int(label)] = 1\n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 1., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 1., 0., 0.],\n",
       "       [1., 0., 1., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001 0.6174081518752018\n",
      "0.01 0.6174081494907646\n",
      "0.1 0.6174079419635514\n",
      "0.5 0.6174049197331472\n",
      "0.75 0.6174023910597577\n",
      "1.0 0.6173997536697944\n",
      "------------------\n",
      "0.001 0.7042131450176463\n",
      "0.01 0.7042131449021258\n",
      "0.1 0.7042131341504188\n",
      "0.5 0.7042129258072632\n",
      "0.75 0.7042126913081677\n",
      "1.0 0.7042123865546952\n",
      "------------------\n",
      "0.001 0.6405293650278552\n",
      "0.01 0.6405293643199262\n",
      "0.1 0.6405293035770623\n",
      "0.5 0.6405284696126301\n",
      "0.75 0.6405278129689744\n",
      "1.0 0.6405271539313317\n",
      "------------------\n",
      "0.001 0.5206868082561187\n",
      "0.01 0.5206868064937693\n",
      "0.1 0.5206866550090807\n",
      "0.5 0.5206845661735036\n",
      "0.75 0.5206829204240566\n",
      "1.0 0.5206812723936773\n",
      "------------------\n",
      "0.001 0.6225629182679313\n",
      "0.01 0.6225628870674288\n",
      "0.1 0.6225602493284829\n",
      "0.5 0.6225265347174933\n",
      "0.75 0.6225024258166685\n",
      "1.0 0.6224802007531789\n",
      "------------------\n",
      "0.001 0.47625033808763034\n",
      "0.01 0.4762503310360723\n",
      "0.1 0.47624973372408597\n",
      "0.5 0.4762420258070793\n",
      "0.75 0.4762364393569697\n",
      "1.0 0.47623122503579396\n",
      "------------------\n",
      "0.001 0.37015383088158105\n",
      "0.01 0.37015383051625794\n",
      "0.1 0.37015379589885844\n",
      "0.5 0.370153120483382\n",
      "0.75 0.3701523989904022\n",
      "1.0 0.3701515220047934\n",
      "------------------\n",
      "0.001 0.6278499957612576\n",
      "0.01 0.6278499933196181\n",
      "0.1 0.6278497675145762\n",
      "0.5 0.6278457789099899\n",
      "0.75 0.6278419420023433\n",
      "1.0 0.627837666925348\n",
      "------------------\n",
      "0.001 0.23972549325385814\n",
      "0.01 0.23972546015299\n",
      "0.1 0.23972230652354265\n",
      "0.5 0.2396593031542591\n",
      "0.75 0.23959034757832143\n",
      "1.0 0.23950497349498\n",
      "------------------\n",
      "0.001 0.31331172323399825\n",
      "0.01 0.3133113149919019\n",
      "0.1 0.3132732609784179\n",
      "0.5 0.3125863700441769\n",
      "0.75 0.3119170265340445\n",
      "1.0 0.31116713928425954\n",
      "------------------\n",
      "0.001 0.2558623247962669\n",
      "0.01 0.255861948626774\n",
      "0.1 0.2558268879333644\n",
      "0.5 0.2551944259969803\n",
      "0.75 0.254578676028139\n",
      "1.0 0.2538894622998168\n",
      "------------------\n",
      "0.001 0.5968983087672983\n",
      "0.01 0.5968983084398413\n",
      "0.1 0.5968982782239397\n",
      "0.5 0.5968977292368627\n",
      "0.75 0.5968971633273094\n",
      "1.0 0.5968964809073818\n",
      "------------------\n",
      "0.001 0.49290871329017727\n",
      "0.01 0.49290871298539585\n",
      "0.1 0.4929086845398815\n",
      "0.5 0.49290813804804207\n",
      "0.75 0.49290753815710786\n",
      "1.0 0.49290677775529046\n",
      "------------------\n",
      "0.001 0.3787539379466851\n",
      "0.01 0.37875392012227116\n",
      "0.1 0.37875241060554954\n",
      "0.5 0.3787329277123833\n",
      "0.75 0.37871876766614176\n",
      "1.0 0.37870547804838306\n",
      "------------------\n",
      "0.001 0.7506973147934757\n",
      "0.01 0.7506973136319354\n",
      "0.1 0.7506972086330781\n",
      "0.5 0.7506954269694857\n",
      "0.75 0.7506936901241192\n",
      "1.0 0.7506916736611128\n",
      "------------------\n",
      "0.001 0.01983763392161686\n",
      "0.01 0.019837535325928135\n",
      "0.1 0.019828450862805713\n",
      "0.5 0.019665777176268495\n",
      "0.75 0.01950321718332293\n",
      "1.0 0.019314882518966292\n",
      "------------------\n",
      "0.001 0.1751297622786967\n",
      "0.01 0.17512974759033484\n",
      "0.1 0.17512846022244855\n",
      "0.5 0.17510915339406974\n",
      "0.75 0.17509248192232651\n",
      "1.0 0.17507468614395694\n",
      "------------------\n",
      "0.001 0.1667931781498947\n",
      "0.01 0.16679317509693092\n",
      "0.1 0.1667928880710675\n",
      "0.5 0.1667873460571777\n",
      "0.75 0.1667814074139947\n",
      "1.0 0.16677415822966601\n",
      "------------------\n",
      "0.001 0.3087568657202341\n",
      "0.01 0.3087568642759011\n",
      "0.1 0.3087567290489941\n",
      "0.5 0.3087542387474458\n",
      "0.75 0.30875175512550346\n",
      "1.0 0.3087489153085835\n",
      "------------------\n",
      "0.001 0.38082130482961174\n",
      "0.01 0.380821304671176\n",
      "0.1 0.38082128970689655\n",
      "0.5 0.38082100099719085\n",
      "0.75 0.38082069536892904\n",
      "1.0 0.3808203259166289\n",
      "------------------\n",
      "0.001 0.1538312914148493\n",
      "0.01 0.15383122528024018\n",
      "0.1 0.1538250686849436\n",
      "0.5 0.15371444612700225\n",
      "0.75 0.15360709884995571\n",
      "1.0 0.15348721808287602\n",
      "------------------\n",
      "0.001 0.48557824579010384\n",
      "0.01 0.48557824528334803\n",
      "0.1 0.4855781985932974\n",
      "0.5 0.48557738349917456\n",
      "0.75 0.48557660601055197\n",
      "1.0 0.48557574340418097\n",
      "------------------\n",
      "0.001 0.3646582386899322\n",
      "0.01 0.3646582372378981\n",
      "0.1 0.364658112376793\n",
      "0.5 0.36465637881526125\n",
      "0.75 0.3646549894024714\n",
      "1.0 0.364653566661458\n",
      "------------------\n",
      "0.001 0.6577178864298491\n",
      "0.01 0.6577178855069651\n",
      "0.1 0.6577177994042775\n",
      "0.5 0.6577162388191071\n",
      "0.75 0.657714710592422\n",
      "1.0 0.6577129906824652\n",
      "------------------\n",
      "0.001 0.48347736718545864\n",
      "0.01 0.4834773624770783\n",
      "0.1 0.4834769405428032\n",
      "0.5 0.4834700745036658\n",
      "0.75 0.48346367708679355\n",
      "1.0 0.483456474479732\n",
      "------------------\n",
      "0.001 0.43786458026883995\n",
      "0.01 0.43786457972979137\n",
      "0.1 0.4378645337127519\n",
      "0.5 0.4378639170133599\n",
      "0.75 0.4378634463465395\n",
      "1.0 0.43786298621777675\n",
      "------------------\n",
      "0.001 0.21837253521077882\n",
      "0.01 0.2183724949425644\n",
      "0.1 0.21836905357883252\n",
      "0.5 0.21832290898991366\n",
      "0.75 0.21828791269733872\n",
      "1.0 0.21825408221249284\n",
      "------------------\n",
      "0.001 0.0019063946880274463\n",
      "0.01 0.0019063937044974109\n",
      "0.1 0.0019063073388934093\n",
      "0.5 0.0019050204660372438\n",
      "0.75 0.0019039365114243976\n",
      "1.0 0.0019028140324179876\n",
      "------------------\n"
     ]
    }
   ],
   "source": [
    "sub_ridge_preds = np.zeros(sub_class_preds.shape)\n",
    "from sklearn.linear_model import Ridge\n",
    "for cls in np.arange(n_classes):\n",
    "    for alpha in [0.001, 0.01, 0.1, 0.5, 0.75, 1.0]:\n",
    "        y = y_train[:, cls]\n",
    "        X = oof_class_preds\n",
    "        clf = Ridge(alpha=alpha)\n",
    "        clf.fit(X,y)\n",
    "        score_ = clf.score(X, y)\n",
    "        print(alpha, score_)\n",
    "    print('------------------')\n",
    "#         X_test = sub_class_preds[:, cls]\n",
    "#         preds_ = clf.predict(X_test)\n",
    "#         sub_ridge_preds[:,cls] = preds_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_ridge_preds = np.zeros(sub_class_preds.shape)\n",
    "from sklearn.linear_model import Ridge\n",
    "for cls in np.arange(n_classes):\n",
    "    y = y_train[:, cls]\n",
    "    X = oof_class_preds\n",
    "    clf = Ridge(alpha=0.1)\n",
    "    clf.fit(X,y)\n",
    "    X_test = sub_class_preds\n",
    "    preds_ = clf.predict(X_test)\n",
    "    sub_ridge_preds[:,cls] = preds_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.38001867e-02, 1.59430779e-04, 9.98871672e-01, ...,\n",
       "        1.77784316e-03, 1.12266340e-04, 5.20836841e-09],\n",
       "       [2.47062426e-02, 2.68127583e-04, 7.85995722e-04, ...,\n",
       "        6.51888692e-01, 8.71524611e-04, 3.26655725e-05],\n",
       "       [8.41529155e-01, 2.72278007e-04, 3.96186303e-03, ...,\n",
       "        9.23864961e-01, 2.01543609e-03, 1.92988443e-05],\n",
       "       ...,\n",
       "       [6.59056642e-04, 5.12143007e-05, 3.49444263e-05, ...,\n",
       "        1.77463120e-03, 5.20864920e-08, 5.91902866e-09],\n",
       "       [5.01914832e-01, 9.99162483e-01, 2.73049554e-03, ...,\n",
       "        1.16331837e-02, 1.53418808e-04, 1.20560289e-06],\n",
       "       [5.07521251e-01, 3.52088286e-04, 3.01849514e-03, ...,\n",
       "        6.92711103e-01, 1.99362053e-03, 1.05607675e-06]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_class_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11702,)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_class_preds[:, 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.26424064e-01,  8.84581981e-03,  8.85833838e-01, ...,\n",
       "         3.20592330e-02,  4.54385428e-03, -6.92529375e-05],\n",
       "       [ 5.51528260e-02,  2.13827355e-03,  1.63897473e-02, ...,\n",
       "         5.38178358e-01,  1.06812025e-03,  1.39571143e-03],\n",
       "       [ 7.77233272e-01, -1.67743788e-03,  1.87791802e-02, ...,\n",
       "         7.51411388e-01, -1.45306321e-03,  1.27131495e-03],\n",
       "       ...,\n",
       "       [ 2.62432560e-02,  4.66381707e-04,  7.97892029e-03, ...,\n",
       "         2.92185935e-02,  3.12140745e-03,  1.76712611e-04],\n",
       "       [ 4.95625470e-01,  8.71181686e-01,  1.99755452e-02, ...,\n",
       "         3.70837162e-02,  3.03441473e-03,  3.03600332e-05],\n",
       "       [ 4.96285545e-01,  1.04218405e-02,  2.67882221e-02, ...,\n",
       "         5.85205684e-01,  4.37290352e-03,  1.52204091e-06]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_ridge_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11702/11702 [00:00<00:00, 88242.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../submissions/sub12-g.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "predicted = []\n",
    "alpha = 0.35\n",
    "for line in tqdm(sub_ridge_preds):\n",
    "    label_predict = np.arange(28)[line>=alpha]\n",
    "    str_predict_label = ' '.join(str(l) for l in label_predict)\n",
    "    predicted.append(str_predict_label)\n",
    "submit['Predicted'] = predicted\n",
    "name = '../submissions/sub12-g.csv'\n",
    "print(name)\n",
    "submit.to_csv(name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.4.7.1 / client 1.3.8)\n",
      "Successfully submitted to Human Protein Atlas Image ClassificationCPU times: user 372 ms, sys: 201 ms, total: 573 ms\n",
      "Wall time: 17.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!kaggle competitions submit -c human-protein-atlas-image-classification -f ../submissions/sub12-g.csv -m \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.4.7.1 / client 1.3.8)\r\n",
      "fileName      date                 description  status    publicScore  privateScore  \r\n",
      "------------  -------------------  -----------  --------  -----------  ------------  \r\n",
      "sub12-g.csv   2018-10-25 00:55:10               complete  0.433        None          \r\n",
      "sub12-c.csv   2018-10-25 00:45:32               complete  0.469        None          \r\n",
      "sub12-bb.csv  2018-10-25 00:43:34               complete  0.466        None          \r\n",
      "sub12-b.csv   2018-10-25 00:41:50               complete  0.457        None          \r\n",
      "sub12-a.csv   2018-10-25 00:40:56               complete  0.449        None          \r\n",
      "sub11-k.csv   2018-10-24 00:35:39               complete  0.346        None          \r\n",
      "sub11-j.csv   2018-10-24 00:34:46               complete  0.366        None          \r\n",
      "sub11-j.csv   2018-10-24 00:33:17               complete  0.000        None          \r\n",
      "sub11-i.csv   2018-10-24 00:24:24               complete  0.389        None          \r\n",
      "sub11-h.csv   2018-10-24 00:21:18               complete  0.371        None          \r\n",
      "sub11-g.csv   2018-10-23 09:13:19               complete  0.347        None          \r\n",
      "sub11-f.csv   2018-10-23 09:11:15               complete  0.358        None          \r\n",
      "sub11-b.csv   2018-10-23 05:25:32               complete  0.437        None          \r\n",
      "sub12.csv     2018-10-23 05:18:36               complete  0.436        None          \r\n",
      "sub11.csv     2018-10-23 01:07:18               complete  0.431        None          \r\n",
      "sub10.csv     2018-10-22 17:16:40               complete  0.336        None          \r\n",
      "sub9.csv      2018-10-21 20:04:09               complete  0.098        None          \r\n",
      "sub9.csv      2018-10-21 19:44:17               complete  0.073        None          \r\n",
      "sub9.csv      2018-10-21 19:37:30               complete  0.043        None          \r\n",
      "sub9.csv      2018-10-21 19:27:51               complete  0.000        None          \r\n"
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "sleep(10)\n",
    "!kaggle competitions submissions -c human-protein-atlas-image-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11702/11702 [00:00<00:00, 79991.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../submissions/sub12-h.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "predicted = []\n",
    "alpha = 0.4\n",
    "for line in tqdm(sub_ridge_preds):\n",
    "    label_predict = np.arange(28)[line>=alpha]\n",
    "    str_predict_label = ' '.join(str(l) for l in label_predict)\n",
    "    predicted.append(str_predict_label)\n",
    "submit['Predicted'] = predicted\n",
    "name = '../submissions/sub12-h.csv'\n",
    "print(name)\n",
    "submit.to_csv(name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.0 / client 1.3.8)\n",
      "Successfully submitted to Human Protein Atlas Image ClassificationWarning: Looks like you're using an outdated API Version, please consider updating (server 1.5.0 / client 1.3.8)\n",
      "fileName      date                 description  status    publicScore  privateScore  \n",
      "------------  -------------------  -----------  --------  -----------  ------------  \n",
      "sub12-h.csv   2018-10-26 02:07:56               complete  0.389        None          \n",
      "sub12-g.csv   2018-10-25 00:55:10               complete  0.433        None          \n",
      "sub12-c.csv   2018-10-25 00:45:32               complete  0.469        None          \n",
      "sub12-bb.csv  2018-10-25 00:43:34               complete  0.466        None          \n",
      "sub12-b.csv   2018-10-25 00:41:50               complete  0.457        None          \n",
      "sub12-a.csv   2018-10-25 00:40:56               complete  0.449        None          \n",
      "sub11-k.csv   2018-10-24 00:35:39               complete  0.346        None          \n",
      "sub11-j.csv   2018-10-24 00:34:46               complete  0.366        None          \n",
      "sub11-j.csv   2018-10-24 00:33:17               complete  0.000        None          \n",
      "sub11-i.csv   2018-10-24 00:24:24               complete  0.389        None          \n",
      "sub11-h.csv   2018-10-24 00:21:18               complete  0.371        None          \n",
      "sub11-g.csv   2018-10-23 09:13:19               complete  0.347        None          \n",
      "sub11-f.csv   2018-10-23 09:11:15               complete  0.358        None          \n",
      "sub11-b.csv   2018-10-23 05:25:32               complete  0.437        None          \n",
      "sub12.csv     2018-10-23 05:18:36               complete  0.436        None          \n",
      "sub11.csv     2018-10-23 01:07:18               complete  0.431        None          \n",
      "sub10.csv     2018-10-22 17:16:40               complete  0.336        None          \n",
      "sub9.csv      2018-10-21 20:04:09               complete  0.098        None          \n",
      "sub9.csv      2018-10-21 19:44:17               complete  0.073        None          \n",
      "sub9.csv      2018-10-21 19:37:30               complete  0.043        None          \n",
      "CPU times: user 328 ms, sys: 282 ms, total: 610 ms\n",
      "Wall time: 24.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!kaggle competitions submit -c human-protein-atlas-image-classification -f ../submissions/sub12-h.csv -m \"\"\n",
    "from time import sleep\n",
    "sleep(10)\n",
    "!kaggle competitions submissions -c human-protein-atlas-image-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.0 / client 1.3.8)\n",
      "Successfully submitted to Human Protein Atlas Image ClassificationWarning: Looks like you're using an outdated API Version, please consider updating (server 1.5.0 / client 1.3.8)\n",
      "fileName      date                 description  status    publicScore  privateScore  \n",
      "------------  -------------------  -----------  --------  -----------  ------------  \n",
      "sub12-d.csv   2018-10-26 02:09:32               complete  0.466        None          \n",
      "sub12-h.csv   2018-10-26 02:07:56               complete  0.389        None          \n",
      "sub12-g.csv   2018-10-25 00:55:10               complete  0.433        None          \n",
      "sub12-c.csv   2018-10-25 00:45:32               complete  0.469        None          \n",
      "sub12-bb.csv  2018-10-25 00:43:34               complete  0.466        None          \n",
      "sub12-b.csv   2018-10-25 00:41:50               complete  0.457        None          \n",
      "sub12-a.csv   2018-10-25 00:40:56               complete  0.449        None          \n",
      "sub11-k.csv   2018-10-24 00:35:39               complete  0.346        None          \n",
      "sub11-j.csv   2018-10-24 00:34:46               complete  0.366        None          \n",
      "sub11-j.csv   2018-10-24 00:33:17               complete  0.000        None          \n",
      "sub11-i.csv   2018-10-24 00:24:24               complete  0.389        None          \n",
      "sub11-h.csv   2018-10-24 00:21:18               complete  0.371        None          \n",
      "sub11-g.csv   2018-10-23 09:13:19               complete  0.347        None          \n",
      "sub11-f.csv   2018-10-23 09:11:15               complete  0.358        None          \n",
      "sub11-b.csv   2018-10-23 05:25:32               complete  0.437        None          \n",
      "sub12.csv     2018-10-23 05:18:36               complete  0.436        None          \n",
      "sub11.csv     2018-10-23 01:07:18               complete  0.431        None          \n",
      "sub10.csv     2018-10-22 17:16:40               complete  0.336        None          \n",
      "sub9.csv      2018-10-21 20:04:09               complete  0.098        None          \n",
      "sub9.csv      2018-10-21 19:44:17               complete  0.073        None          \n",
      "CPU times: user 352 ms, sys: 328 ms, total: 680 ms\n",
      "Wall time: 26.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!kaggle competitions submit -c human-protein-atlas-image-classification -f ../submissions/sub12-d.csv -m \"\"\n",
    "from time import sleep\n",
    "sleep(10)\n",
    "!kaggle competitions submissions -c human-protein-atlas-image-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hpg",
   "language": "python",
   "name": "hpg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
