{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/mathormad/inceptionv3-baseline-lb-0-379/code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.io\n",
    "from skimage.transform import resize\n",
    "from imgaug import augmenters as iaa\n",
    "from tqdm import tqdm\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from sklearn.utils import class_weight, shuffle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "SIZE = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/rejpalcz/best-loss-function-for-f1-score-metric/notebook\n",
    "import tensorflow as tf\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    y_pred = K.round(y_pred)\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n",
    "\n",
    "def f1_loss(y_true, y_pred):\n",
    "    \n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(K.binary_crossentropy(y_true, y_pred), axis=-1) + (1 - K.mean(f1))\n",
    "\n",
    "# POS_WEIGHT = 1.0  # multiplier for positive targets, needs to be tuned\n",
    "\n",
    "# def weighted_binary_crossentropy(target, output):\n",
    "#     \"\"\"\n",
    "#     Weighted binary crossentropy between an output tensor \n",
    "#     and a target tensor. POS_WEIGHT is used as a multiplier \n",
    "#     for the positive targets.\n",
    "\n",
    "#     Combination of the following functions:\n",
    "#     * keras.losses.binary_crossentropy\n",
    "#     * keras.backend.tensorflow_backend.binary_crossentropy\n",
    "#     * tf.nn.weighted_cross_entropy_with_logits\n",
    "#     \"\"\"\n",
    "#     # transform back to logits\n",
    "# #     _epsilon = tfb._to_tensor(tfb.epsilon(), output.dtype.base_dtype)\n",
    "#     _epsilon = K.epsilon()\n",
    "#     output = tf.clip_by_value(output, _epsilon, 1 - _epsilon)\n",
    "#     output = tf.log(output / (1 - output))\n",
    "#     # compute weighted loss\n",
    "#     loss = tf.nn.weighted_cross_entropy_with_logits(targets=target,\n",
    "#                                                     logits=output,\n",
    "#                                                     pos_weight=POS_WEIGHT)\n",
    "#     return tf.reduce_mean(loss, axis=-1)\n",
    "\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.python.framework import ops\n",
    "# from functools import reduce\n",
    "\n",
    "# def binaryRound(x):\n",
    "#     \"\"\"\n",
    "#     Rounds a tensor whose values are in [0,1] to a tensor with values in {0, 1},\n",
    "#     using the straight through estimator for the gradient.\n",
    "#     \"\"\"\n",
    "#     g = tf.get_default_graph()\n",
    "\n",
    "#     with ops.name_scope(\"BinaryRound\") as name:\n",
    "#         with g.gradient_override_map({\"Round\": \"Identity\"}):\n",
    "#             return tf.round(x, name=name)\n",
    "\n",
    "#         # For Tensorflow v0.11 and below use:\n",
    "#         #with g.gradient_override_map({\"Floor\": \"Identity\"}):\n",
    "#         #    return tf.round(x, name=name)\n",
    "        \n",
    "# def f1_loss2(y_true, y_pred):\n",
    "#     y_pred = binaryRound(y_pred)\n",
    "#     tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "#     tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "#     fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "#     fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "#     p = tp / (tp + fp + K.epsilon())\n",
    "#     r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "#     f1 = 2*p*r / (p+r+K.epsilon())\n",
    "#     f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "#     return K.mean(K.binary_crossentropy(y_true, y_pred), axis=-1) + (1-K.mean(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load dataset info\n",
    "path_to_train = '../data/train/'\n",
    "data = pd.read_csv('../data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00070df0-bbc3-11e8-b2bc-ac1f6b6435d0</td>\n",
       "      <td>16 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000a6c98-bb9b-11e8-b2b9-ac1f6b6435d0</td>\n",
       "      <td>7 1 2 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000a9596-bbc4-11e8-b2bc-ac1f6b6435d0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000c99ba-bba4-11e8-b2b9-ac1f6b6435d0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001838f8-bbca-11e8-b2bc-ac1f6b6435d0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Id   Target\n",
       "0  00070df0-bbc3-11e8-b2bc-ac1f6b6435d0     16 0\n",
       "1  000a6c98-bb9b-11e8-b2b9-ac1f6b6435d0  7 1 2 0\n",
       "2  000a9596-bbc4-11e8-b2bc-ac1f6b6435d0        5\n",
       "3  000c99ba-bba4-11e8-b2b9-ac1f6b6435d0        1\n",
       "4  001838f8-bbca-11e8-b2bc-ac1f6b6435d0       18"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dataset_info = []\n",
    "for name, labels in zip(data['Id'], data['Target'].str.split(' ')):\n",
    "    train_dataset_info.append({\n",
    "        'path':os.path.join(path_to_train, name),\n",
    "        'labels':np.array([int(label) for label in labels])})\n",
    "train_dataset_info = np.array(train_dataset_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ {'path': '../data/train/00070df0-bbc3-11e8-b2bc-ac1f6b6435d0', 'labels': array([16,  0])},\n",
       "       {'path': '../data/train/000a6c98-bb9b-11e8-b2b9-ac1f6b6435d0', 'labels': array([7, 1, 2, 0])},\n",
       "       {'path': '../data/train/000a9596-bbc4-11e8-b2bc-ac1f6b6435d0', 'labels': array([5])},\n",
       "       ...,\n",
       "       {'path': '../data/train/fff189d8-bbab-11e8-b2ba-ac1f6b6435d0', 'labels': array([7])},\n",
       "       {'path': '../data/train/fffdf7e0-bbc4-11e8-b2bc-ac1f6b6435d0', 'labels': array([25,  2, 21])},\n",
       "       {'path': '../data/train/fffe0ffe-bbc0-11e8-b2bb-ac1f6b6435d0', 'labels': array([2, 0])}], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11702/11702 [00:00<00:00, 198987.85it/s]\n"
     ]
    }
   ],
   "source": [
    "submit = pd.read_csv('../data/sample_submission.csv')\n",
    "path_to_test = '../data/test/'\n",
    "test_dataset_info = []\n",
    "for name in tqdm(submit['Id']):\n",
    "    test_dataset_info.append({\n",
    "        'path':os.path.join(path_to_test, name)})\n",
    "test_dataset_info = np.array(test_dataset_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# rgb_arr = np.memmap('../cache/tmp_rgb_arr', dtype='uint8', mode='r+', \n",
    "#                    shape=(len(train_dataset_info),299,299,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class data_generator:\n",
    "    \n",
    "    def create_train(dataset_info, batch_size, shape, augument=True):\n",
    "        assert shape[2] == 3\n",
    "        while True:\n",
    "            dataset_info = shuffle(dataset_info)\n",
    "            for start in range(0, len(dataset_info), batch_size):\n",
    "                end = min(start + batch_size, len(dataset_info))\n",
    "                batch_images = []\n",
    "                X_train_batch = dataset_info[start:end]\n",
    "                batch_labels = np.zeros((len(X_train_batch), 28))\n",
    "                for i in range(len(X_train_batch)):\n",
    "                    image = data_generator.load_image(\n",
    "                        X_train_batch[i]['path'], shape) \n",
    "#                     image = data_generator.load_image(\n",
    "#                         i, shape) \n",
    "                    if augument:\n",
    "                        image = data_generator.augment(image)\n",
    "                    batch_images.append(image/255.)\n",
    "                    batch_labels[i][X_train_batch[i]['labels']] = 1\n",
    "                yield np.array(batch_images, np.float32), batch_labels\n",
    "    def create_train2(dataset_info, batch_size, shape, augument=False):\n",
    "        assert shape[2] == 3\n",
    "        while True:\n",
    "            dataset_info = shuffle(dataset_info)\n",
    "            for start in range(0, len(dataset_info), batch_size):\n",
    "                end = min(start + batch_size, len(dataset_info))\n",
    "                batch_images = []\n",
    "                X_train_batch = dataset_info[start:end]\n",
    "                batch_labels = np.zeros((len(X_train_batch), 28))\n",
    "                for i in range(len(X_train_batch)):\n",
    "                    image = data_generator.load_image(\n",
    "                        X_train_batch[i]['path'], shape) \n",
    "#                     image = data_generator.load_image(\n",
    "#                         i, shape) \n",
    "                    \n",
    "                    batch_images.append(image/255.)\n",
    "                    \n",
    "                yield np.array(batch_images, np.float32), None\n",
    "    def create_test(dataset_info, batch_size, shape, augument=False):\n",
    "        assert shape[2] == 3\n",
    "        while True:\n",
    "            dataset_info = shuffle(dataset_info)\n",
    "            for start in range(0, len(dataset_info), batch_size):\n",
    "                end = min(start + batch_size, len(dataset_info))\n",
    "                batch_images = []\n",
    "                X_test_batch = dataset_info[start:end]\n",
    "                batch_labels = np.zeros((len(X_test_batch), 28))\n",
    "                for i in range(len(X_test_batch)):\n",
    "                    image = data_generator.load_image(\n",
    "                        X_test_batch[i]['path'], shape) \n",
    "#                     image = data_generator.load_image(\n",
    "#                         i, shape) \n",
    "                    \n",
    "                    batch_images.append(image/255.)\n",
    "                    \n",
    "                yield np.array(batch_images, np.float32), None\n",
    "    def load_image(path, shape):\n",
    "        img1 = cv2.imread(path+'_red.png', cv2.IMREAD_GRAYSCALE)\n",
    "        img2 = cv2.imread(path+'_green.png', cv2.IMREAD_GRAYSCALE)\n",
    "        img3 = cv2.imread(path+'_blue.png', cv2.IMREAD_GRAYSCALE)\n",
    "        image = np.stack((img1,img2,img3), -1)\n",
    "        image = cv2.resize(image, (shape[0], shape[1]))\n",
    "        return image\n",
    "    def load_image3(idx, shape):\n",
    "#         print(idx)\n",
    "        name = '../cache/RGB/img-{}.png'.format(idx)\n",
    "        image = cv2.imread(name)\n",
    "        image = cv2.resize(image, (shape[0], shape[1]))\n",
    "        return image\n",
    "    def load_image2(path, shape):\n",
    "        image_red_ch = Image.open(path+'_red.png')\n",
    "        image_yellow_ch = Image.open(path+'_yellow.png')\n",
    "        image_green_ch = Image.open(path+'_green.png')\n",
    "        image_blue_ch = Image.open(path+'_blue.png')\n",
    "        image = np.stack((\n",
    "            np.array(image_red_ch),\n",
    "            np.array(image_green_ch), \n",
    "            np.array(image_blue_ch)), -1)\n",
    "        w, h = 512, 512\n",
    "#         zero_data = np.zeros((h, w), dtype=np.uint8)\n",
    "#         image2 = np.stack((\n",
    "#             np.array(image_yellow_ch),\n",
    "#             zero_data, zero_data), -1)\n",
    "#         print(image1.shape, image2.shape)\n",
    "#         image = np.vstack((image1, image2))\n",
    "        image = cv2.resize(image, (shape[0], shape[1]))\n",
    "        return image\n",
    "    \n",
    "    def augment(image):\n",
    "        augment_img = iaa.Sequential([\n",
    "            iaa.OneOf([\n",
    "                iaa.Affine(rotate=0),\n",
    "                iaa.Affine(rotate=90),\n",
    "                iaa.Affine(rotate=180),\n",
    "                iaa.Affine(rotate=270),\n",
    "                iaa.Fliplr(0.5),\n",
    "                iaa.Flipud(0.5),\n",
    "            ])], random_order=True)\n",
    "\n",
    "        image_aug = augment_img.augment_image(image)\n",
    "        return image_aug\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, GlobalMaxPooling2D, BatchNormalization, Input, Conv2D\n",
    "from keras.layers import UpSampling2D, Lambda, Reshape, Conv2DTranspose\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import metrics\n",
    "from keras.optimizers import Adam \n",
    "from keras import backend as K\n",
    "import keras\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decoder_block(x,blocks=6,start_filters=512):\n",
    "    for i in range(blocks):\n",
    "        x = Conv2D(start_filters//(2**i),(3,3), activation='relu', padding='same')(x)\n",
    "        x = Conv2D(start_filters//(2**i),(3,3), activation='relu', padding='same')(x)\n",
    "        x = UpSampling2D()(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(32768), Dimension(32768), Dimension(16)])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = decoder_block(x = Input(shape=(512,512,3)))\n",
    "model.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim),mean=0., stddev=1.)\n",
    "    return z_mean + K.exp(z_log_var) * epsilon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 2)\n",
      "(?, 2)\n",
      "(?, 4194304)\n",
      "(None, 256, 256, 64)\n",
      "(?, 256, 256, 64)\n",
      "(?, ?, ?, 32)\n",
      "(?, ?, ?, 3)\n"
     ]
    }
   ],
   "source": [
    "img_shape = (512, 512, 3)\n",
    "batch_size = 16\n",
    "latent_dim = 2\n",
    "\n",
    "\n",
    "input_img = Input(shape=img_shape)\n",
    "\n",
    "x = Conv2D(32, 3,padding='same', activation='relu')(input_img)\n",
    "x = Conv2D(64, 3,padding='same', activation='relu',strides=(2, 2))(x)\n",
    "x = Conv2D(64, 3,padding='same', activation='relu')(x)\n",
    "x = Conv2D(64, 3,padding='same', activation='relu')(x)\n",
    "shape_before_flattening = K.int_shape(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "z_mean = Dense(latent_dim)(x)\n",
    "z_log_var = Dense(latent_dim)(x)\n",
    "z = Lambda(sampling)([z_mean, z_log_var])\n",
    "\n",
    "print(z.shape)\n",
    "# This is the input where we will feed `z`.\n",
    "decoder_input = Input(K.int_shape(z)[1:])\n",
    "\n",
    "print(decoder_input.shape)\n",
    "# Upsample to the correct number of units\n",
    "x = Dense(np.prod(shape_before_flattening[1:]),\n",
    "             activation='relu')(decoder_input)\n",
    "\n",
    "print(x.shape)\n",
    "# Reshape into an image of the same shape as before our last `Flatten` layer\n",
    "x = Reshape(shape_before_flattening[1:])(x)\n",
    "\n",
    "print(shape_before_flattening)\n",
    "print(x.shape)\n",
    "# We then apply then reverse operation to the initial\n",
    "# stack of convolution layers: a `Conv2DTranspose` layers\n",
    "# with corresponding parameters.\n",
    "x = Conv2DTranspose(32, 3,\n",
    "                           padding='same', activation='relu',\n",
    "                           strides=(2, 2))(x)\n",
    "\n",
    "print(x.shape)\n",
    "x = Conv2D(3, 3,\n",
    "                  padding='same', activation='sigmoid')(x)\n",
    "# We end up with a feature map of the same size as the original input.\n",
    "print(x.shape)\n",
    "# This is our decoder model.\n",
    "decoder = Model(decoder_input, x)\n",
    "\n",
    "# We then apply it to `z` to recover the decoded `z`.\n",
    "z_decoded = decoder(z)\n",
    "# return z_decoded\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomVariationalLayer(keras.layers.Layer):\n",
    "\n",
    "    def vae_loss(self, x, z_decoded):\n",
    "        x = K.flatten(x)\n",
    "        z_decoded = K.flatten(z_decoded)\n",
    "        xent_loss = keras.metrics.binary_crossentropy(x, z_decoded)\n",
    "        kl_loss = -5e-4 * K.mean(\n",
    "            1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "        return K.mean(xent_loss + kl_loss)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = inputs[0]\n",
    "        z_decoded = inputs[1]\n",
    "        loss = self.vae_loss(x, z_decoded)\n",
    "        self.add_loss(loss, inputs=inputs)\n",
    "        # We don't use this output.\n",
    "        return x\n",
    "\n",
    "# We call our custom layer on the input and the decoded output,\n",
    "# to obtain the final model output.\n",
    "y = CustomVariationalLayer()([input_img, z_decoded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 512, 512, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 512, 512, 32) 896         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 256, 256, 64) 18496       conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 256, 256, 64) 36928       conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 256, 256, 64) 36928       conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 4194304)      0           conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 32)           134217760   flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 2)            66          dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 2)            66          dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 2)            0           dense_2[0][0]                    \n",
      "                                                                 dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Model)                 (None, 512, 512, 3)  12602243    lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "custom_variational_layer_1 (Cus [(None, 512, 512, 3) 0           input_2[0][0]                    \n",
      "                                                                 model_1[1][0]                    \n",
      "==================================================================================================\n",
      "Total params: 146,913,383\n",
      "Trainable params: 146,913,383\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vae = Model(input_img, y)\n",
    "vae.compile(optimizer='rmsprop', loss=None)\n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# batch_size = 16\n",
    "# indexes = np.arange(train_dataset_info.shape[0])\n",
    "# train_generator = data_generator.create_train2(\n",
    "#     train_dataset_info[indexes], batch_size, (SIZE,SIZE,3), augument=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l_train = len(train_dataset_info) \n",
    "l_test = 11702"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42774"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_all = l_train + l_test\n",
    "len_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X_rgb = np.memmap('../cache/rgb_arr_512_512', dtype=np.float32, mode='w+', shape=(len_all, 512,512,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for ii in tqdm(range(l_train)):\n",
    "#     path = train_dataset_info[ii]['path']\n",
    "#     image = data_generator.load_image(path, (SIZE,SIZE,3))\n",
    "#     X_rgb[ii] = image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# submit = pd.read_csv('../data/sample_submission.csv')\n",
    "# for idx, name in tqdm(enumerate(submit['Id'])):\n",
    "#     path = os.path.join('../data/test/', name)\n",
    "#     image = data_generator.load_image(path, (SIZE,SIZE,3))\n",
    "#     X_rgb[idx+l_train] = image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X_rgb = np.memmap('../cache/rgb_arr_512_512', dtype=np.float32, mode='r+', shape=(len_all, 512,512,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from keras.datasets import mnist\n",
    "# (x_train, _), (x_test, y_test) = mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train.shape, x_test.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train = X_rgb[:l_train].copy()\n",
    "# x_test = X_rgb[l_train:].copy()\n",
    "# x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# batch_size = 16\n",
    "\n",
    "# x_train = x_train.astype('float32') / 255.\n",
    "# # x_train = x_train.reshape(x_train.shape + (1,))\n",
    "# x_test = x_test.astype('float32') / 255.\n",
    "# # x_test = x_test.reshape(x_test.shape + (1,))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# vae.fit(x=x_train, y=None,\n",
    "#         shuffle=True,\n",
    "#         epochs=25,\n",
    "#         batch_size=batch_size,\n",
    "#         validation_data=(x_test, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split data into train, valid\n",
    "indexes = np.arange(train_dataset_info.shape[0])\n",
    "np.random.shuffle(indexes)\n",
    "# train_indexes, valid_indexes = train_test_split(indexes, test_size=0.15, random_state=8)\n",
    "train_indexes = indexes\n",
    "valid_indexes = np.arange(l_test)\n",
    "# create train and valid datagens\n",
    "train_generator = data_generator.create_train2(\n",
    "    train_dataset_info[train_indexes], 32, (SIZE,SIZE,3), augument=True)\n",
    "validation_generator = data_generator.create_test(\n",
    "    test_dataset_info[valid_indexes], 16, (SIZE,SIZE,3), augument=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "971/971 [==============================] - 1108s 1s/step - loss: 2048073432.9487 - val_loss: 0.1828\n",
      "Epoch 2/8\n",
      "971/971 [==============================] - 806s 830ms/step - loss: 0.2228 - val_loss: 0.1820\n",
      "Epoch 3/8\n",
      "971/971 [==============================] - 798s 822ms/step - loss: 0.2220 - val_loss: 0.1818\n",
      "Epoch 4/8\n",
      "971/971 [==============================] - 795s 819ms/step - loss: 0.2217 - val_loss: 0.1821\n",
      "Epoch 5/8\n",
      "971/971 [==============================] - 803s 827ms/step - loss: 0.2215 - val_loss: 0.1810\n",
      "Epoch 6/8\n",
      "971/971 [==============================] - 796s 820ms/step - loss: 0.2214 - val_loss: 0.1822\n",
      "Epoch 7/8\n",
      "971/971 [==============================] - 790s 814ms/step - loss: 0.2213 - val_loss: 0.1813\n",
      "Epoch 8/8\n",
      "971/971 [==============================] - 831s 856ms/step - loss: 0.2212 - val_loss: 0.1810\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdafdad2e80>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size=32\n",
    "vae.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=np.ceil(float(len(train_indexes)) / float(batch_size)),\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=np.ceil(float(len(valid_indexes)) / 16.),\n",
    "    epochs=8, \n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# vae.save_weights('../cache/vae-33-1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from scipy.stats import norm\n",
    "\n",
    "# # Display a 2D manifold of the digits\n",
    "# n = 15  # figure with 15x15 digits\n",
    "# digit_size = 512\n",
    "# figure = np.zeros((digit_size * n, digit_size * n, 3))\n",
    "# # Linearly spaced coordinates on the unit square were transformed\n",
    "# # through the inverse CDF (ppf) of the Gaussian\n",
    "# # to produce values of the latent variables z,\n",
    "# # since the prior of the latent space is Gaussian\n",
    "# grid_x = norm.ppf(np.linspace(0.05, 0.95, n))\n",
    "# grid_y = norm.ppf(np.linspace(0.05, 0.95, n))\n",
    "\n",
    "# for i, yi in enumerate(grid_x):\n",
    "#     for j, xi in enumerate(grid_y):\n",
    "#         z_sample = np.array([[xi, yi]])\n",
    "#         z_sample = np.tile(z_sample, batch_size).reshape(batch_size, 2)\n",
    "#         x_decoded = decoder.predict(z_sample, batch_size=batch_size)\n",
    "#         digit = x_decoded[0].reshape(digit_size, digit_size, 3)\n",
    "#         figure[i * digit_size: (i + 1) * digit_size,\n",
    "#                j * digit_size: (j + 1) * digit_size] = digit\n",
    "\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# plt.imshow(figure, cmap='Greys_r')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def global_average_pooling(x):\n",
    "    return K.mean(x, axis = (2, 3))\n",
    "    \n",
    "def global_average_pooling_shape(input_shape):\n",
    "    return input_shape[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model(input_shape, n_out):\n",
    "    input_tensor = Input(shape=input_shape)\n",
    "    base_model = InceptionV3(include_top=False,\n",
    "                   weights='imagenet',\n",
    "                   input_shape=input_shape)\n",
    "    bn = BatchNormalization()(input_tensor)\n",
    "    x = base_model(bn)\n",
    "    x = Conv2D(256, kernel_size=(1,1), activation='relu', name='conv2')(x)\n",
    "    \n",
    "#     x = Conv2D(32, kernel_size=(1,1), activation='relu', name='conv1')(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(n_out, activation='sigmoid')(x)\n",
    "    model = Model(input_tensor, output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def focal_loss(gamma=2., alpha=.25):\n",
    "#     def focal_loss_fixed(y_true, y_pred):\n",
    "#         pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
    "#         pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
    "\n",
    "#         pt_1 = K.clip(pt_1, 1e-3, .999)\n",
    "#         pt_0 = K.clip(pt_0, 1e-3, .999)\n",
    "\n",
    "#         return -K.sum(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1))-K.sum((1-alpha) * K.pow( pt_0, gamma) * K.log(1. - pt_0))\n",
    "#     return focal_loss_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create callbacks list\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "epochs = 10; batch_size = 16\n",
    "checkpoint = ModelCheckpoint('../cache/InceptionV3-34.h5', monitor='val_loss', verbose=1, \n",
    "                             save_best_only=True, mode='min', save_weights_only = True)\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, \n",
    "                                   verbose=1, mode='auto', epsilon=0.0001)\n",
    "early = EarlyStopping(monitor=\"val_loss\", \n",
    "                      mode=\"min\", \n",
    "                      patience=6)\n",
    "callbacks_list = [checkpoint, early, reduceLROnPlat]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# split data into train, valid\n",
    "indexes = np.arange(train_dataset_info.shape[0])\n",
    "np.random.shuffle(indexes)\n",
    "train_indexes, valid_indexes = train_test_split(indexes, test_size=0.15, random_state=8)\n",
    "\n",
    "# create train and valid datagens\n",
    "train_generator = data_generator.create_train(\n",
    "    train_dataset_info[train_indexes], batch_size, (SIZE,SIZE,3), augument=True)\n",
    "validation_generator = data_generator.create_train(\n",
    "    train_dataset_info[valid_indexes], 32, (SIZE,SIZE,3), augument=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 512, 512, 3)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_95 (Batc (None, 512, 512, 3)       12        \n",
      "_________________________________________________________________\n",
      "inception_v3 (Model)         (None, 14, 14, 2048)      21802784  \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 14, 14, 256)       524544    \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 50176)             0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50176)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              51381248  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 28)                28700     \n",
      "=================================================================\n",
      "Total params: 73,737,288\n",
      "Trainable params: 73,702,850\n",
      "Non-trainable params: 34,438\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# warm up model\n",
    "model = create_model(\n",
    "    input_shape=(SIZE,SIZE,3), \n",
    "    n_out=28)\n",
    "model.summary()\n",
    "\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "model.layers[-1].trainable = True\n",
    "model.layers[-2].trainable = True\n",
    "model.layers[-3].trainable = True\n",
    "model.layers[-4].trainable = True\n",
    "model.layers[-5].trainable = True\n",
    "model.layers[-6].trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=f1_loss, \n",
    "    optimizer=Adam(1e-03),\n",
    "    metrics=[f1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "3302/3302 [==============================] - 1135s 344ms/step - loss: 1.1137 - f1: 0.0464 - val_loss: 1.5707 - val_f1: 0.0334\n",
      "Epoch 2/2\n",
      "3302/3302 [==============================] - 1029s 312ms/step - loss: 1.0977 - f1: 0.0620 - val_loss: 1.4721 - val_f1: 0.0346\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f73685e0278>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size=8\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=np.ceil(float(len(train_indexes)) / float(batch_size)),\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=np.ceil(float(len(valid_indexes)) / float(batch_size)),\n",
    "    epochs=2, \n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs=120\n",
    "\n",
    "for layer in model.layers:\n",
    "    layer.trainable = True\n",
    "model.compile(loss=f1_loss,\n",
    "            optimizer=Adam(lr=1e-4),\n",
    "            metrics=[f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "6603/6603 [==============================] - 3791s 574ms/step - loss: 0.9487 - f1: 0.1932 - val_loss: 0.8098 - val_f1: 0.3203\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.80976, saving model to ../cache/InceptionV3-8i1.h5\n",
      "Epoch 2/120\n",
      "6603/6603 [==============================] - 3784s 573ms/step - loss: 0.8446 - f1: 0.2700 - val_loss: 0.7620 - val_f1: 0.3501\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.80976 to 0.76196, saving model to ../cache/InceptionV3-8i1.h5\n",
      "Epoch 3/120\n",
      "6603/6603 [==============================] - 3752s 568ms/step - loss: 0.8079 - f1: 0.2944 - val_loss: 0.7483 - val_f1: 0.3740\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.76196 to 0.74834, saving model to ../cache/InceptionV3-8i1.h5\n",
      "Epoch 4/120\n",
      "6603/6603 [==============================] - 3773s 571ms/step - loss: 0.7817 - f1: 0.3105 - val_loss: 0.7292 - val_f1: 0.3805\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.74834 to 0.72923, saving model to ../cache/InceptionV3-8i1.h5\n",
      "Epoch 5/120\n",
      "6603/6603 [==============================] - 3777s 572ms/step - loss: 0.7595 - f1: 0.3242 - val_loss: 0.7413 - val_f1: 0.3780\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.72923\n",
      "Epoch 6/120\n",
      "6603/6603 [==============================] - 3774s 572ms/step - loss: 0.7414 - f1: 0.3349 - val_loss: 0.7438 - val_f1: 0.3819\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.72923\n",
      "Epoch 7/120\n",
      "6603/6603 [==============================] - 3766s 570ms/step - loss: 0.7248 - f1: 0.3441 - val_loss: 0.7273 - val_f1: 0.3899\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.72923 to 0.72735, saving model to ../cache/InceptionV3-8i1.h5\n",
      "Epoch 8/120\n",
      "6603/6603 [==============================] - 3763s 570ms/step - loss: 0.7099 - f1: 0.3527 - val_loss: 0.7547 - val_f1: 0.3735\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.72735\n",
      "Epoch 9/120\n",
      "6603/6603 [==============================] - 3759s 569ms/step - loss: 0.6973 - f1: 0.3595 - val_loss: 0.7393 - val_f1: 0.3909\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.72735\n",
      "Epoch 10/120\n",
      "6603/6603 [==============================] - 3756s 569ms/step - loss: 0.6866 - f1: 0.3655 - val_loss: 0.7504 - val_f1: 0.3849\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.72735\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "Epoch 11/120\n",
      "6603/6603 [==============================] - 3770s 571ms/step - loss: 0.6514 - f1: 0.3836 - val_loss: 0.7144 - val_f1: 0.4098\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.72735 to 0.71438, saving model to ../cache/InceptionV3-8i1.h5\n",
      "Epoch 12/120\n",
      "6603/6603 [==============================] - 3732s 565ms/step - loss: 0.6390 - f1: 0.3902 - val_loss: 0.7171 - val_f1: 0.4084\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.71438\n",
      "Epoch 13/120\n",
      "6603/6603 [==============================] - 3740s 566ms/step - loss: 0.6331 - f1: 0.3929 - val_loss: 0.7229 - val_f1: 0.4082\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.71438\n",
      "Epoch 14/120\n",
      "6603/6603 [==============================] - 3745s 567ms/step - loss: 0.6289 - f1: 0.3949 - val_loss: 0.7263 - val_f1: 0.4072\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.71438\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "Epoch 15/120\n",
      "6603/6603 [==============================] - 3725s 564ms/step - loss: 0.6244 - f1: 0.3971 - val_loss: 0.7268 - val_f1: 0.4090\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.71438\n",
      "Epoch 16/120\n",
      "6603/6603 [==============================] - 3732s 565ms/step - loss: 0.6233 - f1: 0.3977 - val_loss: 0.7287 - val_f1: 0.4082\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.71438\n",
      "Epoch 17/120\n",
      "6603/6603 [==============================] - 3732s 565ms/step - loss: 0.6225 - f1: 0.3980 - val_loss: 0.7302 - val_f1: 0.4072\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.71438\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f732447b240>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train all layers\n",
    "batch_size=4\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=np.ceil(float(len(train_indexes)) / float(batch_size)),\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=np.ceil(float(len(valid_indexes)) / float(batch_size)),\n",
    "    epochs=epochs, \n",
    "    verbose=1,\n",
    "    callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for ii in tqdm(np.arange(len(train_dataset_info))):\n",
    "#     img1 = cv2.imread(train_dataset_info[ii]['path']+'_red.png', cv2.IMREAD_GRAYSCALE)\n",
    "#     img2 = cv2.imread(train_dataset_info[ii]['path']+'_green.png', cv2.IMREAD_GRAYSCALE)\n",
    "#     img3 = cv2.imread(train_dataset_info[ii]['path']+'_blue.png', cv2.IMREAD_GRAYSCALE)\n",
    "#     img1 = np.stack((img1, img2, img3), -1)\n",
    "#     name = '../cache/RGB/img-{}.png'.format(ii)\n",
    "#     cv2.imwrite(name,img1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# submit = pd.read_csv('../data/sample_submission.csv')\n",
    "# for name in tqdm(submit['Id']):\n",
    "#     path = os.path.join('../data/test/', name)\n",
    "#     img1 = cv2.imread(path+'_red.png', cv2.IMREAD_GRAYSCALE)\n",
    "#     img2 = cv2.imread(path+'_green.png', cv2.IMREAD_GRAYSCALE)\n",
    "#     img3 = cv2.imread(path+'_blue.png', cv2.IMREAD_GRAYSCALE)\n",
    "#     img1 = np.stack((img1, img2, img3), -1)\n",
    "#     name1 = '../cache/RGB/test/img-{}.png'.format(name)\n",
    "#     cv2.imwrite(name1,img1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11702/11702 [08:48<00:00, 22.16it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create submit\n",
    "submit = pd.read_csv('../data/sample_submission.csv')\n",
    "predicted = []\n",
    "draw_predict = []\n",
    "# model = create_model(\n",
    "#     input_shape=(SIZE,SIZE,3), \n",
    "#     n_out=28)\n",
    "# for layer in model.layers:\n",
    "#     layer.trainable = True\n",
    "# model.compile(loss=f1_loss,\n",
    "#             optimizer=Adam(lr=1e-4),\n",
    "#             metrics=[f1])\n",
    "model.load_weights('../cache/InceptionV3-8i1.h5')\n",
    "for name in tqdm(submit['Id']):\n",
    "    path = os.path.join('../data/test/', name)\n",
    "    image = data_generator.load_image(path, (SIZE,SIZE,3))/255.\n",
    "    score_predict = model.predict(image[np.newaxis])[0]\n",
    "    draw_predict.append(score_predict)\n",
    "    label_predict = np.arange(28)[score_predict>=0.2]\n",
    "    str_predict_label = ' '.join(str(l) for l in label_predict)\n",
    "    predicted.append(str_predict_label)\n",
    "\n",
    "submit['Predicted'] = predicted\n",
    "# np.save('../cache/draw_predict_InceptionV3-8.npy', score_predict)\n",
    "# submit.to_csv('../submissions/submit_InceptionV3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submit.to_csv('../submissions/sub8i1-a.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11702/11702 [08:59<00:00, 21.70it/s]\n"
     ]
    }
   ],
   "source": [
    "predicted = []\n",
    "for name in tqdm(submit['Id']):\n",
    "    path = os.path.join('../data/test/', name)\n",
    "    image = data_generator.load_image(path, (SIZE,SIZE,3))/255.\n",
    "    score_predict = model.predict(image[np.newaxis])[0]\n",
    "    draw_predict.append(score_predict)\n",
    "    label_predict = np.arange(28)[score_predict>=0.25]\n",
    "    str_predict_label = ' '.join(str(l) for l in label_predict)\n",
    "    predicted.append(str_predict_label)\n",
    "submit['Predicted'] = predicted\n",
    "submit.to_csv('../submissions/sub8i1-b.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11702/11702 [09:18<00:00, 20.97it/s]\n"
     ]
    }
   ],
   "source": [
    "predicted = []\n",
    "for name in tqdm(submit['Id']):\n",
    "    path = os.path.join('../data/test/', name)\n",
    "    image = data_generator.load_image(path, (SIZE,SIZE,3))/255.\n",
    "    score_predict = model.predict(image[np.newaxis])[0]\n",
    "    draw_predict.append(score_predict)\n",
    "    label_predict = np.arange(28)[score_predict>=0.3]\n",
    "    str_predict_label = ' '.join(str(l) for l in label_predict)\n",
    "    predicted.append(str_predict_label)\n",
    "submit.to_csv('../submissions/sub8i1-c.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11702/11702 [09:26<00:00, 20.66it/s]\n"
     ]
    }
   ],
   "source": [
    "predicted = []\n",
    "for name in tqdm(submit['Id']):\n",
    "    path = os.path.join('../data/test/', name)\n",
    "    image = data_generator.load_image(path, (SIZE,SIZE,3))/255.\n",
    "    score_predict = model.predict(image[np.newaxis])[0]\n",
    "    draw_predict.append(score_predict)\n",
    "    label_predict = np.arange(28)[score_predict>=0.35]\n",
    "    str_predict_label = ' '.join(str(l) for l in label_predict)\n",
    "    predicted.append(str_predict_label)\n",
    "submit['Predicted'] = predicted\n",
    "submit.to_csv('../submissions/sub8i1-d.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11702/11702 [09:29<00:00, 20.54it/s]\n"
     ]
    }
   ],
   "source": [
    "predicted = []\n",
    "for name in tqdm(submit['Id']):\n",
    "    path = os.path.join('../data/test/', name)\n",
    "    image = data_generator.load_image(path, (SIZE,SIZE,3))/255.\n",
    "    score_predict = model.predict(image[np.newaxis])[0]\n",
    "    draw_predict.append(score_predict)\n",
    "    label_predict = np.arange(28)[score_predict>=0.4]\n",
    "    str_predict_label = ' '.join(str(l) for l in label_predict)\n",
    "    predicted.append(str_predict_label)\n",
    "submit['Predicted'] = predicted\n",
    "submit.to_csv('../submissions/sub8i1-e.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/1855095/how-to-create-a-zip-archive-of-a-directory\n",
    "def backup_project_as_zip(project_dir, zip_file):\n",
    "    assert(os.path.isdir(project_dir))\n",
    "    assert(os.path.isdir(os.path.dirname(zip_file)))\n",
    "    shutil.make_archive(zip_file.replace('.zip',''), 'zip', project_dir)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-11-19 12:33:39.384598\n"
     ]
    }
   ],
   "source": [
    "import datetime, shutil\n",
    "now = datetime.datetime.now()\n",
    "print(now)\n",
    "PROJECT_PATH = '/home/watts/lal/Kaggle/kagglehp/scripts_nbs'\n",
    "backup_project_as_zip(PROJECT_PATH, '../cache/code.scripts_nbs.%s.zip'%now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 480k/480k [00:08<00:00, 51.3kB/s]\n",
      "Successfully submitted to Human Protein Atlas Image ClassificationCPU times: user 332 ms, sys: 134 ms, total: 467 ms\n",
      "Wall time: 15.6 s\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# !kaggle competitions submit -c human-protein-atlas-image-classification -f ../submissions/sub8i1.csv -m \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileName      date                 description  status    publicScore  privateScore  \r\n",
      "------------  -------------------  -----------  --------  -----------  ------------  \r\n",
      "sub8i.csv     2018-11-14 04:28:35               complete  0.443        None          \r\n",
      "sub8h.csv     2018-11-13 23:48:00               complete  0.434        None          \r\n",
      "sub8g.csv     2018-11-13 07:17:59               complete  0.389        None          \r\n",
      "sub8c.csv     2018-11-11 14:31:02               complete  0.429        None          \r\n",
      "sub30.csv     2018-11-09 07:02:56               complete  0.033        None          \r\n",
      "sub29.csv     2018-11-08 22:07:11               complete  0.389        None          \r\n",
      "sub28-c.csv   2018-11-08 15:47:08               complete  0.457        None          \r\n",
      "sub28-bb.csv  2018-11-08 15:46:13               complete  0.458        None          \r\n",
      "sub28-b.csv   2018-11-08 15:45:28               complete  0.454        None          \r\n",
      "sub28-a.csv   2018-11-08 15:44:27               complete  0.454        None          \r\n",
      "sub25.csv     2018-11-07 10:45:12               complete  0.421        None          \r\n",
      "sub25.csv     2018-11-07 10:26:20               complete  0.421        None          \r\n",
      "sub8a.csv     2018-11-07 05:53:08               complete  0.425        None          \r\n",
      "sub24.csv     2018-11-07 05:09:26               complete  0.410        None          \r\n",
      "sub23-d.csv   2018-11-07 00:21:06               complete  0.469        None          \r\n",
      "sub23-c.csv   2018-11-06 14:34:37               complete  0.472        None          \r\n",
      "sub23-bb.csv  2018-11-06 14:33:35               complete  0.466        None          \r\n",
      "sub23-b.csv   2018-11-06 14:32:47               complete  0.463        None          \r\n",
      "sub23-a.csv   2018-11-06 14:31:57               complete  0.461        None          \r\n",
      "sub22-a.csv   2018-11-06 14:30:53               complete  0.467        None          \r\n"
     ]
    }
   ],
   "source": [
    "# from time import sleep\n",
    "# sleep(60)\n",
    "# !kaggle competitions submissions -c human-protein-atlas-image-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.4.7.1 / client 1.3.8)\r\n",
      "fileName  date                 description  status    publicScore  privateScore  \r\n",
      "--------  -------------------  -----------  --------  -----------  ------------  \r\n",
      "sub8.csv  2018-10-20 20:08:45               complete  0.422        None          \r\n",
      "sub7.csv  2018-10-20 17:06:09               complete  0.389        None          \r\n",
      "sub5.csv  2018-10-19 18:27:33               complete  0.387        None          \r\n",
      "sub4.csv  2018-10-19 14:45:15               complete  0.411        None          \r\n",
      "sub3.csv  2018-10-19 10:19:26               complete  0.377        None          \r\n",
      "sub2.csv  2018-10-19 08:07:30               complete  0.135        None          \r\n",
      "sub1.csv  2018-10-19 06:28:57               complete  0.374        None          \r\n"
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "sleep(60)\n",
    "!kaggle competitions submissions -c human-protein-atlas-image-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hpg",
   "language": "python",
   "name": "hpg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
